{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src import eda, util, fe, models\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# ---- EDA Konfiguration ----\n",
    "# Skalierung aller Sensoren und Operation Settings (Z-Norm pro Betriebsbedingung)\n",
    "NORMALIZE = True\n",
    "\n",
    "EDA_FD001 = True\n",
    "EDA_FD002 = True\n",
    "EDA_FD003 = True\n",
    "EDA_FD004 = True\n",
    "\n",
    "# ---- Caching-/Recompute-Konfiguration ----\n",
    "PRECOMPUTE_ALL_PLOTS = False        # Alle Plots bei Notebook-Start berechnen. Widgets reagieren erst nach dem Precompute.\n",
    "FORCE_RECOMPUTE_PLOTS = False       # Alle Plots beim Precompute immer neu berechnen, auch wenn sie schon im Cache sind.\n",
    "FORCE_RECOMPUTE_TSNE_DBSCAN = False # TSNE/DBSCAN immer neu berechnen\n",
    "\n",
    "if not PRECOMPUTE_ALL_PLOTS:        # Nur gültig, wenn Precompute aktiviert ist!\n",
    "    FORCE_RECOMPUTE_PLOTS = False   \n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; background-color: white; padding: 10px; border-radius: 6px; box-shadow: 0 0 5px rgba(0,0,0,0.2);\">\n",
    "  <tr>\n",
    "    <td>\n",
    "      <h1 style=\"margin-bottom: 0; color: black; font-size: clamp(1.4rem, 2.2vw, 2.2rem);\">\n",
    "        Predictive Maintenance: Vorhersage der Remaining Useful Life (RUL) von Triebwerken des NASA C-MAPSS-Datensatzes\n",
    "      </h1>\n",
    "    </td>\n",
    "    <td align=\"right\">\n",
    "      <img src=\"images/OST_Logo_DE_RGB@2000ppi.png\" alt=\"OST Logo\" width=\"200\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Autor:** Rino Albertin  \n",
    "**Datum:** 6. März 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inhaltsverzeichnis\n",
    "\n",
    "1. Einleitung  \n",
    "   1.1 Zielsetzung  \n",
    "   1.2 Vorgehensweise  \n",
    "\n",
    "2. Überblick über den Datensatz und technische Grundlagen  \n",
    "   2.1 Allgemeine Datenstruktur  \n",
    "   2.2 Operative Einstellungen und Sensorik  \n",
    "\n",
    "3. Einzelanalyse  \n",
    "   3.1 FD001  \n",
    "   3.2 FD002  \n",
    "   3.3 FD003  \n",
    "   3.4 FD004  \n",
    "\n",
    "4. Kombinierte Analyse aller Datensätze  \n",
    "   4.1 Explorative Datenanalyse  \n",
    "   4.2 Feature Engineering  \n",
    "   4.3 Modellierung  \n",
    "   4.4 Hyperparameter-Tuning  \n",
    "   4.5 Evaluation  \n",
    "\n",
    "5. Vergleich der Modellresultate  \n",
    "\n",
    "6. Fazit und Ausblick\n",
    "\n",
    "# Anhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Einleitung\n",
    "\n",
    "Predictive Maintenance ist in der heutigen Industrie von zentraler Bedeutung, um ungeplante Ausfälle zu vermeiden und Wartungskosten zu senken. Die Vorhersage der verbleibenden Nutzungsdauer (Remaining Useful Life, RUL) von Triebwerken ermoeglicht eine optimierte Planung von Wartungsarbeiten und verbessert die Betriebseffizienz.\n",
    "\n",
    "Der NASA (C-MAPSS) Commercial Modular Aero-Propulsion System Simulation-Datensatz bietet simulierte Run-to-Failure-Zeitreihen von Triebwerken der NASA, die Zeit, Betriebsbedingungen, 3 operative Einstellungen und 21 Sensormessungen umfassen. Dies macht ihn zu einer idealen Grundlage, um moderne Machine-Learning-Methoden zur RUL-Vorhersage zu evaluieren und zu vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Zielsetzung\n",
    "\n",
    "Entwicklung eines Machine-Learning-Modells, das auf Basis historischer Sensordaten die RUL von Triebwerken präzise vorhersagen kann. Dabei soll sowohl das Verhalten einzelner Szenarien als auch eine generalisierbare Lösung über alle vier Datensätze hinweg untersucht werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Vorgehensweise\n",
    "\n",
    "Die Bearbeitung erfolgt in zwei aufeinander aufbauenden Phasen:\n",
    "\n",
    "### Phase 1: Einzelanalysen pro Datensatz (FD001–FD004)\n",
    "Jeder der vier C-MAPSS-Datensätze wird separat analysiert, um spezifische Charakteristika und Herausforderungen zu verstehen. Für jeden Datensatz wird dieselbe Pipeline angewendet:\n",
    "\n",
    "1. **Explorative Datenanalyse (EDA):**\n",
    "   - Visualisierung typischer Sensorverläufe.\n",
    "   - Analyse der Datenstruktur und Lebensdauerverläufe.\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Selektion und Transformation relevanter Sensoren.\n",
    "   - Umgang mit korrelierten oder konstanten Features.\n",
    "\n",
    "3. **Modellierung:**\n",
    "   - Auswahl geeigneter Machine-Learning-Modelle.\n",
    "   - Aufbau einer Pipeline (Preprocessing, Training, Inferenz).\n",
    "\n",
    "4. **Hyperparameter-Tuning:**\n",
    "   - Optimierung mit `GridSearchCV` zur groben Parameterauswahl.\n",
    "   - Erweiterte Feinabstimmung vielversprechender Modelle mit `RandomizedSearchCV`.\n",
    "\n",
    "5. **Evaluation:**\n",
    "   - Validierung.\n",
    "   - Vergleich der Szenarien und Modelle.\n",
    "\n",
    "### Phase 2: Kombinierte Analyse (Generalmodell)\n",
    "In Phase 2 werden die vier Datensätze zusammengeführt, um ein Modell zu entwickeln, das über unterschiedliche Szenarien hinweg verallgemeinerbar ist. Die Analyse basiert auf der gleichen Pipeline wie in Phase 1.\n",
    "\n",
    "**Referenzen:**  \n",
    "- NASA C-MAPSS-Datensatz: https://data.nasa.gov/d/ff5v-kuh6, Alternativ verfügbar unter: [Kaggle – NASA Turbofan Jet Engine Data Set](https://www.kaggle.com/datasets/behrad3d/nasa-cmaps)\n",
    "- Machine Learning Unterichtsunterlagen der OST – Ostschweizer Fachhochschule\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Überblick über den Datensatz und technische Grundlagen\n",
    "\n",
    "Bevor mit der eigentlichen Analyse begonnen wird, erfolgt in diesem Kapitel eine technische Einführung in den C-MAPSS-Datensatz. Ziel ist es, ein grundlegendes Verständnis für Struktur, Sensorik und die inhaltlichen Rahmenbedingungen zu schaffen. Eine erste übergreifende EDA bietet zusätzlich einen Einblick in Gemeinsamkeiten und Besonderheiten der vier Szenarien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Allgemeine Datenstruktur\n",
    "\n",
    "Der C-MAPSS-Datensatz (Commercial Modular Aero-Propulsion System Simulation) besteht aus vier Teildatensätzen (FD001–FD004), die unterschiedliche Betriebsszenarien simulieren. Jeder Datensatz enthält Sensormessungen von mehreren Triebwerken über deren gesamte Lebensdauer hinweg (Run-to-Failure).\n",
    "\n",
    "Für jede Zeile sind folgende Informationen verfügbar:\n",
    "\n",
    "- **unit**: ID des Triebwerks (eine Einheit)\n",
    "- **time**: aktueller Zyklus (Zeitpunkt)\n",
    "- **op_setting_1–3**: operative Einstellungen (Flughöhe, Machzahl, Drosselklappen-Positionen)\n",
    "- **sensor_1–21**: Sensormessungen aus verschiedenen Triebwerkskomponenten\n",
    "\n",
    "![Triebwerksaufbau in C-MAPSS](images/Simplified%20diagram%20of%20engine%20simulated%20in%20C-MAPSS.png)\n",
    "\n",
    "Die Abbildung zeigt den schematischen Aufbau eines Triebwerks, wie es in der C-MAPSS-Simulation verwendet wird. Die Hauptkomponenten sind:\n",
    "\n",
    "- **Fan:** Der Fan (Luftgebläse) saugt Umgebungsluft an, die teilweise in den Bypass strömt (äusserer Luftstrom) und teilweise ins Triebwerk.\n",
    "- **LPC (Low Pressure Compressor):** Komprimiert die angesaugte Luft bei niedrigem Druck.\n",
    "- **HPC (High Pressure Compressor):** Erhöht den Druck der Luft weiter vor der Verbrennung.\n",
    "- **Combustor:** Vermischt die verdichtete Luft mit Treibstoff, zündet die Mischung und erzeugt damit heisse Hochdruckgase.\n",
    "- **HPT (High Pressure Turbine):** Entzieht den heissen Gasen Energie, um den HPC anzutreiben.\n",
    "- **LPT (Low Pressure Turbine):** Treibt den Fan und die LPC an.\n",
    "- **N1/N2:** Repräsentieren die beiden Hauptwellen im Triebwerk (N1: Fan + LPC, N2: HPC + HPT).\n",
    "- **Nozzle:** Düse am Austritt – beschleunigt die Abgasströmung und erzeugt Schub.\n",
    "\n",
    "Viele der 21 Sensoren messen Parameter an genau diesen Stellen, z. B. Druck, Temperatur, Drehzahl oder Luftmassenströme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Operative Einstellungen und Sensorik\n",
    "\n",
    "Die C-MAPSS-Daten umfassen neben Zyklusinformationen auch drei operative Einstellungen und 21 Sensormessungen. Die operativen Einstellungen variieren je nach Szenario und beeinflussen die physikalischen Messgrössen, die an verschiedenen Triebwerkskomponenten aufgezeichnet werden.\n",
    "\n",
    "#### Operative Einstellungen\n",
    "\n",
    "| Spalte         | Beschreibung                         | Wertebereich        |\n",
    "|----------------|--------------------------------------|---------------------|\n",
    "| op_setting_1   | Flughöhe (Altitude)                  | 0 – 42'000 ft       |\n",
    "| op_setting_2   | Machzahl                             | 0 – 0.84            |\n",
    "| op_setting_3   | Throttle Resolver Angle (TRA)        | 20 – 100            |\n",
    "\n",
    "#### Sensorübersicht\n",
    "\n",
    "| Sensor | Beschreibung                             | Wertebereich (FD001–FD004) |\n",
    "|--------|------------------------------------------|----------------------------|\n",
    "|  1     | Total temperature at fan inlet (T2)      | 445.0 – 518.67 °R          |\n",
    "|  2     | Total temperature at LPC outlet (T24)    | 535.48 – 645.11 °R         |\n",
    "|  3     | Total temperature at HPC outlet (T30)    | 1242.67 – 1616.91 °R       |\n",
    "|  4     | Total temperature at LPT outlet (T50)    | 1023.77 – 1441.49 °R       |\n",
    "|  5     | Pressure at fan inlet (P2)               | 3.91 – 14.62 psia          |\n",
    "|  6     | Bypass-duct pressure (P15)               | 5.67 – 21.61 psia          |\n",
    "|  7     | Total pressure at HPC outlet (P30)       | 136.17 – 570.81 psia       |\n",
    "|  8     | Physical fan speed (Nf)                  | 1914.72 – 2388.64 rpm      |\n",
    "|  9     | Physical core speed (Nc)                 | 7984.51 – 9244.59 rpm      |\n",
    "| 10     | Engine pressure ratio (epr)              | 0.93 – 1.32                |\n",
    "| 11     | Static pressure at HPC outlet (Ps30)     | 36.04 – 48.53 psia         |\n",
    "| 12     | Ratio of fuel flow to Ps30 (phi)         | 128.31 – 537.49 pps/psi    |\n",
    "| 13     | Corrected fan speed (NRf)                | 2027.57 – 2390.49 rpm      |\n",
    "| 14     | Corrected core speed (NRc)               | 7845.78 – 8293.72 rpm      |\n",
    "| 15     | Bypass ratio (BPR)                       | 8.1563 – 11.0669           |\n",
    "| 16     | Burner fuel-air ratio (farB)             | 0.02 – 0.03                |\n",
    "| 17     | Bleed enthalpy (htBleed)                 | 302   – 400                |\n",
    "| 18     | Demanded fan speed (Nf_dmd)              | 1915   – 2388 rpm          |\n",
    "| 19     | Demanded corrected fan speed (PCNfR_dmd) | 84.93 – 100.0 rpm          |\n",
    "| 20     | HPT coolant bleed (W31)                  | 10.16 – 39.89 lbm/s        |\n",
    "| 21     | LPT coolant bleed (W32)                  | 6.0105 – 23.9505 lbm/s     |\n",
    "\n",
    "*Die angegebenen Wertebereiche wurden über alle Trainingsdaten der Szenarien FD001 bis FD004 bestimmt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"FD001\": util.load_cmapss_data(\"FD001\"),\n",
    "    \"FD002\": util.load_cmapss_data(\"FD002\"),\n",
    "    \"FD003\": util.load_cmapss_data(\"FD003\"),\n",
    "    \"FD004\": util.load_cmapss_data(\"FD004\"),\n",
    "    \"ALL\":   util.load_cmapss_data()\n",
    "}\n",
    "\n",
    "raw_datasets = {k: (df_train.copy(), df_test.copy()) for k, (df_train, df_test) in datasets.items()}\n",
    "\n",
    "df_train_01, df_test_01 = datasets[\"FD001\"]\n",
    "df_train_02, df_test_02 = datasets[\"FD002\"]\n",
    "df_train_03, df_test_03 = datasets[\"FD003\"]\n",
    "df_train_04, df_test_04 = datasets[\"FD004\"]\n",
    "df_train, df_test = datasets[\"ALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vorverarbeitung – Skalierung nach Betriebs­bedingungen\n",
    "\n",
    "Um Niveauverschiebungen auszublenden, die allein durch wechselnde Flughöhen, Machzahlen oder Drosselklappen-Stellungen entstehen (op_settings), werden alle 21 Sensoren **z-standardisiert – getrennt pro Betriebs­gruppe (`op_cond`)**.\n",
    "\n",
    "Die Gruppierung erfolgt anhand fester Schwellenwerte (siehe Plot unten) in einer **6 × 5 × 2-Einteilung**:\n",
    "\n",
    "| Einstellgrösse    | Binning-Strategie                            | Zweck                           |\n",
    "|-------------------|----------------------------------------------|----------------------------------|\n",
    "| **op_setting 1**  | manuell: `[0 – 5 – 15 – 22 – 30 – 40 – ∞]`    | trennt Flughöhenbereiche        |\n",
    "| **op_setting 2**  | manuell: `[0 – 0.2 – 0.55 – 0.63 – 0.8 – ∞]`  | trennt Geschwindigkeitsbereiche |\n",
    "| **op_setting 3**  | binär: `< 80` → T0, `≥ 80` → T1               | Zweipunkt-Steuerung (TRA)       |\n",
    "\n",
    "Diese Einteilung ergibt **60 theoretisch mögliche Kombinationen** (6 × 5 × 2).  \n",
    "**Tatsächlich kommen aber in jedem Szenario nur genau 6 Gruppen vor** – ein Grossteil der Kombinationen tritt in den Daten nicht auf. Dadurch bleibt die Normalisierung robust und gut interpretierbar.\n",
    "\n",
    "- Der `StandardScaler` wird **ausschliesslich auf den Trainingsdaten** pro `op_cond`-Gruppe fit-transformiert.\n",
    "- Für die zugehörigen Testdaten wird **dieselbe Skalierung** mittels `transform()` übernommen.\n",
    "- Bei **konstanten Betriebspunkten** (z. B. FD001 & FD003) degeneriert das Verfahren zu einer **globalen Standardisierung**, da nur eine einzige `op_cond`-Gruppe existiert.\n",
    "\n",
    "> **Hinweis:** Alle tatsächlich vorkommenden Gruppen enthalten mindestens **5000 Zeilen**, was eine robuste, gruppenbasierte Skalierung erlaubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_op_settings_histograms(df_train_02, df_test_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    for k in datasets:\n",
    "        datasets[k] = util.standardize_by_op_cond(*datasets[k])\n",
    "else:\n",
    "    for k in datasets:\n",
    "        datasets[k] = tuple(util.assign_op_cond_bins(df) for df in datasets[k])\n",
    "\n",
    "df_train_01, df_test_01 = datasets[\"FD001\"]\n",
    "df_train_02, df_test_02 = datasets[\"FD002\"]\n",
    "df_train_03, df_test_03 = datasets[\"FD003\"]\n",
    "df_train_04, df_test_04 = datasets[\"FD004\"]\n",
    "df_train, df_test = datasets[\"ALL\"]\n",
    "\n",
    "print(\"df_train_02:\", util.get_op_cond_distribution_summary(df_train_02), \"\\n\")\n",
    "print(\"df_test_02:\", util.get_op_cond_distribution_summary(df_test_02), \"\\n\")\n",
    "\n",
    "print(\"df_train_04:\", util.get_op_cond_distribution_summary(df_train_04), \"\\n\")\n",
    "print(\"df_test_04:\", util.get_op_cond_distribution_summary(df_test_04), \"\\n\")\n",
    "\n",
    "print(\"df_train:\", util.get_op_cond_distribution_summary(df_train), \"\\n\")\n",
    "print(\"df_test:\", util.get_op_cond_distribution_summary(df_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Einzelanalysen der vier Datensätze\n",
    "\n",
    "Ziel dieses Kapitels ist es, die vier Teildatensätze **FD001 bis FD004** separat zu analysieren und zu modellieren. Jeder Datensatz repräsentiert ein eigenes Betriebsszenario mit unterschiedlichen Rahmenbedingungen (konstante vs. variable Settings, ein oder zwei Degradationsmodi).\n",
    "\n",
    "Für jeden Datensatz wird eine identische Analysepipeline angewendet, bestehend aus:\n",
    "- Explorative Datenanalyse (EDA)\n",
    "- Feature Engineering\n",
    "- Modellierung\n",
    "- Hyperparameter-Tuning\n",
    "- Evaluation\n",
    "\n",
    "Diese Einzelschritte ermöglichen ein besseres Verständnis der Stärken und Schwächen verschiedener Modelle je Szenario und legen die Basis für die spätere kombinierte Analyse in Kapitel 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1 Analyse für FD001\n",
    "Der Datensatz FD001 stellt das einfachste Szenario innerhalb von C-MAPSS dar: konstante Betriebsbedingungen und ein einziger Degradationsmodus. Er eignet sich daher besonders gut für eine erste Modellierung und das Testen von Grundkonzepten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Explorative Datenanalyse (EDA)\n",
    "Ziel dieses Abschnitts ist es, ein erstes Verständnis für die Struktur und Eigenschaften des Datensatzes FD001 zu entwickeln. Dabei werden typische Lebensdauerverläufe analysiert, exemplarische Sensorwerte visualisiert und erste Hinweise auf potenziell relevante Merkmale identifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD001:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD001 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_01, \"FD001\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[39, 69]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=69, dataset_name=\"FD001-69\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD001\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD001 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_01,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD001\",\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_01[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD001\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD001\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD001\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD001\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD001\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD001\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD001\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD001\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD001 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD001 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lebensdauerverteilung:**  \n",
    "Die Lebensdauer der Triebwerke reicht von 128 bis 362 Zyklen (Median: 199). Die Verteilung ist leicht rechtsschief und weist einige Ausreisser mit hoher Zyklenanzahl auf.\n",
    "\n",
    "**Operation Settings:**  \n",
    "Die Betriebsbedingungen sind in diesem Szenario konstant und nur leicht verrauscht. `op_setting_1` und `op_setting_2` zeigen minimale Streuung, während `op_setting_3` konstant bleibt. Die Korrelationen der Settings mit der RUL sind vernachlässigbar (alle < 0.01). Auch innerhalb der Lifetime-Cluster zeigen sich keine signifikanten Unterschiede, weshalb diese Settings nicht zur Modellierung herangezogen werden sollten.\n",
    "\n",
    "**Sensoranalyse:**  \n",
    "Die Sensoren lassen sich in mehrere Gruppen mit stark korrelierten Verläufen einteilen. Konstante Sensoren wurden zuvor entfernt:\n",
    "\n",
    "- **Gruppe A:** `sensor_2`, `3`, `4`, `8`, `11`, `13`, `15`, `17`  \n",
    "- **Gruppe B:** `sensor_7`, `12`, `20`, `21`  \n",
    "- **Gruppe C:** `sensor_9`, `14`  \n",
    "- **Gruppe D:** `sensor_6` – stark verrauscht, nicht informativ\n",
    "\n",
    "Mehrere Sensoren zeigen klare Trends über die Zeit und starke Korrelationen mit der RUL. Sensorverläufe über normierte Zeit zeigen für viele Sensoren monotone, glatte Verläufe. Diese sind potenziell prädiktiv und für Feature Engineering geeignet. Die Verteilungen zeigen teils Unterschiede zwischen Units mit langer und kurzer Lebensdauer, was weitere Segmentierungen rechtfertigt. Die Verteilungen sind meist unimodal im letzen Zyklus und weissen wenig Aussreiser auf. Die Ausreisser wurden dabei nicht entfernt da sie potenziel wichitge Informationen liefern.\n",
    "\n",
    "**Clusteranalyse:**  \n",
    "Ein t-SNE/DBSCAN-Verfahren identifiziert zwei Cluster, wobei der kleinere (Cluster 1) ca. 2 % der Daten umfasst. Er enthält keine finalen Datenpunkte (also keinen Lebensdauer-Endpunkt). Der Eintritt in diesen Cluster erfolgt typischerweise deutlich früher (Ø = 0.255 normierte Zeit) als bei Cluster 0 (Ø = 0.507).\n",
    "\n",
    "Sensorverläufe in Cluster 1 sind stark verrauscht und flach. In Cluster 0 hingegen zeigen sich klar strukturierte Abnahmen bzw. Zunahmen – konsistent mit dem Verschleissverhalten. Daraus ergibt sich:\n",
    "\n",
    "- **Cluster 0**: Hauptcluster mit verwertbaren Mustern und finalen Datenpunkten  \n",
    "- **Cluster 1**: Frühzeitiger Sondercluster ohne verwertbare Zielgrösse (RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Feature Engineering\n",
    "\n",
    "Auf Basis der EDA wurden gezielt Sensoren ausgewählt, die für die Prognose der Restlebensdauer (RUL) eine hohe Aussagekraft besitzen. Die Auswahl erfolgte entlang physikalischer Kriterien, des zeitlichen Signalverlaufs, der Korrelation zur Zielgrösse sowie einer Redundanzanalyse innerhalb stark korrelierter Sensorgruppen. Konstant bleibende oder verrauschte Sensoren wurden entfernt.\n",
    "\n",
    "Zur besseren Übersicht wurden die verbleibenden Sensoren in Gruppen eingeteilt und repräsentative Merkmale extrahiert. Zusätzlich wurden kombinierte Features gebildet, um komplexe physikalische Zusammenhänge wie thermodynamische Effizienz oder mechanische Wechselwirkungen modellierbar zu machen.\n",
    "\n",
    "Um den physikalischen Kontext zu verdeutlichen, wurden im ersten Verarbeitungsschritt alle Sensoren und Betriebsbedingungen in Klartext umbenannt. Ein weiterer Verarbeitungsschritt bestand darin, das Trainingsset gezielt zu kürzen: Bei einem zufälligen Anteil von 25 % der Triebwerks-Units wurde das letzte Segment abgeschnitten, sodass diese Einheiten nicht bis zum vollständigen Ausfall beobachtet wurden. Dadurch wird das Modell gezwungen, auch aus unvollständigen Lebenszyklen zu lernen, was der realen Situation im laufenden Betrieb besser entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df_train_01, df_test_01 = raw_datasets[\"FD001\"]\n",
    "df_train_01_fe = fe.rename_opsettings_and_sensors(df_train_01)\n",
    "df_test_01_fe = fe.rename_opsettings_and_sensors(df_test_01)\n",
    "df_train_01_fe = fe.truncate_train_units(df_train_01_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gruppe A: Temperatur, Druck, Drehzahl & Verhältnisse\n",
    "\n",
    "Verwendet wurden `sensor_4_T50_LPT_outlet_temp`, `sensor_11_Ps30_HPC_static_pres`, `sensor_15_BPR_bypass_ratio` und `sensor_17_htBleed_bleed_enthalpy`, da sie zentrale thermodynamische und aerodynamische Zustände des Triebwerks abbilden. `sensor_4` zeigte die höchste Korrelation mit der RUL und ist physikalisch am sinnvollsten, da er die Temperatur ganz am Ende des Systems misst. Die Sensoren `sensor_2_T24` und `sensor_3_T30` wurden aufgrund starker Redundanz mit `sensor_4` ausgeschlossen. Ergänzend wurden mehrere kombinierte Features eingesetzt: `rpm_diff = sensor_13_NRf_corrected_fan_speed - sensor_8_Nf_fan_speed` dient als robustes Mass für mechanische Abweichungen. `temp_to_pressure = sensor_4_T50_LPT_outlet_temp / sensor_11_Ps30_HPC_static_pres` quantifiziert potenzielle Effizienzverluste bei abweichenden Druckverhältnissen. `bleed_minus_temp = sensor_17_htBleed_bleed_enthalpy - sensor_4_T50_LPT_outlet_temp` identifiziert thermische Ungleichgewichte zwischen Zapfluft und Abgastemperatur, z. B. durch Leckagen.\n",
    "\n",
    "##### Gruppe B: Treibstofffluss & Kühlung\n",
    "\n",
    "Es wurde `sensor_12_phi_fuel_flow_per_Ps30` verwendet, da er die Brennstoffeffizienz relativ zum statischen Druck abbildet. Zusätzlich wurde `coolant_mean = (sensor_20_W31_HPT_coolant_bleed + sensor_21_W32_LPT_coolant_bleed)/2` gebildet, um den thermischen Kühlzustand robuster zu erfassen. Das kombinierte Feature `phi_to_bpr = sensor_12_phi_fuel_flow_per_Ps30 / sensor_15_BPR_bypass_ratio` erlaubt Rückschlüsse auf Effizienzverluste bei untypischer Strömungsverteilung.\n",
    "\n",
    "##### Gruppe C: Mechanische Belastung\n",
    "\n",
    "`sensor_14_NRc_corrected_core_speed` wurde als direkter Indikator für mechanische Belastung ausgewählt. Zusätzlich wurde `torque_ratio = sensor_14_NRc_corrected_core_speed / sensor_9_Nc_core_speed` gebildet, um die Lastverteilung normiert über Betriebspunkte hinweg zu erfassen. `sensor_9_Nc_core_speed` wurde aufgrund starker linearer Korrelation (r = 0.96) entfernt. Das gruppenübergreifende Feature `torque_times_bleed = sensor_14_NRc_corrected_core_speed * sensor_17_htBleed_bleed_enthalpy` verstärkt Zustände mit gleichzeitiger mechanischer und thermischer Belastung, wie sie bei ineffizientem Betrieb auftreten.\n",
    "\n",
    "##### Gruppe D: Konstant / verrauscht\n",
    "\n",
    "`sensor_6_P15_bypass_pres` wurde ausgeschlossen, da er über alle Units konstant bzw. stark verrauscht war und keinen Beitrag zur Zustandsdiagnose liefert.\n",
    "\n",
    "##### Skalierung und Zeitnormalisierung\n",
    "\n",
    "Alle Merkmale wurden anschliessend mithilfe von `standardize_by_op_cond()` standardisiert. Obwohl im Szenario **FD001** nur eine einzige Betriebsbedingung (`op_cond`-Gruppe) vorliegt, wurde die Funktion trotzdem verwendet, um ein konsistentes Vorgehen über alle Datensätze hinweg sicherzustellen. In diesem Fall entspricht die Skalierung einer **globalen Standardisierung** über alle Datenpunkte hinweg. Dies stellt sicher, dass alle Sensorwerte **dimensionslos und vergleichbar** sind, und verhindert, dass einzelne Sensoren aufgrund unterschiedlicher Wertebereiche **unverhältnismässig stark** ins Modell eingehen.\n",
    "\n",
    "Zur Verbesserung der zeitlichen Einordnung wurde zudem die **Zykluszeit pro Unit auf den Bereich [0, 1] normiert** (`groupby(\"unit\")[\"time\"] / max`), um **Trends über den Lebensverlauf** unabhängig von der absoluten Lebensdauer sichtbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01_fe = fe.add_combined_features(df_train_01_fe, dataset_name=\"FD001\")\n",
    "df_test_01_fe = fe.add_combined_features(df_test_01_fe, dataset_name=\"FD001\")\n",
    "\n",
    "df_train_01_fe, df_test_01_fe = util.standardize_by_op_cond(df_train_01_fe, df_test_01_fe)\n",
    "\n",
    "df_train_01_fe[\"time\"] = df_train_01_fe.groupby(\"unit\")[\"time\"].transform(lambda x: x / x.max())\n",
    "df_test_01_fe[\"time\"] = df_test_01_fe.groupby(\"unit\")[\"time\"].transform(lambda x: x / x.max())\n",
    "\n",
    "df_train_01_fe = fe.select_columns(df_train_01_fe, [4, 11, 12, 14, 17], include_opsettings = False, dataset_name=\"FD001\")\n",
    "df_test_01_fe = fe.select_columns(df_test_01_fe, [4, 11, 12, 14, 17], include_opsettings = False, dataset_name=\"FD001\")\n",
    "\n",
    "df_train_01_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduktion nach Analyse\n",
    "drop_cols = [\n",
    "    \"sensor_14_NRc_corrected_core_speed\",\n",
    "    \"rpm_diff\",\n",
    "    \"temp_to_pressure\",\n",
    "    \"bleed_minus_temp\",\n",
    "    \"torque_ratio\",\n",
    "    \"torque_times_bleed\"\n",
    "]\n",
    "df_train_01_fe.drop(columns=drop_cols, inplace=True)\n",
    "df_test_01_fe.drop(columns=drop_cols, inplace=True)\n",
    "# ---\n",
    "\n",
    "toggle = util.make_toggle_shortcut(df_train_01_fe, \"FD001_FE\")\n",
    "\n",
    "feature_cols = [col for col in df_train_01_fe.columns if col not in [\"unit\", \"time\", \"RUL\"]]\n",
    "\n",
    "sensors_plots = [\n",
    "    toggle(\"Korrelation\", lambda df: eda.plot_sensor_correlation_matrix(df, sensor_cols=feature_cols, dataset_name=\"FD001_FE\", annot=True)),\n",
    "    toggle(\"Verteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=feature_cols),\n",
    "    toggle(\"Trend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=feature_cols),\n",
    "    toggle(\"RUL-Korrelation\", eda.plot_sensor_rul_correlation, sensor_cols=feature_cols),\n",
    "]\n",
    "\n",
    "sections = [\n",
    "    util.make_dropdown_section(sensors_plots, \"FD001_FE\", use_cache=False),\n",
    "]\n",
    "tab_titles = [\"Featureanalyse (FE)\"]\n",
    "\n",
    "eda_panel_FD001_FE = util.make_lazy_panel_with_tabs(\n",
    "    sections,\n",
    "    tab_titles=tab_titles,\n",
    "    open_btn_text=\"FD001_FE öffnen\",\n",
    "    close_btn_text=\"Schliessen\"\n",
    ")\n",
    "display(eda_panel_FD001_FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reduktion nach Feature-Analyse\n",
    "\n",
    "Nach der initialen Auswahl physikalisch sinnvoller und korrelierter Sensoren sowie der Berechnung mehrerer kombinierter Features wurde eine gezielte Reduktion der Featuremenge durchgeführt. Grundlage bildeten die normierten Zeitverläufe, Verteilungen nach Lebensdauer, Korrelationsmatrix sowie die Korrelation mit der Zielgrösse (RUL).\n",
    "\n",
    "Folgende ursprünglich gewählte Merkmale wurden entfernt:\n",
    "\n",
    "- `sensor_14_NRc_corrected_core_speed`, `torque_ratio`, `torque_times_bleed`: Zeigten entweder hohe Varianz im späteren Verlauf oder starke Korrelation untereinander bzw. mit bestehenden thermischen Merkmalen.\n",
    "- `rpm_diff`, `temp_to_pressure`, `bleed_minus_temp`: Keine klaren Trends oder geringe Streuung, ohne nennenswerte Korrelation zur RUL.\n",
    "\n",
    "Die finale Featuremenge enthält somit nur Merkmale mit stabilen zeitlichen Trends, guter Trennschärfe in der Lebensdauerverteilung und möglichst geringer Redundanz.\n",
    "\n",
    "**Verwendete Sensoren:**\n",
    "\n",
    "- **Direkt:** `sensor_4`, `sensor_11`, `sensor_12`, `sensor_17`  \n",
    "- **Indirekt über kombinierte Features:** `sensor_15`, `sensor_20`, `sensor_21`\n",
    "\n",
    "Die Gruppe C Mechanische Belastung wurde ausgeschlossen da die Sensoren `sensor_14` und `sensor_9` teils starke Varianz oder starke Redundanz zu bereits verwendeten thermischen Merkmalen zeigten. Trotz mehrerer getesteter Kombinationen (z. B. Verhältnis-, Differenz- und Log-Features) konnten keine robusten, verlässlich prädiktiven Trends identifiziert werden. Daher wurde Gruppe C in der finalen Featureauswahl nicht berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Erweiterung durch temporale Fenstermerkmale\n",
    "\n",
    "Um dynamische Informationen über den Degradationsverlauf zu erfassen, wurde die ursprüngliche Featuremenge mithilfe der Funktion `extract_temporal_features()` um aggregierte Merkmale aus mehreren Zeitfenstern erweitert. Für jeden Triebwerkslauf wurden um normierte Zeitpunkte (25 %, 50 %, 75 %) herum statistische Kennzahlen wie **Mittelwert, Standardabweichung, Min, Max, Range**, **lineare Regressionsslope und R²** sowie die **Mittelwertdifferenz** zwischen dem frühen und dem späten Bereich im Fenster berechnet. Dabei entspricht der frühe Bereich den **ersten 30 %** und der späte Bereich den **letzten 30 %** der Werte im jeweiligen Zeitfenster.\n",
    "\n",
    "Das verwendete Fenster betrug jeweils **± 0.25 um den jeweiligen Zeitpunkt**, sodass **alle Sensorwerte pro Unit** in mindestens ein Fenster einflossen. Damit spiegeln die extrahierten Merkmale nicht nur lokale, sondern auch übergreifende Verläufe der Sensorzeitreihen wider.\n",
    "\n",
    "Beim Testdatensatz kam eine angepasste Version (`extract_temporal_features_test()`) zum Einsatz. Dabei wurde pro Unit ein **einziges Zeitfenster um den letzten bekannten Zeitpunkt** (normierte Zeit = 1.0) betrachtet. Innerhalb dieses Fensters wurden **alle verfügbaren Sensorwerte ausgewertet**, um die aggregierten Merkmale zu berechnen. Die dabei entstehende Zielvariable (`RUL`) wurde anschliessend durch die **originalen Labelwerte** ersetzt, um eine faire Evaluation sicherzustellen und **Data-Leakage** zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01_fe = fe.extract_temporal_features(df_train_01_fe)\n",
    "df_test_01_fe = fe.extract_temporal_features_test(df_test_01_fe)\n",
    "\n",
    "df_train_01_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection\n",
    "Nach dem vollständigen Feature Engineering erfolgt nun die gezielte Reduktion der Merkmale mittels RandomForest-basierter Feature Selection. Ziel ist es, Merkmale mit sehr geringer Prädiktionsrelevanz zu identifizieren und zu entfernen, um Overfitting zu vermeiden und die Modellkomplexität zu reduzieren.\n",
    "\n",
    "Dazu wird ein RandomForestRegressor auf den Trainingsdaten trainiert und die Feature-Wichtigkeiten (feature_importances_) berechnet. Alle Merkmale mit einer Wichtigkeit unterhalb eines definierten Schwellenwerts (< 0.005) werden verworfen.\n",
    "\n",
    "Die wichtigsten Merkmale stammen überwiegend aus **temporalen Trendanalysen**, insbesondere aus Zeitreihenmerkmalen wie **Steigung (`slope`)**, **Regressionsgüte (`r²`)** und **Mittelwertunterschied (`mean_diff`)**. Dominant sind die Temperatur am LPT-Ausgang (`sensor_4_T50`) sowie kombinierte Effizienzkennzahlen wie `phi_to_bpr` und `coolant_mean`.  \n",
    "\n",
    "Diese Features spiegeln **deutliche zeitliche Veränderungen** im Systemzustand wider und sind daher besonders gut geeignet, den Verschleissverlauf und die verbleibende Lebensdauer vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Vorbereitung der Daten ===\n",
    "X_train = df_train_01_fe.drop(columns=[\"unit\", \"time_point\", \"RUL\"])\n",
    "y_train = df_train_01_fe[\"RUL\"]\n",
    "X_test = df_test_01_fe.drop(columns=[\"unit\", \"time_point\", \"RUL\"])\n",
    "y_test = df_test_01_fe[\"RUL\"]\n",
    "\n",
    "# Feature Selection durchführen\n",
    "X_train, X_test, imp_df, drop_cols = fe.select_features(X_train, y_train, X_test)\n",
    "\n",
    "# Top-10 Features anzeigen\n",
    "imp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Modellierung\n",
    "\n",
    "In diesem Schritt werden verschiedene Regressionsmodelle trainiert, um die verbleibende Nutzungsdauer (RUL) auf Basis der zuvor selektierten Features vorherzusagen. Ziel ist es, die leistungsfähigsten Modelle anhand praxisnaher Fehlerkennzahlen zu bewerten und das beste Modell für die weitere Verwendung auszuwählen.\n",
    "\n",
    "##### Baseline-Modell\n",
    "\n",
    "**Verwendete Bewertungsmetriken:**\n",
    "- **RMSE (Root Mean Squared Error):** Durchschnittlicher quadratischer Fehler – misst die allgemeine Abweichung zwischen Vorhersage und Wahrheit.\n",
    "- **R² (Bestimmtheitsmass):** Erklärt, wie viel Varianz der Zielvariable durch das Modell erklärt wird.\n",
    "- **NASA-Score:** Eine speziell für RUL-Probleme entwickelte Metrik, die Fehler **asymmetrisch und exponentiell** bestraft.\n",
    "  \n",
    "Der NASA-Score wurde speziell für Remaining-Useful-Life-Prognosen entwickelt und berücksichtigt die unterschiedliche Schwere von Vorhersagefehlern:\n",
    "\n",
    "- **Überschätzungen der RUL** (Modell zu optimistisch) werden **stark bestraft**, da sie in der Praxis zu unerwarteten Ausfällen führen können.  \n",
    "- **Unterschätzungen** (Modell zu vorsichtig) sind weniger kritisch und werden entsprechend **milder bestraft**.\n",
    "\n",
    "Die Strafe erfolgt exponentiell – mit unterschiedlicher Basis:\n",
    "\n",
    "$$\n",
    "\\text{NASA-Score} =\n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^{n} e^{- \\frac{\\hat{y}_i - y_i}{13}} - 1, & \\text{falls } \\hat{y}_i - y_i < 0 \\\\\n",
    "\\sum_{i=1}^{n} e^{\\frac{\\hat{y}_i - y_i}{10}} - 1, & \\text{sonst}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dabei ist $(\\hat{y}_i) $ die vorhergesagte RUL und $(y_i)$ der wahre Wert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellliste\n",
    "models_list = models.get_model_list(weighted=False)\n",
    "\n",
    "# Evaluation\n",
    "results = []\n",
    "for name, model in models_list:\n",
    "    results.append(models.evaluate_model(model, X_train, y_train, X_test, y_test, model_name=name))\n",
    "models_df = pd.DataFrame(results).sort_values(\"NASA-Score\")\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.plot_model_scores(\n",
    "    models_df,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: (Scores bis 2000 begrenzt)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich:**  \n",
    "Die Abbildung zeigt den NASA-Score verschiedener Regressionsmodelle bei der Vorhersage der verbleibenden Nutzungsdauer (RUL). Je niedriger der Score, desto besser ist das Modell in Bezug auf sichere, realistische Vorhersagen.\n",
    "\n",
    "- **Random Forest** erzielt den besten Score, gefolgt von **Gradient Boosting** und **Ridge**.  \n",
    "- **Lineare Modelle** wie `Linear Regression` schneiden deutlich schlechter ab als regulierte Varianten.  \n",
    "- Modelle wie `ElasticNet`, `Lasso`, `Decision Tree` und `KNN` erreichen den maximalen Score (2000) und gelten als ungeeignet für dieses Szenario.  \n",
    "- Besonders **SVR** fällt durch seinen relativ hohen Fehler auf, obwohl es in anderen Kontexten oft gut performt.\n",
    "\n",
    "Die starken Unterschiede zeigen, dass einfache lineare oder nicht regulierte Modelle den komplexen Degradationsverlauf nicht adäquat abbilden können. Ensembles wie Random Forest sind hier deutlich robuster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestes Modell ungewichtet\n",
    "best_model_name = models_df.iloc[0][\"Model\"]\n",
    "model_map = {name: model for name, model in models_list}\n",
    "best_model = model_map[best_model_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Plot\n",
    "models.plot_prediction_and_residuals(y_test, y_pred, model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der rechte Residuenplot zeigt, dass das Modell bei **niedriger RUL tendenziell zur Überschätzung** neigt – es prognostiziert also eine längere verbleibende Lebensdauer als tatsächlich vorhanden ist. Umgekehrt tritt bei hoher RUL häufig eine leichte Unterschätzung auf. Diese Tendenz ist insbesondere in späten Lebensphasen kritisch, da **Überschätzungen kurz vor dem Ausfall** das Risiko ungeplanter Stillstände deutlich erhöhen.\n",
    "\n",
    "Der verwendete **NASA-Score berücksichtigt diese Asymmetrie** explizit, indem er Überschätzungen deutlich stärker bestraft als Unterschätzungen. Um diesem Umstand gezielt Rechnung zu tragen, wird im nächsten Schritt eine **gewichtete Modellbewertung** eingeführt:  \n",
    "Beobachtungen mit geringer RUL erhalten ein höheres Gewicht, sodass das Modell stärker auf präzise Vorhersagen in sicherheitskritischen Phasen optimiert wird. Die Gewichtsfunktion nimmt dabei exponentiell mit der RUL ab:\n",
    "\n",
    "$$\n",
    "w(\\text{RUL}) = 1 + 2 \\cdot e^{- \\frac{\\text{RUL}}{25}}\n",
    "$$\n",
    "\n",
    "Die Parameter wurden so gewählt, dass die Gewichtung insbesondere im Bereich bis etwa **125 Zyklen** wirkt – also genau dort, wo im Residuenplot eine systematische Überschätzung auftritt. Damit erhalten Einheiten mit geringer Restlebensdauer ein bis zu dreifach höheres Gewicht. Die folgende Grafik visualisiert den Funktionsverlauf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gewichtsfunktion definieren\n",
    "rul_vals = np.linspace(0, 125, 200)\n",
    "weights = 1 + 2 * np.exp(-rul_vals / 25)\n",
    "\n",
    "plt.plot(rul_vals, weights)\n",
    "plt.xlabel(\"RUL\")\n",
    "plt.ylabel(\"Gewicht\")\n",
    "plt.title(\"Gewichtsfunktion in Abhängigkeit vom RUL\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gewichtete Modelle\n",
    "weighted_models = models.get_model_list(weighted=True)\n",
    "results_weighted = []\n",
    "for name, model in weighted_models:\n",
    "    results_weighted.append(models.evaluate_model_weighted(model, X_train, y_train, X_test, y_test, model_name=name))\n",
    "models_df_weighted = pd.DataFrame(results_weighted)\n",
    "\n",
    "# Kombinieren\n",
    "models_df_combined = pd.concat([models_df, models_df_weighted]).sort_values(\"NASA-Score\").reset_index(drop=True)\n",
    "models_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellvergleichsplot\n",
    "models.plot_model_scores(\n",
    "    models_df,\n",
    "    models_df_weighted,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach Gewichtung (Scores bis 2000 begrenzt)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich vor und nach Gewichtung:**\n",
    "\n",
    "Die Abbildung zeigt den Vergleich der NASA-Scores für jedes Modell – jeweils **vor (schraffiert)** und **nach (vollflächig)** Anwendung der Gewichtung. Ziel war es, Überschätzungen bei niedriger RUL stärker zu bestrafen und so das Modellverhalten in sicherheitskritischen Phasen gezielter zu verbessern.\n",
    "\n",
    "- Bei fast allen Modellen verbessert sich der Score leicht bis deutlich. Besonders ausgeprägt ist der Effekt bei **Linear Regression**, **Gradient Boosting** und **Ridge**.\n",
    "- Bei **Random Forest** ist die Verbesserung zwar gering, aber vorhanden – das Modell war bereits ungewichtet sehr gut.\n",
    "- Bei **ElasticNet** und **Lasso** bringt die Gewichtung zwar einen Fortschritt, allerdings verbleiben sie weiterhin im nicht praktikablen Bereich.\n",
    "- **Decision Trees** bleiben unabhängig von der Gewichtung ungeeignet.\n",
    "\n",
    "Insgesamt zeigt sich, dass eine gezielte Gewichtung der Trainingsdaten — abgestimmt auf die Schwere der Vorhersagefehler — zu einer robusteren Modellleistung führen kann, insbesondere bei Modellen, die empfindlich auf fehlerverteilte Daten reagieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = models_df_combined.iloc[0]\n",
    "best_model_name = best[\"Model\"]\n",
    "base_name = best_model_name.replace(\" (weighted)\", \"\")\n",
    "model_map_all = {**{name: model for name, model in weighted_models}, **{f\"{name} (weighted)\": model for name, model in weighted_models}}\n",
    "best_model = model_map_all[best_model_name if best_model_name in model_map_all else base_name]\n",
    "\n",
    "# Trainieren\n",
    "if best_model_name.endswith(\"(weighted)\"):\n",
    "    weights = 1 + 2 * np.exp(-y_train / 25)\n",
    "    best_model.fit(X_train, y_train, sample_weight=weights)\n",
    "else:\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage + Plot\n",
    "y_pred = best_model.predict(X_test)\n",
    "models.plot_prediction_and_residuals(y_test, y_pred, model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse des gewichteten Random Forest:**\n",
    "\n",
    "Im Vergleich zur ungewichteten Variante zeigt der gewichtete Random Forest eine **verbesserte Modellanpassung in den kritischen RUL-Bereichen**. In der linken Grafik („Vorhersage vs. Wahrheit“) sind weniger starke Überschätzungen bei niedriger RUL sichtbar, was auf eine gezieltere Fehlerkontrolle in späten Lebensphasen hinweist.\n",
    "\n",
    "Auch im Residuenplot (rechts) ist eine **leichte Zentrierung der Residuen im Bereich niedriger RUL** erkennbar. Die systematische Tendenz zur Überschätzung wurde abgemildert. Bei höherer RUL bleibt die Streuung vergleichbar zur ungewichteten Variante – hier hat die Gewichtung kaum Einfluss, was gewünscht ist.\n",
    "\n",
    "Insgesamt bestätigt sich, dass die eingeführte Gewichtung ihre Wirkung entfaltet: **Fehler bei niedriger RUL – die im NASA-Score stark bestraft werden – wurden gezielt reduziert**, ohne das Verhalten in stabilen Bereichen negativ zu beeinflussen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Hyperparameter-Tuning\n",
    "\n",
    "Nachdem die Modelle im vorherigen Schritt mit Standardparametern trainiert und bewertet wurden, erfolgt nun eine gezielte Optimierung der Hyperparameter in zwei aufeinander aufbauenden Stufen.\n",
    "\n",
    "**Stufe 1 – Grobe Raster-Suche (GridSearch):**  \n",
    "Zunächst wird für alle Modelle ein sinnvoller Parameterraum definiert und mittels `GridSearchCV` nach einer geeigneten Modellkonfiguration gesucht. Als Bewertungsmetrik kommt erneut der NASA-Score zum Einsatz. Diese erste Phase dient dazu, eine solide Ausgangsbasis zu schaffen und bereits klare Fehlkonfigurationen auszusortieren.\n",
    "\n",
    "**Stufe 2 – Feinjustierung (RandomizedSearch):**  \n",
    "Für eine Auswahl der vielversprechendsten Modelle aus der GridSearch wird im Anschluss eine umfassendere Feinabstimmung mit `RandomizedSearchCV` durchgeführt. Dabei werden grössere, kontinuierliche Hyperraumverteilungen verwendet, um durch stichprobenartige Suche bessere Parameterkombinationen zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Scorer vorbereiten ===\n",
    "nasa_scorer = models.nasa_scorer\n",
    "\n",
    "# === Modelle und GridSearch-Suchräume definieren ===\n",
    "model_defs = [\n",
    "    (\"Linear Regression\", LinearRegression(), True),\n",
    "    (\"Ridge\", Ridge(), True),\n",
    "    (\"Lasso\", Lasso(), True),\n",
    "    (\"ElasticNet\", ElasticNet(), True),\n",
    "    (\"KNN\", KNeighborsRegressor(), False),\n",
    "    (\"SVR\", SVR(), False),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor(), True),\n",
    "    (\"Random Forest\", RandomForestRegressor(), True),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor(), True),\n",
    "]\n",
    "\n",
    "param_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Ridge\": {\"alpha\": [0.1, 1.0, 10.0]},\n",
    "    \"Lasso\": {\"alpha\": [0.001, 0.01, 0.1]},\n",
    "    \"ElasticNet\": {\"alpha\": [0.01, 0.1], \"l1_ratio\": [0.2, 0.5, 0.8]},\n",
    "    \"KNN\": {\"n_neighbors\": [3, 5, 7]},\n",
    "    \"SVR\": {\"C\": [1, 10], \"epsilon\": [0.1, 0.5]},\n",
    "    \"Decision Tree\": {\"max_depth\": [4, 6, 10], \"min_samples_leaf\": [5, 10]},\n",
    "    \"Random Forest\": {\"n_estimators\": [50, 100], \"max_depth\": [6, 10]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [50, 100], \"learning_rate\": [0.05, 0.1]},\n",
    "}\n",
    "\n",
    "# === GridSearchCV (erste HPT)\n",
    "df_hpt_grid = models.run_grid_search(X_train, y_train, X_test, y_test, model_defs, param_grids)\n",
    "df_hpt_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add = models_df[models_df[\"Model\"].isin([\"SVR\", \"KNN\"])]\n",
    "models_df_vor = pd.concat([models_df_weighted, rows_to_add], ignore_index=True)\n",
    "models.plot_model_scores(\n",
    "    models_df_vor,\n",
    "    df_hpt_grid,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach HPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich vor und nach erstem Hyperparameter-Tuning (HPT):**\n",
    "\n",
    "Die Abbildung zeigt die Auswirkungen des Hyperparameter-Tunings (HPT) auf den NASA-Score der Modelle. Verglichen wird die Modellleistung **vor dem Tuning (schraffiert)** mit der Leistung **nach dem Tuning (vollflächig)**.\n",
    "\n",
    "- Bei den meisten Modellen konnte der Score durch HPT weiter reduziert werden, insbesondere bei **Lasso**, **ElasticNet**, **Decision Tree** und **SVR**, die vorher relativ schlecht abschnitten.\n",
    "- **Random Forest** und **Gradient Boosting** profitieren hingegen kaum vom HPT, da sie bereits zuvor mit guten Default-Werten arbeiteten.\n",
    "- **KNN** bleibt weiterhin ungeeignet – trotz Tuning werden keine brauchbaren Scores erreicht.\n",
    "\n",
    "Für das erweiterte Hyperparameter-Tuning mittels `RandomizedSearchCV` wurden bewusst nicht nur die leistungsstärksten Modelle ausgewählt, sondern gezielt solche, bei denen noch substantielles Optimierungspotenzial vermutet wurde:\n",
    "\n",
    "- **Random Forest** und **Gradient Boosting** wurden weiter untersucht, da sie bereits starke Resultate liefern und eine Feinjustierung hier zusätzliche Leistungsgewinne ermöglichen kann.\n",
    "- **Lasso**, **ElasticNet** und **SVR** zeigten in der GridSearch erkennbare Fortschritte und verfügen über komplexe Hyperparameter, deren breitere Variation durch Randomized Search zusätzliche Verbesserungen verspricht.\n",
    "- **Decision Tree** wurde trotz signifikanter Verbesserung nicht weiter optimiert, da sein Beitrag im Vergleich zu den bereits berücksichtigten Ensemble-Methoden (**RF**, **GB**) begrenzt ist.\n",
    "- **Ridge** und **Linear Regression** wurden ausgeschlossen, da sich ihre Performance im GridSearch-Schritt kaum verbessert hat. Im Fall der **Linear Regression** ist zudem **kein Hyperparameter** vorhanden, der überhaupt abgestimmt werden könnte.\n",
    "\n",
    "Die Auswahl zielt darauf ab, **vielfältige Modellfamilien zu vertreten**, dabei jedoch Doppelungen zu vermeiden und Rechenressourcen auf aussichtsreiche Kandidaten zu konzentrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# === Modelle + breite Parameterverteilungen\n",
    "models_with_dists = {\n",
    "    \"Random Forest\": (RandomForestRegressor(), {\n",
    "        \"n_estimators\": randint(100, 500),\n",
    "        \"max_depth\": [6, 10, None],\n",
    "        \"min_samples_leaf\": randint(1, 6),\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "        \"bootstrap\": [True, False]\n",
    "    }),\n",
    "    \"Gradient Boosting\": (GradientBoostingRegressor(), {\n",
    "        \"n_estimators\": randint(100, 500),\n",
    "        \"learning_rate\": uniform(0.01, 0.2),\n",
    "        \"max_depth\": [3, 6, 9],\n",
    "        \"subsample\": uniform(0.6, 0.4),\n",
    "        \"min_samples_leaf\": randint(1, 6)\n",
    "    }),\n",
    "    \"Lasso\": (Lasso(), {\n",
    "        \"alpha\": uniform(0.0001, 0.1)\n",
    "    }),\n",
    "    \"ElasticNet\": (ElasticNet(), {\n",
    "        \"alpha\": uniform(0.001, 0.1),\n",
    "        \"l1_ratio\": uniform(0, 1)\n",
    "    }),\n",
    "    \"SVR\": (SVR(), {\n",
    "        \"C\": uniform(1, 100),\n",
    "        \"epsilon\": uniform(0.01, 1.0),\n",
    "        \"kernel\": [\"rbf\", \"linear\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    })\n",
    "}\n",
    "\n",
    "# === RandomizedSearchCV (zweite HPT)\n",
    "X_train[\"unit\"] = df_train_01_fe[\"unit\"]\n",
    "X_test[\"unit\"] = df_test_01_fe[\"unit\"]\n",
    "\n",
    "df_hpt_rand = models.run_random_search(\n",
    "    X_train.drop(columns=[\"unit\"]),\n",
    "    y_train,\n",
    "    X_test.drop(columns=[\"unit\"]),\n",
    "    y_test,\n",
    "    X_train[\"unit\"],\n",
    "    models_with_dists,\n",
    "    n_iter=500\n",
    ")\n",
    "\n",
    "df_hpt_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Hyperparameter-Spalten aus \"Best Params\" extrahieren\n",
    "df_best_params = models.expand_best_params(df_hpt_rand )\n",
    "df_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpt_grid_red = df_hpt_grid[~df_hpt_grid[\"Model\"].isin([\"Linear Regression\", \"Ridge\", \"Decision Tree\", \"KNN\"])]\n",
    "df_plot = models.select_best_per_model(df_hpt_grid_red, df_hpt_rand)\n",
    "models.plot_model_scores(\n",
    "    df_hpt_grid_red,\n",
    "    df_plot,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: Vorher-Nachher nur für Modelle mit Randomized Search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich: Vorher–Nachher nur für Modelle mit Randomized Search**\n",
    "\n",
    "Die Abbildung zeigt den gezielten Vergleich der Modellperformance **vor und nach dem erweiterten Hyperparameter-Tuning** mittels `RandomizedSearchCV`. Betrachtet wurden nur jene Modelle, die auf Basis der ersten Tuningrunde (GridSearch) als vielversprechend eingestuft wurden.\n",
    "\n",
    "- **ElasticNet** profitiert am deutlichsten vom erweiterten Suchraum und kann seinen NASA-Score signifikant verbessern.\n",
    "- Auch bei **Lasso** zeigt sich ein spürbarer Leistungsgewinn durch präzisere Abstimmung des Regularisierungsparameters.\n",
    "- **Random Forest** und **Gradient Boosting** bleiben stabil – die Default-Parameter lagen bereits nahe am Optimum.\n",
    "- **SVR** zeigt keinerlei Verbesserung – trotz erweitertem Hyperraum bleibt das Modell im Vergleich zur Konkurrenz deutlich zurück.\n",
    "\n",
    "Insgesamt bestätigt sich, dass Randomized Search insbesondere bei **sensiblen, stark hyperparameterabhängigen Modellen** (wie Lasso/ElasticNet) lohnenswert ist, während robuste Modelle wie Random Forest oder Gradient Boosting kaum profitieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Evaluation\n",
    "\n",
    "Nach Abschluss der zweistufigen Hyperparameter-Optimierung folgt nun die abschliessende Bewertung der besten Modellkonfigurationen. Für jedes Modell, das in der Randomized-Search-Phase ein überzeugendes Ergebnis erzielt hat, wird die finale Variante erneut instanziiert, mit gewichteter Verlustfunktion auf den Trainingsdaten trainiert und auf den Testdaten evaluiert.\n",
    "\n",
    "Bewertet wird anhand des **NASA-Scores**, der auch in dieser finalen Phase als zentrales Auswahlkriterium dient.\n",
    "\n",
    "Anschliessend wird das **beste Modell** anhand des minimalen NASA-Scores ausgewählt und dessen Vorhersageverhalten visuell analysiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "y_preds = []\n",
    "models_list = []\n",
    "\n",
    "model_map = {\n",
    "    \"Random Forest\": RandomForestRegressor,\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor,\n",
    "    \"Lasso\": Lasso,\n",
    "    \"ElasticNet\": ElasticNet,\n",
    "    \"SVR\": SVR,\n",
    "}\n",
    "\n",
    "for _, row in df_plot.iterrows():\n",
    "    name = row[\"Model\"]\n",
    "    params = row[\"Best Params\"]\n",
    "    model_cls = model_map[name]\n",
    "\n",
    "    model = model_cls(**params)\n",
    "    eval_result = models.evaluate_model_weighted(model, X_train, y_train, X_test, y_test, model_name=name)\n",
    "\n",
    "    results.append(eval_result)\n",
    "    y_preds.append(model.predict(X_test))\n",
    "    models_list.append(model)\n",
    "\n",
    "df_test_eval = pd.DataFrame(results)\n",
    "best_idx = df_test_eval[\"NASA-Score\"].idxmin()\n",
    "df_test_eval = df_test_eval.loc[[best_idx]].reset_index(drop=True)\n",
    "\n",
    "y_pred_best = y_preds[best_idx]\n",
    "y_test_best = y_test\n",
    "best_model_name = df_test_eval.loc[0, \"Model\"]\n",
    "df_test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.plot_prediction_and_residuals(y_test_best, y_pred_best, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abschliessende Evaluation des besten Modells: Random Forest (weighted)**\n",
    "\n",
    "Das finale Modell, ein **gewichteter Random Forest**, erzielte den besten NASA-Score aller getesteten Modelle:\n",
    "\n",
    "- **RMSE-Test:** 17.79  \n",
    "- **R²-Test:** 0.82  \n",
    "- **NASA-Score:** 470.81\n",
    "\n",
    "Die Vorhersagegrafik (links) zeigt eine gute Übereinstimmung zwischen vorhergesagter und tatsächlicher RUL, insbesondere im mittleren Bereich. Nur in sehr hohen RUL-Bereichen treten kleinere systematische Abweichungen auf, was für dieses Szenario tolerierbar ist.\n",
    "\n",
    "Im **Residuenplot** (rechts) ist die Fehlerverteilung relativ gleichmässig um Null zentriert – ohne starke systematische Verzerrung. Damit erfüllt das Modell nicht nur die Anforderungen an Vorhersagegüte, sondern auch an **robuste Fehlerverteilung** über verschiedene RUL-Bereiche hinweg.\n",
    "\n",
    "Insgesamt lässt sich festhalten:  \n",
    "Der gewichtete Random Forest bildet den komplexen Degradationsverlauf zuverlässig ab und vermeidet gleichzeitig kritische Überschätzungen in späten Lebensphasen – was insbesondere durch den niedrigen NASA-Score bestätigt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fazit zu Kapitel 3.1 – Analyse für FD001**\n",
    "\n",
    "Die Analyse des einfachsten C-MAPSS-Szenarios FD001 hat gezeigt, dass auch unter konstanten Betriebsbedingungen eine präzise RUL-Vorhersage anspruchsvoll bleibt. Durch gezielte Feature-Auswahl, temporale Merkmalsextraktion sowie eine schrittweise Modelloptimierung konnte jedoch ein leistungsfähiges Vorhersagemodell entwickelt werden.\n",
    "\n",
    "Besonders hervorgetan hat sich der **gewichtete Random Forest**, der dank robuster Struktur und Fehlergewichtung sowohl in klassischen Metriken (RMSE, R²) als auch im NASA-Score überzeugte. Die Gewichtung erwies sich dabei als entscheidender Faktor zur Reduktion systematischer Überschätzungen bei niedriger RUL.\n",
    "\n",
    "Damit bildet FD001 eine solide Grundlage, auf der sich die Generalisierbarkeit und Belastbarkeit der entwickelten Pipeline in komplexeren Szenarien (Kapitel 3.2–3.4) überprüfen lässt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 Analyse für FD002\n",
    "\n",
    "Der Datensatz FD002 enthält variable Betriebsbedingungen bei gleichzeitig einem einzigen Degradationsmodus. Im Vergleich zu FD001 ist das Verhalten der Sensoren komplexer, da die Betriebspunkte schwanken.  \n",
    "Die Analyse dieses Szenarios liefert wichtige Erkenntnisse darüber, wie stark sich Sensorwerte durch die Operation Settings beeinflussen lassen und welche Normalisierungen oder Features erforderlich sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Explorative Datenanalyse (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD002:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD002 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_02, \"FD002\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in list(range(1, 18)) + [19, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[244, 112]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=112, dataset_name=\"FD002-112\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD002\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD002 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_02,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD002\",\n",
    "            dbscan_eps = 2.5,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_02[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD002\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD002\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD002\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD002\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD002\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD002\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD002\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD002\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD002 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD002 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD002  \n",
    "Der Datensatz FD002 weist variierende Betriebsbedingungen auf, wobei `op_setting_1` und `op_setting_2` stark schwanken und hoch korreliert sind. Die Triebwerke zeigen erneut eine rechtsschiefe Lebensdauerverteilung mit moderater Streuung.  \n",
    "\n",
    "Die Operation Settings beeinflussen mehrere Sensorverteilungen deutlich, haben aber nur eine geringe direkte Korrelation zur RUL. Die Sensoren sind stark untereinander korreliert, was auf eine hohe Redundanz hinweist. Einzelne Sensoren wie `sensor_14`, `15` und `16` liefern dennoch potenziell prädiktive Informationen.\n",
    "\n",
    "Die t-SNE/DBSCAN-Clusteranalyse identifiziert sieben Lebenszustände:\n",
    "- darunter **Cluster 3** als instabiler Zwischenzustand,  \n",
    "- sowie **Cluster 6** als möglicher finaler Zustand kurz vor Ausfall.\n",
    "\n",
    "Diese Erkenntnisse bilden die Grundlage für das Feature Engineering und die spätere Modellierung. Eine vollständige Detailauswertung befindet sich in **Anhang B.2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 Analyse für FD003\n",
    "FD003 weist konstante Betriebsbedingungen, aber mehrere Degradationsmodi auf. Damit eignet sich der Datensatz gut, um rein sensorbasierte Unterschiede im Degradationsverhalten zu untersuchen, ohne dass sich zusätzlich die Betriebszustände verändern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD003:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD003 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_03, \"FD003\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[99, 55]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=55, dataset_name=\"FD003-55\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD003\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD003 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_03,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD003\",\n",
    "            dbscan_eps = 3,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_03[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD003\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD003\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD003\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD003\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD003\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD003\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD003\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD003\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD003 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD003 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD003  \n",
    "Der Datensatz FD003 enthält konstante Betriebspunkte bei mehreren Triebwerktypen und weist eine hohe Streuung in der Lebensdauer auf. Die Lebensdauerverteilung ist erneut rechtsschief, jedoch mit deutlich grösserer Varianz als bei FD001/FD002.\n",
    "\n",
    "Die Operation Settings bleiben über den gesamten Lebenszyklus konstant und zeigen keinerlei signifikanten Einfluss auf die Sensoren oder die RUL.\n",
    "\n",
    "Die Sensoren zeigen hingegen ausgeprägte Trends und Strukturen. Mehrere Sensoren korrelieren deutlich mit der Lebensdauer, andere besitzen multimodale Verteilungen oder bilden stark korrelierte Gruppen. Diese Merkmale bieten gute Voraussetzungen für Feature Engineering.\n",
    "\n",
    "Die Clusteranalyse mit t-SNE/DBSCAN identifiziert fünf Betriebszustände:  \n",
    "- **Cluster 0** dominiert als stabiler Nominalzustand,  \n",
    "- **Cluster 1, 2 und 4** zeigen unterschiedliche Degradationsphasen,  \n",
    "- **Cluster 3** ist kurzzeitig zu beginn aktiv, instabil und wird als Übergangszustand interpretiert.\n",
    "\n",
    "Diese Struktur liefert eine gute Grundlage für zustandsbasierte Modellierungsansätze. Die vollständige Detailanalyse befindet sich in **Anhang B.3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.4 Analyse für FD004\n",
    "FD004 kombiniert die komplexesten Bedingungen aller C-MAPSS-Datensätze: variable Betriebspunkte und mehrere Degradationsmodi.\n",
    "Dieser Datensatz stellt somit das realistischste, aber auch herausforderndste Szenario dar. Ziel der Analyse ist es, robuste Muster trotz starker Streuung und Rauschen zu identifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.1 Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD004:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD004 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_04, \"FD004\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in range(1, 22)]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[214, 118]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=118, dataset_name=\"FD004-118\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD004\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD004 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_04,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD004\",\n",
    "            dbscan_eps = 3,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_04[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD004\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD004\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD004\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD004\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD004\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD004\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD004\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD004\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD004 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD004 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD004  \n",
    "Der Datensatz FD004 kombiniert mehrere Triebwerkstypen mit stark schwankenden Betriebspunkten und langer Lebensdauer. Die Lebensdauerverteilung ist dabei ebenfalls rechtsschief, mit ähnlich grosser Streuung wie in FD003. Die Operation Settings 1 und 2 variieren stark und beeinflussen viele Sensorverteilungen deutlich, während Setting 3 konstant bleibt und vernachlässigt werden kann.\n",
    "\n",
    "Die Sensorverläufe sind oft verrauscht und zeigen hohe Redundanz, mit wenigen klaren RUL-Trends. Daher ist gezieltes Preprocessing entscheidend.\n",
    "\n",
    "Die t-SNE/DBSCAN-Clusteranalyse liefert eine gut interpretierbare Struktur mit 18 Zuständen:\n",
    "- **Cluster 0–9**: Früh- bzw. Zwischenzustände mit teils instabilen Verläufen,  \n",
    "- **Cluster 10–17**: Klar erkennbare Degradationsphasen am Lebensende.\n",
    "\n",
    "FD004 stellt hohe Anforderungen an Feature Engineering und Modellierung, bietet aber gleichzeitig Potenzial für robuste, zustandsadaptive Modelle. Eine vollständige Detailauswertung befindet sich in **Anhang B.4**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Kombinierte Analyse (FD001–FD004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Explorative Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.4 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Zusammenfassung und Ausblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Ergebnisse im Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.3 Weiterführende Ideen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Anhang A – Erklärung der verwendeten Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Zur besseren Nachvollziehbarkeit der Explorativen Datenanalyse (EDA) werden im Folgenden die wichtigsten Plot-Typen kurz erläutert. Die Beschreibungen beziehen sich nicht auf konkrete Ergebnisse, sondern auf den allgemeinen Zweck und die Lesart der Visualisierungen.\n",
    "\n",
    "### 1. Lebensdauerkennzahlen  \n",
    "**Typ:** Tabellenausgabe + Histogramm  \n",
    "Zentrale Kennzahlen wie Median, Mittelwert, Min/Max und Standardabweichung der Lebensdauer sowie deren Verteilung (z. B. rechtsschief bei Run-to-Failure-Daten).\n",
    "\n",
    "### 2. Verläufe Operation Settings  \n",
    "**Typ:** Liniendiagramme einzelner Units  \n",
    "Visualisiert den zeitlichen Verlauf der Betriebspunkte (`op_setting_1–3`) über den Lebenszyklus. Beurteilt Konstanz oder Variation der Betriebsbedingungen.\n",
    "\n",
    "### 3. Korrelation zu RUL (Settings/Sensoren)  \n",
    "**Typ:** Balkendiagramm  \n",
    "Korrelationskoeffizienten zwischen aktuellen Featurewerten (z. B. im letzten Zyklus) und der Restlebensdauer (RUL). Dient zur Identifikation prädiktiver Merkmale.\n",
    "\n",
    "### 4. Sensorverläufe einzelner Units  \n",
    "**Typ:** Liniendiagramme  \n",
    "Zeigt typische Sensorverläufe über den Lebenszyklus einzelner Triebwerke. Hilft, Trends oder Auffälligkeiten visuell zu erkennen.\n",
    "\n",
    "### 5. Überlagerte Sensortrends  \n",
    "**Typ:** Liniendiagramm mit vielen Kurven  \n",
    "Mehrere Sensorverläufe einer Unit überlagert dargestellt. Dient zur Interpretation von globalen Trends.\n",
    "\n",
    "### 6. Verteilungen (nach Lebensdauer, Cluster, Settings)  \n",
    "**Typ:** Box- und Violinplots  \n",
    "Vergleicht Sensorwerte im letzten Zyklus oder in Lebensdauer-Quantilen – gruppiert nach Cluster oder Betriebspunkt-Kategorie. Zeigt Unterschiede und Streuungen zwischen Gruppen.\n",
    "\n",
    "### 7. Korrelationsmatrizen  \n",
    "**Typ:** Heatmaps  \n",
    "Visualisieren lineare Zusammenhänge zwischen Features (Sensoren/Settings) über den gesamten Datensatz. Unterstützt die Auswahl nicht-redundanter Merkmale.\n",
    "\n",
    "### 8. Trends über normierte Zeit  \n",
    "**Typ:** Liniendiagramm (aggregiert)  \n",
    "Zeigt den mittleren Verlauf eines Features über normierte Zeit (0 = Beginn, 1 = Ausfall). Dient zur Identifikation typischer Degradationstrends.\n",
    "\n",
    "### 9. t-SNE + DBSCAN  \n",
    "**Typ:** 2D-Scatterplot  \n",
    "Dimensionalitätsreduktion und Clustering. Visualisiert unterschiedliche Betriebs- oder Degradationszustände über den gesamten Lebenszyklus hinweg.\n",
    "\n",
    "### 10. Sankey-Diagramm (Clustertransitions)  \n",
    "**Typ:** Flussdiagramm  \n",
    "Zeigt, wie Units im Lebensverlauf von einem Clusterzustand in einen anderen wechseln. Hilft bei der Interpretation typischer Zustandsverläufe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
