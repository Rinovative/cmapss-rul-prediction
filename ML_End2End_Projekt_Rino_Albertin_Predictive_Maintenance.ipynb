{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src import eda, util, fe, models\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# ---- EDA Konfiguration ----\n",
    "# Skalierung aller Sensoren und Operation Settings (Z-Norm pro Betriebsbedingung)\n",
    "NORMALIZE = True\n",
    "\n",
    "EDA_FD001 = True\n",
    "EDA_FD002 = True\n",
    "EDA_FD003 = True\n",
    "EDA_FD004 = True\n",
    "\n",
    "# ---- HPT Konfiguration ----\n",
    "# True: Hyperparameter-Tuning ausführen, False: gespeichertes Modell laden\n",
    "HPT_FD001 = False\n",
    "HPT_FD002 = False\n",
    "HPT_FD003 = False\n",
    "HPT_FD004 = False\n",
    "\n",
    "# ---- Caching-/Recompute-Konfiguration ----\n",
    "PRECOMPUTE_ALL_PLOTS = False        # Alle EDA-Plots bei Notebook-Start berechnen. Widgets reagieren erst nach dem Precompute.\n",
    "FORCE_RECOMPUTE_PLOTS = False       # Alle EDA-Plots beim Precompute immer neu berechnen, auch wenn sie schon im Cache sind.\n",
    "FORCE_RECOMPUTE_TSNE_DBSCAN = False # TSNE/DBSCAN immer neu berechnen\n",
    "\n",
    "if not PRECOMPUTE_ALL_PLOTS:        # Nur gültig, wenn Precompute aktiviert ist!\n",
    "    FORCE_RECOMPUTE_PLOTS = False   \n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; background-color: white; padding: 10px; border-radius: 6px; box-shadow: 0 0 5px rgba(0,0,0,0.2);\">\n",
    "  <tr>\n",
    "    <td>\n",
    "      <h1 style=\"margin-bottom: 0; color: black; font-size: clamp(1.4rem, 2.2vw, 2.2rem);\">\n",
    "        Predictive Maintenance: Vorhersage der Remaining Useful Life (RUL) von Triebwerken des NASA C-MAPSS-Datensatzes\n",
    "      </h1>\n",
    "    </td>\n",
    "    <td align=\"right\">\n",
    "      <img src=\"images/OST_Logo_DE_RGB@2000ppi.png\" alt=\"OST Logo\" width=\"200\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Autor:** Rino Albertin  \n",
    "**Datum:** 6. März 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inhaltsverzeichnis\n",
    "\n",
    "1. Einleitung  \n",
    "   1.1 Zielsetzung  \n",
    "   1.2 Vorgehensweise  \n",
    "\n",
    "2. Überblick über den Datensatz und technische Grundlagen  \n",
    "   2.1 Allgemeine Datenstruktur  \n",
    "   2.2 Operative Einstellungen und Sensorik  \n",
    "\n",
    "3. Einzelanalyse  \n",
    "   3.1 FD001  \n",
    "   3.2 FD002  \n",
    "   3.3 FD003  \n",
    "   3.4 FD004  \n",
    "\n",
    "4. Kombinierte Analyse aller Datensätze  \n",
    "   4.1 Explorative Datenanalyse  \n",
    "   4.2 Feature Engineering  \n",
    "   4.3 Modellierung  \n",
    "   4.4 Hyperparameter-Tuning  \n",
    "   4.5 Evaluation  \n",
    "\n",
    "5. Vergleich der Modellresultate  \n",
    "\n",
    "6. Fazit und Ausblick\n",
    "\n",
    "# Anhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Einleitung\n",
    "\n",
    "Predictive Maintenance ist in der heutigen Industrie von zentraler Bedeutung, um ungeplante Ausfälle zu vermeiden und Wartungskosten zu senken. Die Vorhersage der verbleibenden Nutzungsdauer (Remaining Useful Life, RUL) von Triebwerken ermoeglicht eine optimierte Planung von Wartungsarbeiten und verbessert die Betriebseffizienz.\n",
    "\n",
    "Der NASA (C-MAPSS) Commercial Modular Aero-Propulsion System Simulation-Datensatz bietet simulierte Run-to-Failure-Zeitreihen von Triebwerken der NASA, die Zeit, Betriebsbedingungen, 3 operative Einstellungen und 21 Sensormessungen umfassen. Dies macht ihn zu einer idealen Grundlage, um moderne Machine-Learning-Methoden zur RUL-Vorhersage zu evaluieren und zu vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Zielsetzung\n",
    "\n",
    "Entwicklung eines Machine-Learning-Modells, das auf Basis historischer Sensordaten die RUL von Triebwerken präzise vorhersagen kann. Dabei soll sowohl das Verhalten einzelner Szenarien als auch eine generalisierbare Lösung über alle vier Datensätze hinweg untersucht werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Vorgehensweise\n",
    "\n",
    "Die Bearbeitung erfolgt in zwei aufeinander aufbauenden Phasen:\n",
    "\n",
    "### Phase 1: Einzelanalysen pro Datensatz (FD001–FD004)\n",
    "Jeder der vier C-MAPSS-Datensätze wird separat analysiert, um spezifische Charakteristika und Herausforderungen zu verstehen. Für jeden Datensatz wird dieselbe Pipeline angewendet:\n",
    "\n",
    "1. **Explorative Datenanalyse (EDA):**\n",
    "   - Visualisierung typischer Sensorverläufe.\n",
    "   - Analyse der Datenstruktur und Lebensdauerverläufe.\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Selektion und Transformation relevanter Sensoren.\n",
    "   - Umgang mit korrelierten oder konstanten Features.\n",
    "\n",
    "3. **Modellierung:**\n",
    "   - Auswahl geeigneter Machine-Learning-Modelle.\n",
    "   - Aufbau einer Pipeline (Preprocessing, Training, Inferenz).\n",
    "\n",
    "4. **Hyperparameter-Tuning:**\n",
    "   - Optimierung mit `GridSearchCV` zur groben Parameterauswahl.\n",
    "   - Erweiterte Feinabstimmung vielversprechender Modelle mit `RandomizedSearchCV`.\n",
    "\n",
    "5. **Evaluation:**\n",
    "   - Validierung.\n",
    "   - Vergleich der Szenarien und Modelle.\n",
    "\n",
    "### Phase 2: Kombinierte Analyse (Generalmodell)\n",
    "In Phase 2 werden die vier Datensätze zusammengeführt, um ein Modell zu entwickeln, das über unterschiedliche Szenarien hinweg verallgemeinerbar ist. Die Analyse basiert auf der gleichen Pipeline wie in Phase 1.\n",
    "\n",
    "**Referenzen:**  \n",
    "- NASA C-MAPSS-Datensatz: https://data.nasa.gov/d/ff5v-kuh6, Alternativ verfügbar unter: [Kaggle – NASA Turbofan Jet Engine Data Set](https://www.kaggle.com/datasets/behrad3d/nasa-cmaps)\n",
    "- Machine Learning Unterichtsunterlagen der OST – Ostschweizer Fachhochschule\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Überblick über den Datensatz und technische Grundlagen\n",
    "\n",
    "Bevor mit der eigentlichen Analyse begonnen wird, erfolgt in diesem Kapitel eine technische Einführung in den C-MAPSS-Datensatz. Ziel ist es, ein grundlegendes Verständnis für Struktur, Sensorik und die inhaltlichen Rahmenbedingungen zu schaffen. Eine erste übergreifende EDA bietet zusätzlich einen Einblick in Gemeinsamkeiten und Besonderheiten der vier Szenarien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Allgemeine Datenstruktur\n",
    "\n",
    "Der C-MAPSS-Datensatz (Commercial Modular Aero-Propulsion System Simulation) besteht aus vier Teildatensätzen (FD001–FD004), die unterschiedliche Betriebsszenarien simulieren. Jeder Datensatz enthält Sensormessungen von mehreren Triebwerken über deren gesamte Lebensdauer hinweg (Run-to-Failure).\n",
    "\n",
    "Für jede Zeile sind folgende Informationen verfügbar:\n",
    "\n",
    "- **unit**: ID des Triebwerks (eine Einheit)\n",
    "- **time**: aktueller Zyklus (Zeitpunkt)\n",
    "- **op_setting_1–3**: operative Einstellungen (Flughöhe, Machzahl, Drosselklappen-Positionen)\n",
    "- **sensor_1–21**: Sensormessungen aus verschiedenen Triebwerkskomponenten\n",
    "\n",
    "![Triebwerksaufbau in C-MAPSS](images/Simplified%20diagram%20of%20engine%20simulated%20in%20C-MAPSS.png)\n",
    "\n",
    "Die Abbildung zeigt den schematischen Aufbau eines Triebwerks, wie es in der C-MAPSS-Simulation verwendet wird. Die Hauptkomponenten sind:\n",
    "\n",
    "- **Fan:** Der Fan (Luftgebläse) saugt Umgebungsluft an, die teilweise in den Bypass strömt (äusserer Luftstrom) und teilweise ins Triebwerk.\n",
    "- **LPC (Low Pressure Compressor):** Komprimiert die angesaugte Luft bei niedrigem Druck.\n",
    "- **HPC (High Pressure Compressor):** Erhöht den Druck der Luft weiter vor der Verbrennung.\n",
    "- **Combustor:** Vermischt die verdichtete Luft mit Treibstoff, zündet die Mischung und erzeugt damit heisse Hochdruckgase.\n",
    "- **HPT (High Pressure Turbine):** Entzieht den heissen Gasen Energie, um den HPC anzutreiben.\n",
    "- **LPT (Low Pressure Turbine):** Treibt den Fan und die LPC an.\n",
    "- **N1/N2:** Repräsentieren die beiden Hauptwellen im Triebwerk (N1: Fan + LPC, N2: HPC + HPT).\n",
    "- **Nozzle:** Düse am Austritt – beschleunigt die Abgasströmung und erzeugt Schub.\n",
    "\n",
    "Viele der 21 Sensoren messen Parameter an genau diesen Stellen, z. B. Druck, Temperatur, Drehzahl oder Luftmassenströme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Operative Einstellungen und Sensorik\n",
    "\n",
    "Die C-MAPSS-Daten umfassen neben Zyklusinformationen auch drei operative Einstellungen und 21 Sensormessungen. Die operativen Einstellungen variieren je nach Szenario und beeinflussen die physikalischen Messgrössen, die an verschiedenen Triebwerkskomponenten aufgezeichnet werden.\n",
    "\n",
    "#### Operative Einstellungen\n",
    "\n",
    "| Spalte         | Beschreibung                         | Wertebereich        |\n",
    "|----------------|--------------------------------------|---------------------|\n",
    "| op_setting_1   | Flughöhe (Altitude)                  | 0 – 42'000 ft       |\n",
    "| op_setting_2   | Machzahl                             | 0 – 0.84            |\n",
    "| op_setting_3   | Throttle Resolver Angle (TRA)        | 20 – 100            |\n",
    "\n",
    "#### Sensorübersicht\n",
    "\n",
    "| Sensor | Beschreibung                             | Wertebereich (FD001–FD004) |\n",
    "|--------|------------------------------------------|----------------------------|\n",
    "|  1     | Total temperature at fan inlet (T2)      | 445.0 – 518.67 °R          |\n",
    "|  2     | Total temperature at LPC outlet (T24)    | 535.48 – 645.11 °R         |\n",
    "|  3     | Total temperature at HPC outlet (T30)    | 1242.67 – 1616.91 °R       |\n",
    "|  4     | Total temperature at LPT outlet (T50)    | 1023.77 – 1441.49 °R       |\n",
    "|  5     | Pressure at fan inlet (P2)               | 3.91 – 14.62 psia          |\n",
    "|  6     | Bypass-duct pressure (P15)               | 5.67 – 21.61 psia          |\n",
    "|  7     | Total pressure at HPC outlet (P30)       | 136.17 – 570.81 psia       |\n",
    "|  8     | Physical fan speed (Nf)                  | 1914.72 – 2388.64 rpm      |\n",
    "|  9     | Physical core speed (Nc)                 | 7984.51 – 9244.59 rpm      |\n",
    "| 10     | Engine pressure ratio (epr)              | 0.93 – 1.32                |\n",
    "| 11     | Static pressure at HPC outlet (Ps30)     | 36.04 – 48.53 psia         |\n",
    "| 12     | Ratio of fuel flow to Ps30 (phi)         | 128.31 – 537.49 pps/psi    |\n",
    "| 13     | Corrected fan speed (NRf)                | 2027.57 – 2390.49 rpm      |\n",
    "| 14     | Corrected core speed (NRc)               | 7845.78 – 8293.72 rpm      |\n",
    "| 15     | Bypass ratio (BPR)                       | 8.1563 – 11.0669           |\n",
    "| 16     | Burner fuel-air ratio (farB)             | 0.02 – 0.03                |\n",
    "| 17     | Bleed enthalpy (htBleed)                 | 302   – 400                |\n",
    "| 18     | Demanded fan speed (Nf_dmd)              | 1915   – 2388 rpm          |\n",
    "| 19     | Demanded corrected fan speed (PCNfR_dmd) | 84.93 – 100.0 rpm          |\n",
    "| 20     | HPT coolant bleed (W31)                  | 10.16 – 39.89 lbm/s        |\n",
    "| 21     | LPT coolant bleed (W32)                  | 6.0105 – 23.9505 lbm/s     |\n",
    "\n",
    "*Die angegebenen Wertebereiche wurden über alle Trainingsdaten der Szenarien FD001 bis FD004 bestimmt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"FD001\": util.load_cmapss_data(\"FD001\"),\n",
    "    \"FD002\": util.load_cmapss_data(\"FD002\"),\n",
    "    \"FD003\": util.load_cmapss_data(\"FD003\"),\n",
    "    \"FD004\": util.load_cmapss_data(\"FD004\"),\n",
    "    \"ALL\":   util.load_cmapss_data()\n",
    "}\n",
    "\n",
    "raw_datasets = {k: (df_train.copy(), df_test.copy()) for k, (df_train, df_test) in datasets.items()}\n",
    "\n",
    "df_train_01, df_test_01 = datasets[\"FD001\"]\n",
    "df_train_02, df_test_02 = datasets[\"FD002\"]\n",
    "df_train_03, df_test_03 = datasets[\"FD003\"]\n",
    "df_train_04, df_test_04 = datasets[\"FD004\"]\n",
    "df_train, df_test = datasets[\"ALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vorverarbeitung – Skalierung nach Betriebs­bedingungen\n",
    "\n",
    "Um Niveauverschiebungen auszublenden, die allein durch wechselnde Flughöhen, Machzahlen oder Drosselklappen-Stellungen entstehen (op_settings), werden alle 21 Sensoren **z-standardisiert – getrennt pro Betriebs­gruppe (`op_cond`)**.\n",
    "\n",
    "Die Gruppierung erfolgt anhand fester Schwellenwerte (siehe Plot unten) in einer **6 × 5 × 2-Einteilung**:\n",
    "\n",
    "| Einstellgrösse    | Binning-Strategie                            | Zweck                           |\n",
    "|-------------------|----------------------------------------------|----------------------------------|\n",
    "| **op_setting 1**  | manuell: `[0 – 5 – 15 – 22 – 30 – 40 – ∞]`    | trennt Flughöhenbereiche        |\n",
    "| **op_setting 2**  | manuell: `[0 – 0.2 – 0.55 – 0.63 – 0.8 – ∞]`  | trennt Geschwindigkeitsbereiche |\n",
    "| **op_setting 3**  | binär: `< 80` → T0, `≥ 80` → T1               | Zweipunkt-Steuerung (TRA)       |\n",
    "\n",
    "Diese Einteilung ergibt **60 theoretisch mögliche Kombinationen** (6 × 5 × 2).  \n",
    "**Tatsächlich kommen aber in jedem Szenario nur genau 6 Gruppen vor** – ein Grossteil der Kombinationen tritt in den Daten nicht auf. Dadurch bleibt die Normalisierung robust und gut interpretierbar.\n",
    "\n",
    "- Der `StandardScaler` wird **ausschliesslich auf den Trainingsdaten** pro `op_cond`-Gruppe fit-transformiert.\n",
    "- Für die zugehörigen Testdaten wird **dieselbe Skalierung** mittels `transform()` übernommen.\n",
    "- Bei **konstanten Betriebspunkten** (z. B. FD001 & FD003) degeneriert das Verfahren zu einer **globalen Standardisierung**, da nur eine einzige `op_cond`-Gruppe existiert.\n",
    "\n",
    "> **Hinweis:** Alle tatsächlich vorkommenden Gruppen enthalten mindestens **5000 Zeilen**, was eine robuste, gruppenbasierte Skalierung erlaubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_op_settings_histograms(df_train_02, df_test_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    for k in datasets:\n",
    "        datasets[k] = util.standardize_by_op_cond(*datasets[k])\n",
    "else:\n",
    "    for k in datasets:\n",
    "        datasets[k] = tuple(util.assign_op_cond_bins(df) for df in datasets[k])\n",
    "\n",
    "df_train_01, df_test_01 = datasets[\"FD001\"]\n",
    "df_train_02, df_test_02 = datasets[\"FD002\"]\n",
    "df_train_03, df_test_03 = datasets[\"FD003\"]\n",
    "df_train_04, df_test_04 = datasets[\"FD004\"]\n",
    "df_train, df_test = datasets[\"ALL\"]\n",
    "\n",
    "print(\"df_train_02:\", util.get_op_cond_distribution_summary(df_train_02), \"\\n\")\n",
    "print(\"df_test_02:\", util.get_op_cond_distribution_summary(df_test_02), \"\\n\")\n",
    "\n",
    "print(\"df_train_04:\", util.get_op_cond_distribution_summary(df_train_04), \"\\n\")\n",
    "print(\"df_test_04:\", util.get_op_cond_distribution_summary(df_test_04), \"\\n\")\n",
    "\n",
    "print(\"df_train:\", util.get_op_cond_distribution_summary(df_train), \"\\n\")\n",
    "print(\"df_test:\", util.get_op_cond_distribution_summary(df_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Einzelanalysen der vier Datensätze\n",
    "\n",
    "Ziel dieses Kapitels ist es, die vier Teildatensätze **FD001 bis FD004** separat zu analysieren und zu modellieren. Jeder Datensatz repräsentiert ein eigenes Betriebsszenario mit unterschiedlichen Rahmenbedingungen (konstante vs. variable Settings, ein oder zwei Degradationsmodi).\n",
    "\n",
    "Für jeden Datensatz wird eine identische Analysepipeline angewendet, bestehend aus:\n",
    "- Explorative Datenanalyse (EDA)\n",
    "- Feature Engineering\n",
    "- Modellierung\n",
    "- Hyperparameter-Tuning\n",
    "- Evaluation\n",
    "\n",
    "Diese Einzelschritte ermöglichen ein besseres Verständnis der Stärken und Schwächen verschiedener Modelle je Szenario und legen die Basis für die spätere kombinierte Analyse in Kapitel 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1 Analyse für FD001\n",
    "Der Datensatz FD001 stellt das einfachste Szenario innerhalb von C-MAPSS dar: konstante Betriebsbedingungen und ein einziger Degradationsmodus. Er eignet sich daher besonders gut für eine erste Modellierung und das Testen von Grundkonzepten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Explorative Datenanalyse (EDA)\n",
    "Ziel dieses Abschnitts ist es, ein erstes Verständnis für die Struktur und Eigenschaften des Datensatzes FD001 zu entwickeln. Dabei werden typische Lebensdauerverläufe analysiert, exemplarische Sensorwerte visualisiert und erste Hinweise auf potenziell relevante Merkmale identifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD001:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD001 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_01, \"FD001\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[39, 69]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=69, dataset_name=\"FD001-69\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD001\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD001 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_01,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD001\",\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_01[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD001\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD001\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD001\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD001\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD001\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD001\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD001\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD001\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD001 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD001 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lebensdauerverteilung:**  \n",
    "Die Lebensdauer der Triebwerke reicht von 128 bis 362 Zyklen (Median: 199). Die Verteilung ist leicht rechtsschief und weist einige Ausreisser mit hoher Zyklenanzahl auf.\n",
    "\n",
    "**Operation Settings:**  \n",
    "Die Betriebsbedingungen sind in diesem Szenario konstant und nur leicht verrauscht. `op_setting_1` und `op_setting_2` zeigen minimale Streuung, während `op_setting_3` konstant bleibt. Die Korrelationen der Settings mit der RUL sind vernachlässigbar (alle < 0.01). Auch innerhalb der Lifetime-Cluster zeigen sich keine signifikanten Unterschiede, weshalb diese Settings nicht zur Modellierung herangezogen werden sollten.\n",
    "\n",
    "**Sensoranalyse:**  \n",
    "Die Sensoren lassen sich in mehrere Gruppen mit stark korrelierten Verläufen einteilen. Konstante Sensoren wurden zuvor entfernt:\n",
    "\n",
    "- **Gruppe A:** `sensor_2`, `3`, `4`, `8`, `11`, `13`, `15`, `17`  \n",
    "- **Gruppe B:** `sensor_7`, `12`, `20`, `21`  \n",
    "- **Gruppe C:** `sensor_9`, `14`  \n",
    "- **Gruppe D:** `sensor_6` – stark verrauscht, nicht informativ\n",
    "\n",
    "Mehrere Sensoren zeigen klare Trends über die Zeit und starke Korrelationen mit der RUL. Sensorverläufe über normierte Zeit zeigen für viele Sensoren monotone, glatte Verläufe. Diese sind potenziell prädiktiv und für Feature Engineering geeignet. Die Verteilungen zeigen teils Unterschiede zwischen Units mit langer und kurzer Lebensdauer, was weitere Segmentierungen rechtfertigt. Die Verteilungen sind meist unimodal im letzen Zyklus und weissen wenig Aussreiser auf. Die Ausreisser wurden dabei nicht entfernt da sie potenziel wichitge Informationen liefern.\n",
    "\n",
    "**Clusteranalyse:**  \n",
    "Ein t-SNE/DBSCAN-Verfahren identifiziert zwei Cluster, wobei der kleinere (Cluster 1) ca. 2 % der Daten umfasst. Er enthält keine finalen Datenpunkte (also keinen Lebensdauer-Endpunkt). Der Eintritt in diesen Cluster erfolgt typischerweise deutlich früher (Ø = 0.255 normierte Zeit) als bei Cluster 0 (Ø = 0.507).\n",
    "\n",
    "Sensorverläufe in Cluster 1 sind stark verrauscht und flach. In Cluster 0 hingegen zeigen sich klar strukturierte Abnahmen bzw. Zunahmen – konsistent mit dem Verschleissverhalten. Daraus ergibt sich:\n",
    "\n",
    "- **Cluster 0**: Hauptcluster mit verwertbaren Mustern und finalen Datenpunkten  \n",
    "- **Cluster 1**: Frühzeitiger Sondercluster ohne verwertbare Zielgrösse (RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Feature Engineering\n",
    "\n",
    "Auf Basis der EDA wurden gezielt Sensoren ausgewählt, die für die Prognose der Restlebensdauer (RUL) eine hohe Aussagekraft besitzen. Die Auswahl erfolgte entlang physikalischer Kriterien, des zeitlichen Signalverlaufs, der Korrelation zur Zielgrösse sowie einer Redundanzanalyse innerhalb stark korrelierter Sensorgruppen. Konstant bleibende oder verrauschte Sensoren wurden entfernt.\n",
    "\n",
    "Zur besseren Übersicht wurden die verbleibenden Sensoren in Gruppen eingeteilt und repräsentative Merkmale extrahiert. Zusätzlich wurden kombinierte Features gebildet, um komplexe physikalische Zusammenhänge wie thermodynamische Effizienz oder mechanische Wechselwirkungen modellierbar zu machen.\n",
    "\n",
    "Um den physikalischen Kontext zu verdeutlichen, wurden im ersten Verarbeitungsschritt alle Sensoren und Betriebsbedingungen in Klartext umbenannt. Ein weiterer Verarbeitungsschritt bestand darin, das Trainingsset gezielt zu kürzen: Bei einem zufälligen Anteil von 25 % der Triebwerks-Units wurde das letzte Segment abgeschnitten, sodass diese Einheiten nicht bis zum vollständigen Ausfall beobachtet wurden. Dadurch wird das Modell gezwungen, auch aus unvollständigen Lebenszyklen zu lernen, was der realen Situation im laufenden Betrieb besser entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df_train_01, df_test_01 = raw_datasets[\"FD001\"]\n",
    "df_train_01_fe = fe.rename_opsettings_and_sensors(df_train_01)\n",
    "df_test_01_fe = fe.rename_opsettings_and_sensors(df_test_01)\n",
    "df_train_01_fe = fe.truncate_train_units(df_train_01_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gruppe A: Temperatur, Druck, Drehzahl & Verhältnisse\n",
    "\n",
    "Verwendet wurden `sensor_4_T50_LPT_outlet_temp`, `sensor_11_Ps30_HPC_static_pres`, `sensor_15_BPR_bypass_ratio` und `sensor_17_htBleed_bleed_enthalpy`, da sie zentrale thermodynamische und aerodynamische Zustände des Triebwerks abbilden. `sensor_4` zeigte die höchste Korrelation mit der RUL und ist physikalisch am sinnvollsten, da er die Temperatur ganz am Ende des Systems misst. Die Sensoren `sensor_2_T24` und `sensor_3_T30` wurden aufgrund starker Redundanz mit `sensor_4` ausgeschlossen. Ergänzend wurden mehrere kombinierte Features eingesetzt: `rpm_diff = sensor_13_NRf_corrected_fan_speed - sensor_8_Nf_fan_speed` dient als robustes Mass für mechanische Abweichungen. `temp_to_pressure = sensor_4_T50_LPT_outlet_temp / sensor_11_Ps30_HPC_static_pres` quantifiziert potenzielle Effizienzverluste bei abweichenden Druckverhältnissen. `bleed_minus_temp = sensor_17_htBleed_bleed_enthalpy - sensor_4_T50_LPT_outlet_temp` identifiziert thermische Ungleichgewichte zwischen Zapfluft und Abgastemperatur, z. B. durch Leckagen.\n",
    "\n",
    "##### Gruppe B: Treibstofffluss & Kühlung\n",
    "\n",
    "Es wurde `sensor_12_phi_fuel_flow_per_Ps30` verwendet, da er die Brennstoffeffizienz relativ zum statischen Druck abbildet. Zusätzlich wurde `coolant_mean = (sensor_20_W31_HPT_coolant_bleed + sensor_21_W32_LPT_coolant_bleed)/2` gebildet, um den thermischen Kühlzustand robuster zu erfassen. Das kombinierte Feature `phi_to_bpr = sensor_12_phi_fuel_flow_per_Ps30 / sensor_15_BPR_bypass_ratio` erlaubt Rückschlüsse auf Effizienzverluste bei untypischer Strömungsverteilung.\n",
    "\n",
    "##### Gruppe C: Mechanische Belastung\n",
    "\n",
    "`sensor_14_NRc_corrected_core_speed` wurde als direkter Indikator für mechanische Belastung ausgewählt. Zusätzlich wurde `torque_ratio = sensor_14_NRc_corrected_core_speed / sensor_9_Nc_core_speed` gebildet, um die Lastverteilung normiert über Betriebspunkte hinweg zu erfassen. `sensor_9_Nc_core_speed` wurde aufgrund starker linearer Korrelation (r = 0.96) entfernt. Das gruppenübergreifende Feature `torque_times_bleed = sensor_14_NRc_corrected_core_speed * sensor_17_htBleed_bleed_enthalpy` verstärkt Zustände mit gleichzeitiger mechanischer und thermischer Belastung, wie sie bei ineffizientem Betrieb auftreten.\n",
    "\n",
    "##### Gruppe D: Konstant / verrauscht\n",
    "\n",
    "`sensor_6_P15_bypass_pres` wurde ausgeschlossen, da er über alle Units konstant bzw. stark verrauscht war und keinen Beitrag zur Zustandsdiagnose liefert.\n",
    "\n",
    "##### Skalierung und Zeitnormalisierung\n",
    "\n",
    "Alle Merkmale wurden anschliessend mithilfe von `standardize_by_op_cond()` standardisiert. Obwohl im Szenario **FD001** nur eine einzige Betriebsbedingung (`op_cond`-Gruppe) vorliegt, wurde die Funktion trotzdem verwendet, um ein konsistentes Vorgehen über alle Datensätze hinweg sicherzustellen. In diesem Fall entspricht die Skalierung einer **globalen Standardisierung** über alle Datenpunkte hinweg. Dies stellt sicher, dass alle Sensorwerte **dimensionslos und vergleichbar** sind, und verhindert, dass einzelne Sensoren aufgrund unterschiedlicher Wertebereiche **unverhältnismässig stark** ins Modell eingehen.\n",
    "\n",
    "Zur Verbesserung der zeitlichen Einordnung wurde zudem die **Zykluszeit pro Unit auf den Bereich [0, 1] normiert** (`groupby(\"unit\")[\"time\"] / max`), um **Trends über den Lebensverlauf** unabhängig von der absoluten Lebensdauer sichtbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01_fe = fe.add_combined_features(df_train_01_fe, dataset_name=\"FD001\")\n",
    "df_test_01_fe = fe.add_combined_features(df_test_01_fe, dataset_name=\"FD001\")\n",
    "\n",
    "df_train_01_fe, df_test_01_fe = util.standardize_by_op_cond(df_train_01_fe, df_test_01_fe)\n",
    "\n",
    "df_train_01_fe[\"time\"] = df_train_01_fe.groupby(\"unit\")[\"time\"].transform(lambda x: x / x.max())\n",
    "df_test_01_fe[\"time\"] = df_test_01_fe.groupby(\"unit\")[\"time\"].transform(lambda x: x / x.max())\n",
    "\n",
    "df_train_01_fe = fe.select_columns(df_train_01_fe, [4, 11, 12, 14, 17], include_opsettings = False, dataset_name=\"FD001\")\n",
    "df_test_01_fe = fe.select_columns(df_test_01_fe, [4, 11, 12, 14, 17], include_opsettings = False, dataset_name=\"FD001\")\n",
    "\n",
    "df_train_01_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduktion nach Analyse\n",
    "drop_cols = [\n",
    "    \"sensor_14_NRc_corrected_core_speed\",\n",
    "    \"rpm_diff\",\n",
    "    \"temp_to_pressure\",\n",
    "    \"bleed_minus_temp\",\n",
    "    \"torque_ratio\",\n",
    "    \"torque_times_bleed\"\n",
    "]\n",
    "df_train_01_fe.drop(columns=drop_cols, inplace=True)\n",
    "df_test_01_fe.drop(columns=drop_cols, inplace=True)\n",
    "# ---\n",
    "\n",
    "toggle = util.make_toggle_shortcut(df_train_01_fe, \"FD001_FE\")\n",
    "\n",
    "feature_cols = [col for col in df_train_01_fe.columns if col not in [\"unit\", \"time\", \"RUL\"]]\n",
    "\n",
    "sensors_plots = [\n",
    "    toggle(\"Korrelation\", lambda df: eda.plot_sensor_correlation_matrix(df, sensor_cols=feature_cols, dataset_name=\"FD001_FE\", annot=True)),\n",
    "    toggle(\"Verteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=feature_cols),\n",
    "    toggle(\"Trend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=feature_cols),\n",
    "    toggle(\"RUL-Korrelation\", eda.plot_sensor_rul_correlation, sensor_cols=feature_cols),\n",
    "]\n",
    "\n",
    "sections = [\n",
    "    util.make_dropdown_section(sensors_plots, \"FD001_FE\", use_cache=False),\n",
    "]\n",
    "tab_titles = [\"Featureanalyse (FE)\"]\n",
    "\n",
    "eda_panel_FD001_FE = util.make_lazy_panel_with_tabs(\n",
    "    sections,\n",
    "    tab_titles=tab_titles,\n",
    "    open_btn_text=\"FD001_FE öffnen\",\n",
    "    close_btn_text=\"Schliessen\"\n",
    ")\n",
    "display(eda_panel_FD001_FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reduktion nach Feature-Analyse\n",
    "\n",
    "Nach der initialen Auswahl physikalisch sinnvoller und korrelierter Sensoren sowie der Berechnung mehrerer kombinierter Features wurde eine gezielte Reduktion der Featuremenge durchgeführt. Grundlage bildeten die normierten Zeitverläufe, Verteilungen nach Lebensdauer, Korrelationsmatrix sowie die Korrelation mit der Zielgrösse (RUL).\n",
    "\n",
    "Folgende ursprünglich gewählte Merkmale wurden entfernt:\n",
    "\n",
    "- `sensor_14_NRc_corrected_core_speed`, `torque_ratio`, `torque_times_bleed`: Zeigten entweder hohe Varianz im späteren Verlauf oder starke Korrelation untereinander bzw. mit bestehenden thermischen Merkmalen.\n",
    "- `rpm_diff`, `temp_to_pressure`, `bleed_minus_temp`: Keine klaren Trends oder geringe Streuung, ohne nennenswerte Korrelation zur RUL.\n",
    "\n",
    "Die finale Featuremenge enthält somit nur Merkmale mit stabilen zeitlichen Trends, guter Trennschärfe in der Lebensdauerverteilung und möglichst geringer Redundanz.\n",
    "\n",
    "**Verwendete Sensoren:**\n",
    "\n",
    "- **Direkt:** `sensor_4`, `sensor_11`, `sensor_12`, `sensor_17`  \n",
    "- **Indirekt über kombinierte Features:** `sensor_15`, `sensor_20`, `sensor_21`\n",
    "\n",
    "Die Gruppe C Mechanische Belastung wurde ausgeschlossen da die Sensoren `sensor_14` und `sensor_9` teils starke Varianz oder starke Redundanz zu bereits verwendeten thermischen Merkmalen zeigten. Trotz mehrerer getesteter Kombinationen (z. B. Verhältnis-, Differenz- und Log-Features) konnten keine robusten, verlässlich prädiktiven Trends identifiziert werden. Daher wurde Gruppe C in der finalen Featureauswahl nicht berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Erweiterung durch temporale Fenstermerkmale\n",
    "\n",
    "Um dynamische Informationen über den Degradationsverlauf zu erfassen, wurde die ursprüngliche Featuremenge mithilfe der Funktion `extract_temporal_features()` um aggregierte Merkmale aus mehreren Zeitfenstern erweitert. Für jeden Triebwerkslauf wurden um normierte Zeitpunkte (25 %, 50 %, 75 %) herum statistische Kennzahlen wie **Mittelwert, Standardabweichung, Min, Max, Range**, **lineare Regressionsslope und R²** sowie die **Mittelwertdifferenz** zwischen dem frühen und dem späten Bereich im Fenster berechnet. Dabei entspricht der frühe Bereich den **ersten 30 %** und der späte Bereich den **letzten 30 %** der Werte im jeweiligen Zeitfenster.\n",
    "\n",
    "Das verwendete Fenster betrug jeweils **± 0.25 um den jeweiligen Zeitpunkt**, sodass **alle Sensorwerte pro Unit** in mindestens ein Fenster einflossen. Damit spiegeln die extrahierten Merkmale nicht nur lokale, sondern auch übergreifende Verläufe der Sensorzeitreihen wider.\n",
    "\n",
    "Beim Testdatensatz kam eine angepasste Version (`extract_temporal_features_test()`) zum Einsatz. Dabei wurde pro Unit ein **einziges Zeitfenster um den letzten bekannten Zeitpunkt** (normierte Zeit = 1.0) betrachtet. Innerhalb dieses Fensters wurden **alle verfügbaren Sensorwerte ausgewertet**, um die aggregierten Merkmale zu berechnen. Die dabei entstehende Zielvariable (`RUL`) wurde anschliessend durch die **originalen Labelwerte** ersetzt, um eine faire Evaluation sicherzustellen und **Data-Leakage** zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01_fe = fe.extract_temporal_features(df_train_01_fe)\n",
    "df_test_01_fe = fe.extract_temporal_features_test(df_test_01_fe)\n",
    "\n",
    "df_train_01_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection\n",
    "Nach dem vollständigen Feature Engineering erfolgt nun die gezielte Reduktion der Merkmale mittels RandomForest-basierter Feature Selection. Ziel ist es, Merkmale mit sehr geringer Prädiktionsrelevanz zu identifizieren und zu entfernen, um Overfitting zu vermeiden und die Modellkomplexität zu reduzieren.\n",
    "\n",
    "Dazu wird ein RandomForestRegressor auf den Trainingsdaten trainiert und die Feature-Wichtigkeiten (feature_importances_) berechnet. Alle Merkmale mit einer Wichtigkeit unterhalb eines definierten Schwellenwerts (< 0.005) werden verworfen.\n",
    "\n",
    "Die wichtigsten Merkmale stammen überwiegend aus **temporalen Trendanalysen**, insbesondere aus Zeitreihenmerkmalen wie **Steigung (`slope`)**, **Regressionsgüte (`r²`)** und **Mittelwertunterschied (`mean_diff`)**. Dominant sind die Temperatur am LPT-Ausgang (`sensor_4_T50`) sowie kombinierte Effizienzkennzahlen wie `phi_to_bpr` und `coolant_mean`.  \n",
    "\n",
    "Diese Features spiegeln **deutliche zeitliche Veränderungen** im Systemzustand wider und sind daher besonders gut geeignet, den Verschleissverlauf und die verbleibende Lebensdauer vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Vorbereitung der Daten ===\n",
    "X_train = df_train_01_fe.drop(columns=[\"unit\", \"time_point\", \"RUL\"])\n",
    "y_train = df_train_01_fe[\"RUL\"]\n",
    "X_test = df_test_01_fe.drop(columns=[\"unit\", \"time_point\", \"RUL\"])\n",
    "y_test = df_test_01_fe[\"RUL\"]\n",
    "\n",
    "# Feature Selection durchführen\n",
    "X_train, X_test, imp_df, drop_cols = fe.select_features(X_train, y_train, X_test)\n",
    "\n",
    "# Top-10 Features anzeigen\n",
    "imp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Modellierung\n",
    "\n",
    "In diesem Schritt werden verschiedene Regressionsmodelle trainiert, um die verbleibende Nutzungsdauer (RUL) auf Basis der zuvor selektierten Features vorherzusagen. Ziel ist es, die leistungsfähigsten Modelle anhand praxisnaher Fehlerkennzahlen zu bewerten und das beste Modell für die weitere Verwendung auszuwählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Baseline-Modell\n",
    "\n",
    "**Verwendete Bewertungsmetriken:**\n",
    "- **RMSE (Root Mean Squared Error):** Durchschnittlicher quadratischer Fehler – misst die allgemeine Abweichung zwischen Vorhersage und Wahrheit.\n",
    "- **R² (Bestimmtheitsmass):** Erklärt, wie viel Varianz der Zielvariable durch das Modell erklärt wird.\n",
    "- **NASA-Score:** Eine speziell für RUL-Probleme entwickelte Metrik, die Fehler **asymmetrisch und exponentiell** bestraft.\n",
    "  \n",
    "Der NASA-Score wurde speziell für Remaining-Useful-Life-Prognosen entwickelt und berücksichtigt die unterschiedliche Schwere von Vorhersagefehlern:\n",
    "\n",
    "- **Überschätzungen der RUL** (Modell zu optimistisch) werden **stark bestraft**, da sie in der Praxis zu unerwarteten Ausfällen führen können.  \n",
    "- **Unterschätzungen** (Modell zu vorsichtig) sind weniger kritisch und werden entsprechend **milder bestraft**.\n",
    "\n",
    "Die Strafe erfolgt exponentiell – mit unterschiedlicher Basis:\n",
    "\n",
    "$$\n",
    "\\text{NASA-Score} =\n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^{n} e^{- \\frac{\\hat{y}_i - y_i}{13}} - 1, & \\text{falls } \\hat{y}_i - y_i < 0 \\\\\n",
    "\\sum_{i=1}^{n} e^{\\frac{\\hat{y}_i - y_i}{10}} - 1, & \\text{sonst}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dabei ist $(\\hat{y}_i) $ die vorhergesagte RUL und $(y_i)$ der wahre Wert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Modellliste mit Angabe, ob sie sample_weight unterstützen ===\n",
    "ALL_MODELS = {\n",
    "    \"Linear Regression\":      (LinearRegression, True),\n",
    "    \"Ridge Regression\":       (Ridge, True),\n",
    "    \"Lasso Regression\":       (Lasso, True),\n",
    "    \"Elastic Net\":            (ElasticNet, True),\n",
    "    \"Decision Tree\":          (DecisionTreeRegressor, True),\n",
    "    \"Random Forest\":          (RandomForestRegressor, True),\n",
    "    \"Gradient Boosting\":      (GradientBoostingRegressor, True),\n",
    "    \"K-Nearest Neighbors\":    (KNeighborsRegressor, False),\n",
    "    \"Support Vector Regr.\":   (SVR, False),\n",
    "}\n",
    "\n",
    "# Einmalige Instanzierung + Gewichtungsinfo für alle Modelle\n",
    "model_defs = [(name, cls(), supports_weights) for name, (cls, supports_weights) in ALL_MODELS.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation aller Modelle ===\n",
    "results = []\n",
    "for name, model, _ in model_defs:\n",
    "    results.append(models.evaluate_model(model, X_train, y_train, X_test, y_test, model_name=name, weighted=False))\n",
    "\n",
    "models_df = pd.DataFrame(results).sort_values(\"NASA-Score\")\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.plot_model_scores(\n",
    "    models_df,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: (Scores bei 2000 begrenzt)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich:**  \n",
    "Die Abbildung zeigt den NASA-Score verschiedener Regressionsmodelle bei der Vorhersage der verbleibenden Nutzungsdauer (RUL). Je niedriger der Score, desto besser ist das Modell in Bezug auf sichere, realistische Vorhersagen.\n",
    "\n",
    "- **Random Forest** erzielt den besten Score, gefolgt von **Gradient Boosting** und **Ridge**.  \n",
    "- Modelle wie **ElasticNet**, **Lasso**, **Decision Tree** und **KNN** erreichen den maximalen Score (2000) und gelten in dieser Form als ungeeignet für dieses Szenario.  \n",
    "\n",
    "In [2] wird für das Ridge-Modell auf demselben Datensatz ein RMSE von 22.64 berichtet. Das hier verwendete Modell erreicht in der Grundkonfiguration einen RMSE von 20.7. Dies deutet darauf hin, dass das eingesetzte Feature Engineering zu einer verbesserten Vorhersagegüte beiträgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Bestes Modell ungewichtet instanziieren, trainieren, vorhersagen ===\n",
    "best_model_name = models_df.iloc[0][\"Model\"]\n",
    "best_model_cls = ALL_MODELS[best_model_name][0]\n",
    "best_model = best_model_cls()\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Plot\n",
    "models.plot_prediction_and_residuals(y_test, y_pred, model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse des Random Forest:**\n",
    "\n",
    "Der rechte Residuenplot zeigt, dass das Modell bei **niedriger RUL tendenziell zur Überschätzung** neigt – es prognostiziert also eine längere verbleibende Lebensdauer als tatsächlich vorhanden ist. Umgekehrt tritt bei hoher RUL häufig eine leichte Unterschätzung auf. Diese Tendenz ist insbesondere in späten Lebensphasen kritisch, da **Überschätzungen kurz vor dem Ausfall** das Risiko ungeplanter Stillstände deutlich erhöhen.\n",
    "\n",
    "**Definition der Gewichtsfunktion**\n",
    "\n",
    "Der verwendete **NASA-Score berücksichtigt diese Asymmetrie** explizit, indem er Überschätzungen deutlich stärker bestraft als Unterschätzungen. Um diesem Umstand gezielt Rechnung zu tragen, wird im nächsten Schritt eine **gewichtete Modellbewertung** eingeführt:  \n",
    "Beobachtungen mit geringer RUL erhalten ein höheres Gewicht, sodass das Modell stärker auf präzise Vorhersagen in sicherheitskritischen Phasen optimiert wird. Die Gewichtsfunktion nimmt dabei exponentiell mit der RUL ab:\n",
    "\n",
    "$$\n",
    "w(\\text{RUL}) = 1 + 2 \\cdot e^{- \\frac{\\text{RUL}}{25}}\n",
    "$$\n",
    "\n",
    "Die Parameter wurden so gewählt, dass die Gewichtung insbesondere im Bereich bis etwa **125 Zyklen** wirkt – also genau dort, wo im Residuenplot eine systematische Überschätzung auftritt. Damit erhalten Einheiten mit geringer Restlebensdauer ein bis zu dreifach höheres Gewicht. Die folgende Grafik visualisiert den Funktionsverlauf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gewichtsfunktion definieren ===\n",
    "rul_vals = np.linspace(0, 125, 200)\n",
    "weights = 1 + 2 * np.exp(-rul_vals / 25)\n",
    "\n",
    "plt.plot(rul_vals, weights)\n",
    "plt.xlabel(\"RUL\")\n",
    "plt.ylabel(\"Gewicht\")\n",
    "plt.title(\"Gewichtsfunktion in Abhängigkeit vom RUL\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gewichtete Modelle evaluieren ===\n",
    "results_weighted = []\n",
    "for name, model, supports_weight in model_defs:\n",
    "    if not supports_weight:\n",
    "        continue\n",
    "    weighted_name = f\"{name} (weighted)\"\n",
    "    results_weighted.append(models.evaluate_model(model, X_train, y_train, X_test,  y_test, model_name=weighted_name, weighted=True))\n",
    "\n",
    "models_df_weighted = pd.DataFrame(results_weighted).sort_values(\"NASA-Score\")\n",
    "\n",
    "# === Kombinieren mit ungewichteten Ergebnissen ===\n",
    "models_df_combined = (pd.concat([models_df, models_df_weighted]).sort_values(\"NASA-Score\").reset_index(drop=True))\n",
    "models_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellvergleichsplot\n",
    "models.plot_model_scores(\n",
    "    models_df,\n",
    "    models_df_weighted,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach Gewichtung (Scores bis 2000 begrenzt)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich vor und nach Gewichtung:**\n",
    "\n",
    "Die Abbildung zeigt den Vergleich der NASA-Scores für jedes Modell – jeweils **vor (schraffiert)** und **nach (vollflächig)** Anwendung der Gewichtung. Ziel war es, Überschätzungen bei niedriger RUL stärker zu bestrafen und so das Modellverhalten in sicherheitskritischen Phasen gezielter zu verbessern.\n",
    "\n",
    "- Bei fast allen Modellen verbessert sich der Score leicht bis deutlich. Besonders ausgeprägt ist der Effekt bei **Linear Regression**, **Gradient Boosting** und **Ridge**.\n",
    "- Bei **Random Forest** ist die Verbesserung zwar gering, aber vorhanden – das Modell war bereits ungewichtet sehr gut.\n",
    "- Bei **ElasticNet** und **Lasso** bringt die Gewichtung zwar einen Fortschritt, allerdings verbleiben sie weiterhin im nicht praktikablen Bereich.\n",
    "- **Decision Trees** bleiben unabhängig von der Gewichtung ungeeignet.\n",
    "\n",
    "Insgesamt zeigt sich, dass eine gezielte Gewichtung der Trainingsdaten — abgestimmt auf die Schwere der Vorhersagefehler — zu einer robusteren Modellleistung führen kann, insbesondere bei Modellen, die empfindlich auf fehlerverteilte Daten reagieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Bestes Modell bestimmen + Instanz erstellen ===\n",
    "best_name = models_df_combined.iloc[0][\"Model\"]\n",
    "base_name = best_name.removesuffix(\" (weighted)\")\n",
    "is_weighted = (best_name != base_name)\n",
    "\n",
    "model_cls, supports_weights = ALL_MODELS[base_name]\n",
    "best_model = model_cls()\n",
    "\n",
    "# === Training (optional mit sample_weight) ===\n",
    "fit_kwargs = {}\n",
    "if is_weighted and supports_weights:\n",
    "    fit_kwargs[\"sample_weight\"] = 1 + 2 * np.exp(-y_train / 25)\n",
    "\n",
    "best_model.fit(X_train, y_train, **fit_kwargs)\n",
    "\n",
    "# === Vorhersage + Plot ===\n",
    "y_pred = best_model.predict(X_test)\n",
    "models.plot_prediction_and_residuals(y_test, y_pred, model_name=best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse des gewichteten Random Forest:**\n",
    "\n",
    "Im Vergleich zur ungewichteten Variante zeigt der gewichtete Random Forest eine **verbesserte Modellanpassung in den kritischen RUL-Bereichen**. In der linken Grafik („Vorhersage vs. Wahrheit“) sind weniger starke Überschätzungen bei niedriger RUL sichtbar, was auf eine gezieltere Fehlerkontrolle in späten Lebensphasen hinweist.\n",
    "\n",
    "Auch im Residuenplot (rechts) ist eine **leichte Zentrierung der Residuen im Bereich niedriger RUL** erkennbar. Die systematische Tendenz zur Überschätzung wurde abgemildert. Bei höherer RUL bleibt die Streuung vergleichbar zur ungewichteten Variante – hier hat die Gewichtung kaum Einfluss, was gewünscht ist.\n",
    "\n",
    "Insgesamt bestätigt sich, dass die eingeführte Gewichtung ihre Wirkung entfaltet: **Fehler bei niedriger RUL – die im NASA-Score stark bestraft werden – wurden gezielt reduziert**, ohne das Verhalten in stabilen Bereichen negativ zu beeinflussen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Hyperparameter-Tuning (HPT)\n",
    "\n",
    "Nachdem die Modelle im vorherigen Schritt mit Standardparametern trainiert und bewertet wurden, erfolgt nun eine gezielte Optimierung der Hyperparameter in zwei aufeinander aufbauenden Stufen.\n",
    "\n",
    "**Stufe 1 – Grobe Raster-Suche (GridSearch):**  \n",
    "Zunächst wird für alle Modelle ein sinnvoller Parameterraum definiert und mittels `GridSearchCV` nach einer geeigneten Modellkonfiguration gesucht. Als Bewertungsmetrik kommt erneut der NASA-Score zum Einsatz. Diese erste Phase dient dazu, eine solide Ausgangsbasis zu schaffen und bereits klare Fehlkonfigurationen auszusortieren.\n",
    "\n",
    "**Stufe 2 – Feinjustierung (RandomizedSearch):**  \n",
    "Für eine Auswahl der vielversprechendsten Modelle aus der GridSearch wird im Anschluss eine umfassendere Feinabstimmung mit `RandomizedSearchCV` durchgeführt. Dabei werden grössere, kontinuierliche Hyperraumverteilungen verwendet, um durch stichprobenartige Suche bessere Parameterkombinationen zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Modelle und GridSearch-Suchräume definieren ===\n",
    "param_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Ridge Regression\": {\"alpha\": [0.1, 1.0, 10.0]},\n",
    "    \"Lasso Regression\": {\"alpha\": [0.001, 0.01, 0.1]},\n",
    "    \"Elastic Net\": {\"alpha\": [0.01, 0.1], \"l1_ratio\": [0.2, 0.5, 0.8]},\n",
    "    \"K-Nearest Neighbors\": {\"n_neighbors\": [3, 5, 7]},\n",
    "    \"Support Vector Regr.\": {\"C\": [1, 10], \"epsilon\": [0.1, 0.5]},\n",
    "    \"Decision Tree\": {\"max_depth\": [4, 6, 10], \"min_samples_leaf\": [5, 10]},\n",
    "    \"Random Forest\": {\"n_estimators\": [50, 100], \"max_depth\": [6, 10]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [50, 100], \"learning_rate\": [0.05, 0.1]},\n",
    "}\n",
    "\n",
    "# === GridSearchCV – erste Stufe des HPT ===\n",
    "df_hpt_grid = models.run_grid_search(\n",
    "    X_train, y_train,\n",
    "    X_test,  y_test,\n",
    "    models=model_defs,\n",
    "    param_grids=param_grids,\n",
    "    model_path=\"models/fd001/best_grid_model.pkl\",\n",
    "    force_run=HPT_FD001      # True => immer neu rechnen\n",
    ")\n",
    "\n",
    "df_hpt_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add = models_df[models_df[\"Model\"].isin([\"Support Vector Regr.\", \"K-Nearest Neighbors\"])]\n",
    "models_df_vor = pd.concat([models_df_weighted, rows_to_add], ignore_index=True)\n",
    "models.plot_model_scores(\n",
    "    models_df_vor,\n",
    "    df_hpt_grid,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach HPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich vor und nach erstem Hyperparameter-Tuning:**\n",
    "\n",
    "Die Abbildung zeigt die Auswirkungen des HPT auf den NASA-Score der Modelle. Verglichen wird die Modellleistung **vor dem Tuning (schraffiert)** mit der Leistung **nach dem Tuning (vollflächig)**.\n",
    "\n",
    "- Bei den meisten Modellen konnte der Score durch HPT weiter reduziert werden, insbesondere bei **Lasso**, **ElasticNet**, **Decision Tree** und **SVR**, die vorher relativ schlecht abschnitten.\n",
    "- **Random Forest** und **Gradient Boosting** profitieren hingegen kaum vom HPT, da sie bereits zuvor mit guten Default-Werten arbeiteten.\n",
    "- **KNN** bleibt weiterhin ungeeignet – trotz Tuning werden keine brauchbaren Scores erreicht.\n",
    "\n",
    "In [2] wird für das Lasso-Modell auf FD001 ein RMSE von 23.86 berichtet. Nach der GridSearch erreicht das hier trainierte Lasso-Modell einen RMSE von 21.4 und liegt somit darunter. Dies deutet darauf hin, dass die Kombination aus selektiven Features und gezieltem Hyperparameter-Tuning zu einer verbesserten Modellgüte beiträgt.\n",
    "\n",
    "Für das erweiterte Hyperparameter-Tuning mittels `RandomizedSearchCV` wurden bewusst nicht nur die leistungsstärksten Modelle ausgewählt, sondern gezielt solche, bei denen noch substantielles Optimierungspotenzial vermutet wurde:\n",
    "\n",
    "- **Random Forest** und **Gradient Boosting** wurden weiter untersucht, da sie bereits starke Resultate liefern und eine Feinjustierung hier zusätzliche Leistungsgewinne ermöglichen kann.\n",
    "- **Lasso**, **ElasticNet** und **SVR** zeigten in der GridSearch erkennbare Fortschritte und verfügen über komplexe Hyperparameter, deren breitere Variation durch Randomized Search zusätzliche Verbesserungen verspricht.\n",
    "- **Decision Tree** wurde trotz signifikanter Verbesserung nicht weiter optimiert, da sein Beitrag im Vergleich zu den bereits berücksichtigten Ensemble-Methoden (**RF**, **GB**) begrenzt ist.\n",
    "- **Ridge** und **Linear Regression** wurden ausgeschlossen, da sich ihre Performance im GridSearch-Schritt kaum verbessert hat. Im Fall der **Linear Regression** ist zudem **kein Hyperparameter** vorhanden, der überhaupt abgestimmt werden könnte.\n",
    "\n",
    "Die Auswahl zielt darauf ab, **vielfältige Modellfamilien zu vertreten**, dabei jedoch Doppelungen zu vermeiden und Rechenressourcen auf aussichtsreiche Kandidaten zu konzentrieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# === Parameterräume ===\n",
    "param_distributions = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": randint(100, 500),\n",
    "        \"max_depth\": [6, 10, None],\n",
    "        \"min_samples_leaf\": randint(1, 6),\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "        \"bootstrap\": [True, False],\n",
    "        \"ccp_alpha\": uniform(0.0, 0.01)\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": randint(100, 500),\n",
    "        \"learning_rate\": uniform(0.01, 0.2),\n",
    "        \"max_depth\": randint(3, 10),\n",
    "        \"subsample\": uniform(0.6, 0.4),\n",
    "        \"min_samples_leaf\": randint(1, 6)\n",
    "    },\n",
    "    \"Lasso Regression\": {\n",
    "        \"alpha\": uniform(0.0001, 0.1)\n",
    "    },\n",
    "    \"Elastic Net\": {\n",
    "        \"alpha\": uniform(0.001, 0.1),\n",
    "        \"l1_ratio\": uniform(0, 1)\n",
    "    },\n",
    "    \"Support Vector Regr.\": {\n",
    "        \"C\": uniform(1, 100),\n",
    "        \"epsilon\": uniform(0.01, 1.0),\n",
    "        \"kernel\": [\"rbf\", \"linear\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Modelle + Parameter + Gewichtbarkeit zusammenführen ===\n",
    "X_train[\"unit\"] = df_train_01_fe[\"unit\"]\n",
    "X_test[\"unit\"] = df_test_01_fe[\"unit\"]\n",
    "\n",
    "# === RandomizedSearch ausführen ===\n",
    "df_hpt_rand = models.run_random_search(\n",
    "    X_train.drop(columns=\"unit\"),\n",
    "    y_train,\n",
    "    X_test.drop(columns=\"unit\"),\n",
    "    y_test,\n",
    "    groups=X_train[\"unit\"],\n",
    "    models=model_defs,\n",
    "    param_distributions=param_distributions,\n",
    "    n_splits=3,\n",
    "    n_iter=5000,\n",
    "    model_path=\"models/fd001/best_rand_model.pkl\",\n",
    "    force_run=HPT_FD001      # True ⇒ neu rechnen\n",
    ")\n",
    "\n",
    "df_hpt_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Hyperparameter-Spalten aus \"Best Params\" extrahieren\n",
    "df_best_params = models.expand_best_params(df_hpt_rand)\n",
    "df_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpt_grid_red = df_hpt_grid[~df_hpt_grid[\"Model\"].isin([\"Linear Regression\", \"Ridge Regression\", \"Decision Tree\", \"K-Nearest Neighbors\"])]\n",
    "df_plot = models.select_best_per_model(df_hpt_grid_red, df_hpt_rand)\n",
    "models.plot_model_scores(\n",
    "    df_hpt_grid_red,\n",
    "    df_plot,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach erweitertem HPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich: Vorher–Nachher nur für Modelle mit Randomized Search**\n",
    "\n",
    "Die Abbildung zeigt den gezielten Vergleich der Modellperformance **vor und nach dem erweiterten HPT** mittels `RandomizedSearchCV`. Betrachtet wurden nur jene Modelle, die auf Basis der ersten Tuningrunde (GridSearch) als vielversprechend eingestuft wurden.\n",
    "\n",
    "- **ElasticNet** profitiert am deutlichsten vom erweiterten Suchraum und kann seinen NASA-Score signifikant verbessern.\n",
    "- Auch bei **Lasso** zeigt sich ein spürbarer Leistungsgewinn durch präzisere Abstimmung des Regularisierungsparameters.\n",
    "- **Random Forest** und **Gradient Boosting** bleiben stabil – die Default-Parameter lagen bereits nahe am Optimum.\n",
    "- **SVR** zeigt keinerlei Verbesserung – trotz erweitertem Hyperraum bleibt das Modell im Vergleich zur Konkurrenz deutlich zurück.\n",
    "\n",
    "Insgesamt bestätigt sich, dass Randomized Search insbesondere bei **sensiblen, stark hyperparameterabhängigen Modellen** (wie Lasso/ElasticNet) lohnenswert ist, während robuste Modelle wie Random Forest oder Gradient Boosting kaum profitieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Evaluation\n",
    "\n",
    "Nach Abschluss der zweistufigen Hyperparameter-Optimierung folgt nun die abschliessende Bewertung der besten Modellkonfigurationen. Für jedes Modell, das in der Randomized-Search-Phase ein überzeugendes Ergebnis erzielt hat, wird die finale Variante erneut instanziiert, mit gewichteter Verlustfunktion auf den Trainingsdaten trainiert und auf den Testdaten evaluiert.\n",
    "\n",
    "Bewertet wird anhand des **NASA-Scores**, der auch in dieser finalen Phase als zentrales Auswahlkriterium dient.\n",
    "\n",
    "Anschliessend wird das **beste Modell** anhand des minimalen NASA-Scores ausgewählt und dessen Vorhersageverhalten visuell analysiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results     = []\n",
    "y_preds     = []\n",
    "models_list = []\n",
    "\n",
    "# Evaluierung aller Modelle aus df_plot mit richtigen Parametern\n",
    "for name, _, supports_weights in model_defs:\n",
    "    if name not in df_plot[\"Model\"].values:\n",
    "        continue  # nur Modelle evaluieren, die im df_plot vorhanden sind\n",
    "\n",
    "    row    = df_plot[df_plot[\"Model\"] == name].iloc[0]\n",
    "    params = row[\"Best Params\"]\n",
    "\n",
    "    model_cls = ALL_MODELS[name][0]\n",
    "    model     = model_cls(**params)\n",
    "\n",
    "    eval_res = models.evaluate_model(\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        X_test,  y_test,\n",
    "        model_name=name,\n",
    "        weighted=supports_weights\n",
    "    )\n",
    "\n",
    "    results.append(eval_res)\n",
    "    y_preds.append(model.predict(X_test))\n",
    "    models_list.append(model)\n",
    "\n",
    "# Bestes Modell bestimmen\n",
    "df_test_eval     = pd.DataFrame(results)\n",
    "best_idx         = df_test_eval[\"NASA-Score\"].idxmin()\n",
    "df_test_eval     = df_test_eval.loc[[best_idx]].reset_index(drop=True)\n",
    "y_pred_best      = y_preds[best_idx]\n",
    "best_model_name  = df_test_eval.loc[0, \"Model\"]\n",
    "df_test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interpretation_plots = [\n",
    "    toggle(\"Vorhersage + Residuen\", lambda df: models.plot_prediction_and_residuals(y_test, y_pred_best, best_model_name)),\n",
    "    toggle(\"Feature-Wichtigkeiten\", lambda df: models.plot_feature_importance(best_model, X_train)),\n",
    "    toggle(\"SHAP Beeswarm\", lambda df: models.plot_shap_beeswarm(best_model, X_train, X_test)),\n",
    "    toggle(\"SHAP Beispiele (Waterfall)\", lambda df: models.plot_shap_waterfalls(best_model, X_train, X_test, y_test, y_pred_best)),\n",
    "    toggle(\"Partial Dependence Plots\", lambda df: models.plot_pdp(best_model, X_train)),\n",
    "]\n",
    "\n",
    "model_interpretation_section = [\n",
    "    util.make_dropdown_section(model_interpretation_plots, f\"fd001_{best_model_name}_Interpretation\", use_cache=False)\n",
    "]\n",
    "\n",
    "panel_modelinterpretation = util.make_lazy_panel_with_tabs(\n",
    "    model_interpretation_section,\n",
    "    tab_titles=[\"Modellinterpretation\"],\n",
    "    open_btn_text=\"FD001_XAI öffnen\",\n",
    "    close_btn_text=\"Schliessen\"\n",
    ")\n",
    "\n",
    "display(panel_modelinterpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abschliessende Evaluation des besten Modells: Random Forest (weighted)**\n",
    "\n",
    "Das finale Modell, ein **gewichteter Random Forest**, erzielte den besten NASA-Score aller getesteten Modelle:\n",
    "\n",
    "- **RMSE-Test:** 17.13  \n",
    "- **R²-Test:** 0.83  \n",
    "- **NASA-Score:** 457.38\n",
    "\n",
    "Die Vorhersagegrafik (links) zeigt eine gute Übereinstimmung zwischen vorhergesagter und tatsächlicher RUL, insbesondere im mittleren Bereich. Nur in sehr hohen RUL-Bereichen treten kleinere systematische Abweichungen auf, was für dieses Szenario tolerierbar ist.\n",
    "\n",
    "Im **Residuenplot** (rechts) ist die Fehlerverteilung relativ gleichmässig um Null zentriert – ohne starke systematische Verzerrung. Damit erfüllt das Modell nicht nur die Anforderungen an Vorhersagegüte, sondern auch an **robuste Fehlerverteilung** über verschiedene RUL-Bereiche hinweg.\n",
    "\n",
    "Insgesamt lässt sich festhalten:  \n",
    "Der gewichtete Random Forest bildet den komplexen Degradationsverlauf zuverlässig ab und vermeidet gleichzeitig kritische Überschätzungen in späten Lebensphasen – was insbesondere durch den niedrigen NASA-Score bestätigt wird.\n",
    "\n",
    "**Vergleich mit bestehender Literatur**\n",
    "\n",
    "Zur Bewertung des eigenen Modells wurden vier aktuelle Arbeiten sowie die systematische Vergleichstabelle von [3] herangezogen. [1] verwendeten einen optimierten Random Forest mit 5-fold-CV und erreichten einen RMSE von 19.01. [2] kombinierten Random-Forest-basierte Feature-Selection mit einem bayes-optimierten MLP und erzielten 17.14 bei einem R² von 0.83. [4] setzten ein LSTM-Modell mit geglätteten Sequenzen ein, das jedoch mit einem RMSE von ca. 28.2 schlechter abschnitt. Die besten Werte wurden von [3] erreicht, deren tiefes LSTM-Netz mit automatischer Degradationspunkt-Erkennung einen RMSE von 7.78 und Score von 100 erzielte.\n",
    "\n",
    "Im Rahmen derselben Quelle [3] wurde zudem ein Überblick über aktuelle Deep-Learning-Modelle veröffentlicht, bei denen die RMSE-Werte zwischen 18.44 (Score 1290) und 7.78 (Score 100) lagen.\n",
    "\n",
    "Das hier entwickelte Modell (RMSE = 17.13, R² = 0.83, NASA-Score = 457.38) reiht sich damit im unteren Drittel moderner Deep-Learning-Verfahren ein, übertrifft jedoch mehrere frühere Ansätze und stellt insbesondere im klassischen Machine Learning eine robuste und interpretierbare Alternative dar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fazit zu Kapitel 3.1 – Analyse für FD001**\n",
    "\n",
    "Die Analyse des einfachsten C-MAPSS-Szenarios FD001 hat gezeigt, dass auch unter konstanten Betriebsbedingungen eine präzise RUL-Vorhersage anspruchsvoll bleibt. Durch gezielte Feature-Auswahl, temporale Merkmalsextraktion sowie eine schrittweise Modelloptimierung konnte jedoch ein leistungsfähiges Vorhersagemodell entwickelt werden.\n",
    "\n",
    "Besonders hervorgetan hat sich der **gewichtete Random Forest**, der dank robuster Struktur und Fehlergewichtung sowohl in klassischen Metriken (RMSE, R²) als auch im NASA-Score überzeugte. Die Gewichtung erwies sich dabei als entscheidender Faktor zur Reduktion systematischer Überschätzungen bei niedriger RUL.\n",
    "\n",
    "Damit bildet FD001 eine solide Grundlage, auf der sich die Generalisierbarkeit und Belastbarkeit der entwickelten Pipeline in komplexeren Szenarien (Kapitel 3.2–3.4) überprüfen lässt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 Analyse für FD002\n",
    "\n",
    "Der Datensatz FD002 enthält variable Betriebsbedingungen bei gleichzeitig einem einzigen Degradationsmodus. Im Vergleich zu FD001 ist das Verhalten der Sensoren komplexer, da die Betriebspunkte schwanken.  \n",
    "Die Analyse dieses Szenarios liefert wichtige Erkenntnisse darüber, wie stark sich Sensorwerte durch die Operation Settings beeinflussen lassen und welche Normalisierungen oder Features erforderlich sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Explorative Datenanalyse (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD002:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD002 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_02, \"FD002\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in list(range(1, 18)) + [19, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[244, 112]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=112, dataset_name=\"FD002-112\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD002\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD002 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_02,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD002\",\n",
    "            dbscan_eps = 2.5,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_02[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD002\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD002\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD002\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD002\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD002\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD002\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD002\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD002\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD002 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD002 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD002  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 Analyse für FD003\n",
    "FD003 weist konstante Betriebsbedingungen, aber mehrere Degradationsmodi auf. Damit eignet sich der Datensatz gut, um rein sensorbasierte Unterschiede im Degradationsverhalten zu untersuchen, ohne dass sich zusätzlich die Betriebszustände verändern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD003:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD003 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_03, \"FD003\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[99, 55]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=55, dataset_name=\"FD003-55\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD003\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD003 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_03,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD003\",\n",
    "            dbscan_eps = 3,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_03[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD003\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD003\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD003\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD003\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD003\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD003\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD003\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD003\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD003 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD003 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD003  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.4 Analyse für FD004\n",
    "FD004 kombiniert die komplexesten Bedingungen aller C-MAPSS-Datensätze: variable Betriebspunkte und mehrere Degradationsmodi.\n",
    "Dieser Datensatz stellt somit das realistischste, aber auch herausforderndste Szenario dar. Ziel der Analyse ist es, robuste Muster trotz starker Streuung und Rauschen zu identifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.1 Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD004:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD004 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_04, \"FD004\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in range(1, 22)]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[214, 118]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=118, dataset_name=\"FD004-118\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD004\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD004 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_04,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD004\",\n",
    "            dbscan_eps = 3,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_04[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD004\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD004\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD004\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD004\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD004\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD004\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD004\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD004\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD004 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD004 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD004  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Kombinierte Analyse (FD001–FD004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Explorative Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.4 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Zusammenfassung und Ausblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Ergebnisse im Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.3 Weiterführende Ideen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anhang A – Eigenständigkeitserklärung\n",
    "\n",
    "Hiermit bestätige ich, dass ich die vorliegende Arbeit selbständig verfasst und keine anderen als die angegebenen Hilfsmittel benutzt habe.  \n",
    "Die Stellen der Arbeit, die dem Wortlaut oder dem Sinn nach anderen Werken (dazu zählen auch Internetquellen) entnommen sind, wurden unter Angabe der Quelle kenntlich gemacht.\n",
    "\n",
    "<table style=\"width:100%; background-color: white; padding: 10px; border-radius: 6px; box-shadow: 0 0 5px rgba(0,0,0,0.2); margin-top:20px;\">\n",
    "  <tr>\n",
    "    <td align=\"left\">\n",
    "      <img src=\"images/Unterschrift.png\" alt=\"Unterschrift\" style=\"height:80px;\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anhang B – Literaturverzeichnis\n",
    "\n",
    "[1] Gupta, R. K.; Nakum, J.; Gupta, P.: *A Machine Learning Approach for Turbofan Jet Engine Predictive Maintenance*. Procedia Computer Science. 259, 2025, S. 161–171. https://doi.org/10.1016/j.procs.2025.03.317\n",
    "\n",
    "[2] Wang, H.; Li, D.; Li, D.; Liu, C.; Yang, X.; Zhu, G.: *Remaining Useful Life Prediction of Aircraft Turbofan Engine Based on Random Forest Feature Selection and Multi-Layer Perceptron*. Applied Sciences. 13, 2023, Art. 7186. https://doi.org/10.3390/app13127186\n",
    "\n",
    "[3] Asif, O.; Haider, S. A.; Naqvi, S. R.; Zaki, J. F. W.; Kwak, K.-S.; Islam, S. M. R.: *A Deep Learning Model for Remaining Useful Life Prediction of Aircraft Turbofan Engine on C-MAPSS Dataset* in IEEE Access, vol. 10, pp. 95425-95440, 2022, https://doi.org//10.1109/ACCESS.2022.3203406\n",
    "\n",
    "[4] Peringal, A.; Mohiuddin, M. B.; Hassan, A.: *Remaining Useful Life Prediction for Aircraft Engines using LSTM.* Preprint auf arXiv, 2024. [arXiv:2401.07590](https://arxiv.org/abs/2401.07590)\n",
    "\n",
    "---\n",
    "*Für die sprachliche Überarbeitung und die Unterstützung bei Codefragmenten wurde das KI-Tool* **ChatGPT** *von OpenAI (GPT-4o, https://chatgpt.com) verwendet. Die fachliche und inhaltliche Verantwortung liegt vollständig beim Autor.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
