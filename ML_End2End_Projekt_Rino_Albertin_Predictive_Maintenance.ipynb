{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src import eda, util, fe, models\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# ---- EDA Konfiguration ----\n",
    "# Skalierung aller Sensoren und Operation Settings (Z-Norm pro Betriebsbedingung)\n",
    "NORMALIZE = True\n",
    "\n",
    "EDA_FD001 = True\n",
    "EDA_FD002 = True\n",
    "EDA_FD003 = True\n",
    "EDA_FD004 = True\n",
    "\n",
    "# ---- HPT Konfiguration ----\n",
    "# True: Hyperparameter-Tuning ausführen, False: gespeichertes Modell laden\n",
    "HPT_FD001 = False\n",
    "HPT_FD002 = False\n",
    "HPT_FD003 = False\n",
    "HPT_FD004 = False\n",
    "\n",
    "# ---- Caching-/Recompute-Konfiguration ----\n",
    "PRECOMPUTE_ALL_PLOTS = False        # Alle EDA-Plots bei Notebook-Start berechnen. Widgets reagieren erst nach dem Precompute.\n",
    "FORCE_RECOMPUTE_PLOTS = False       # Alle EDA-Plots beim Precompute immer neu berechnen, auch wenn sie schon im Cache sind.\n",
    "FORCE_RECOMPUTE_TSNE_DBSCAN = False # TSNE/DBSCAN immer neu berechnen\n",
    "\n",
    "if not PRECOMPUTE_ALL_PLOTS:        # Nur gültig, wenn Precompute aktiviert ist!\n",
    "    FORCE_RECOMPUTE_PLOTS = False   \n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; background-color: white; padding: 10px; border-radius: 6px; box-shadow: 0 0 5px rgba(0,0,0,0.2);\">\n",
    "  <tr>\n",
    "    <td>\n",
    "      <h1 style=\"margin-bottom: 0; color: black; font-size: clamp(1.4rem, 2.2vw, 2.2rem);\">\n",
    "        Predictive Maintenance: Vorhersage der Remaining Useful Life (RUL) von Triebwerken des NASA C-MAPSS-Datensatzes\n",
    "      </h1>\n",
    "    </td>\n",
    "    <td align=\"right\">\n",
    "      <img src=\"images/OST_Logo_DE_RGB@2000ppi.png\" alt=\"OST Logo\" width=\"200\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Autor:** Rino Albertin  \n",
    "**Datum:** 6. März 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Inhaltsverzeichnis\n",
    "\n",
    "1. Einleitung  \n",
    "   1.1 Zielsetzung  \n",
    "   1.2 Vorgehensweise  \n",
    "\n",
    "2. Überblick über den Datensatz und technische Grundlagen  \n",
    "   2.1 Allgemeine Datenstruktur  \n",
    "   2.2 Operative Einstellungen und Sensorik  \n",
    "\n",
    "3. Einzelanalyse  \n",
    "   3.1 FD001  \n",
    "   3.2 FD002  \n",
    "   3.3 FD003  \n",
    "   3.4 FD004  \n",
    "\n",
    "4. Kombinierte Analyse aller Datensätze  \n",
    "   4.1 Explorative Datenanalyse  \n",
    "   4.2 Feature Engineering  \n",
    "   4.3 Modellierung  \n",
    "   4.4 Hyperparameter-Tuning  \n",
    "   4.5 Evaluation  \n",
    "\n",
    "5. Zusammenfassung und Ausblick  \n",
    "   5.1 Ergebnisse im Vergleich  \n",
    "   5.2 Lessons Learned  \n",
    "   5.3 Weiterführende Ideen  \n",
    "\n",
    "Anhang A – Eigenständigkeitserklärung  \n",
    "Anhang B – Literaturverzeichnis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Einleitung\n",
    "\n",
    "Predictive Maintenance ist in der heutigen Industrie von zentraler Bedeutung, um ungeplante Ausfälle zu vermeiden und Wartungskosten zu senken. Die Vorhersage der verbleibenden Nutzungsdauer (Remaining Useful Life, RUL) von Triebwerken ermoeglicht eine optimierte Planung von Wartungsarbeiten und verbessert die Betriebseffizienz.\n",
    "\n",
    "Der NASA (C-MAPSS) Commercial Modular Aero-Propulsion System Simulation-Datensatz bietet simulierte Run-to-Failure-Zeitreihen von Triebwerken der NASA, die Zeit, Betriebsbedingungen, 3 operative Einstellungen und 21 Sensormessungen umfassen. Dies macht ihn zu einer idealen Grundlage, um moderne Machine-Learning-Methoden zur RUL-Vorhersage zu evaluieren und zu vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Zielsetzung\n",
    "\n",
    "Entwicklung eines Machine-Learning-Modells, das auf Basis historischer Sensordaten die RUL von Triebwerken präzise vorhersagen kann. Dabei soll sowohl das Verhalten einzelner Szenarien als auch eine generalisierbare Lösung über alle vier Datensätze hinweg untersucht werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Vorgehensweise\n",
    "\n",
    "Die Bearbeitung erfolgt in zwei strukturierten Phasen:\n",
    "\n",
    "### Phase 1: Einzelanalysen pro Datensatz (FD001–FD004)\n",
    "\n",
    "Jeder der vier C-MAPSS-Datensätze wird separat analysiert, um spezifische Muster, Herausforderungen und Modellierungsstrategien zu identifizieren. Die Analyse umfasst jeweils:\n",
    "\n",
    "1. **Explorative Datenanalyse (EDA):**  \n",
    "   Untersuchung der Lebensdauerverteilung, Sensorverläufe und Betriebsbedingungen, ergänzt durch t-SNE/DBSCAN-Clustering.\n",
    "\n",
    "2. **Feature Engineering:**  \n",
    "   Umbenennung der Sensoren, gezielte Auswahl auf Basis physikalischer Plausibilität, Korrelation und Signaltrends.  \n",
    "   Erweiterung durch kombinierte und temporale Merkmale sowie anschliessende Reduktion irrelevanter oder redundanter Features mittels Random Forest Feature Importances.\n",
    "\n",
    "3. **Modellierung & Evaluation:**  \n",
    "   Training verschiedener ML-Modelle und Vergleich mittels RMSE, R² und NASA-Score.\n",
    "\n",
    "4. **Hyperparameter-Tuning:**  \n",
    "   Zweistufiges Tuning mit GridSearchCV (grober Raster) und RandomizedSearchCV (feine Optimierung ausgewählter Modelle).\n",
    "\n",
    "5. **Modellinterpretation:**  \n",
    "   Analyse der besten Modelle mit SHAP, PDP und Feature Importance zur Sicherstellung physikalischer Plausibilität.\n",
    "\n",
    "### Phase 2: Kombinierte Analyse (Generalmodell über FD001–FD004)\n",
    "\n",
    "In dieser Phase werden alle vier Datensätze zusammengeführt, um ein generalisierbares Modell für unterschiedliche Szenarien zu entwickeln. Dabei wird auf der in Phase 1 entwickelten Pipeline aufgebaut – mit Anpassungen im Feature Engineering und der Modellarchitektur zur Bewältigung der Heterogenität.\n",
    "\n",
    "**Referenzen:**  \n",
    "- **C-MAPSS-Datensatz** – NASA Prognostics Center of Excellence (Datensatz Nr. 6 aus dem offiziellen NASA Prognostics Data Repository):  \n",
    "  A. Saxena and K. Goebel (2008). *Turbofan Engine Degradation Simulation Data Set*, NASA Prognostics Data Repository, NASA Ames Research Center, Moffett Field, CA.  \n",
    "  [Offizielle Beschreibung auf nasa.gov](https://www.nasa.gov/intelligent-systems-division/discovery-and-systems-health/pcoe/pcoe-data-set-repository/)  \n",
    "  [Direkter Download (ZIP)](https://phm-datasets.s3.amazonaws.com/NASA/6.+Turbofan+Engine+Degradation+Simulation+Data+Set.zip)\n",
    "\n",
    "- **Lehrunterlagen** – Modul *Machine Learning*, OST – Ostschweizer Fachhochschule\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Überblick über den Datensatz und technische Grundlagen\n",
    "\n",
    "Bevor mit der eigentlichen Analyse begonnen wird, erfolgt in diesem Kapitel eine technische Einführung in den C-MAPSS-Datensatz. Ziel ist es, ein grundlegendes Verständnis für Struktur, Sensorik und die inhaltlichen Rahmenbedingungen zu schaffen. Eine erste übergreifende EDA bietet zusätzlich einen Einblick in Gemeinsamkeiten und Besonderheiten der vier Szenarien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Allgemeine Datenstruktur\n",
    "\n",
    "Der C-MAPSS-Datensatz (Commercial Modular Aero-Propulsion System Simulation) besteht aus vier Teildatensätzen (FD001–FD004), die unterschiedliche Betriebsszenarien simulieren. Jeder Datensatz enthält Sensormessungen von mehreren Triebwerken über deren gesamte Lebensdauer hinweg (Run-to-Failure).\n",
    "\n",
    "Für jede Zeile sind folgende Informationen verfügbar:\n",
    "\n",
    "- **unit**: ID des Triebwerks (eine Einheit)\n",
    "- **time**: aktueller Zyklus (Zeitpunkt)\n",
    "- **op_setting_1–3**: operative Einstellungen (Flughöhe, Machzahl, Drosselklappen-Positionen)\n",
    "- **sensor_1–21**: Sensormessungen aus verschiedenen Triebwerkskomponenten\n",
    "\n",
    "![Triebwerksaufbau in C-MAPSS](images/Simplified%20diagram%20of%20engine%20simulated%20in%20C-MAPSS.png)\n",
    "\n",
    "Die Abbildung zeigt den schematischen Aufbau eines Triebwerks, wie es in der C-MAPSS-Simulation verwendet wird. Die Hauptkomponenten sind:\n",
    "\n",
    "- **Fan:** Der Fan (Luftgebläse) saugt Umgebungsluft an, die teilweise in den Bypass strömt (äusserer Luftstrom) und teilweise ins Triebwerk.\n",
    "- **LPC (Low Pressure Compressor):** Komprimiert die angesaugte Luft bei niedrigem Druck.\n",
    "- **HPC (High Pressure Compressor):** Erhöht den Druck der Luft weiter vor der Verbrennung.\n",
    "- **Combustor:** Vermischt die verdichtete Luft mit Treibstoff, zündet die Mischung und erzeugt damit heisse Hochdruckgase.\n",
    "- **HPT (High Pressure Turbine):** Entzieht den heissen Gasen Energie, um den HPC anzutreiben.\n",
    "- **LPT (Low Pressure Turbine):** Treibt den Fan und die LPC an.\n",
    "- **N1/N2:** Repräsentieren die beiden Hauptwellen im Triebwerk (N1: Fan + LPC, N2: HPC + HPT).\n",
    "- **Nozzle:** Düse am Austritt – beschleunigt die Abgasströmung und erzeugt Schub.\n",
    "\n",
    "Viele der 21 Sensoren messen Parameter an genau diesen Stellen, z. B. Druck, Temperatur, Drehzahl oder Luftmassenströme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Operative Einstellungen und Sensorik\n",
    "\n",
    "Die C-MAPSS-Daten umfassen neben Zyklusinformationen auch drei operative Einstellungen und 21 Sensormessungen. Die operativen Einstellungen variieren je nach Szenario und beeinflussen die physikalischen Messgrössen, die an verschiedenen Triebwerkskomponenten aufgezeichnet werden.\n",
    "\n",
    "#### Operative Einstellungen\n",
    "\n",
    "| Spalte         | Beschreibung                         | Wertebereich        |\n",
    "|----------------|--------------------------------------|---------------------|\n",
    "| op_setting_1   | Flughöhe (Altitude)                  | 0 – 42'000 ft       |\n",
    "| op_setting_2   | Machzahl                             | 0 – 0.84            |\n",
    "| op_setting_3   | Throttle Resolver Angle (TRA)        | 20 – 100            |\n",
    "\n",
    "#### Sensorübersicht\n",
    "\n",
    "| Sensor | Beschreibung                             | Wertebereich (FD001–FD004) |\n",
    "|--------|------------------------------------------|----------------------------|\n",
    "|  1     | Total temperature at fan inlet (T2)      | 445.0 – 518.67 °R          |\n",
    "|  2     | Total temperature at LPC outlet (T24)    | 535.48 – 645.11 °R         |\n",
    "|  3     | Total temperature at HPC outlet (T30)    | 1242.67 – 1616.91 °R       |\n",
    "|  4     | Total temperature at LPT outlet (T50)    | 1023.77 – 1441.49 °R       |\n",
    "|  5     | Pressure at fan inlet (P2)               | 3.91 – 14.62 psia          |\n",
    "|  6     | Bypass-duct pressure (P15)               | 5.67 – 21.61 psia          |\n",
    "|  7     | Total pressure at HPC outlet (P30)       | 136.17 – 570.81 psia       |\n",
    "|  8     | Physical fan speed (Nf)                  | 1914.72 – 2388.64 rpm      |\n",
    "|  9     | Physical core speed (Nc)                 | 7984.51 – 9244.59 rpm      |\n",
    "| 10     | Engine pressure ratio (epr)              | 0.93 – 1.32                |\n",
    "| 11     | Static pressure at HPC outlet (Ps30)     | 36.04 – 48.53 psia         |\n",
    "| 12     | Ratio of fuel flow to Ps30 (phi)         | 128.31 – 537.49 pps/psi    |\n",
    "| 13     | Corrected fan speed (NRf)                | 2027.57 – 2390.49 rpm      |\n",
    "| 14     | Corrected core speed (NRc)               | 7845.78 – 8293.72 rpm      |\n",
    "| 15     | Bypass ratio (BPR)                       | 8.1563 – 11.0669           |\n",
    "| 16     | Burner fuel-air ratio (farB)             | 0.02 – 0.03                |\n",
    "| 17     | Bleed enthalpy (htBleed)                 | 302   – 400                |\n",
    "| 18     | Demanded fan speed (Nf_dmd)              | 1915   – 2388 rpm          |\n",
    "| 19     | Demanded corrected fan speed (PCNfR_dmd) | 84.93 – 100.0 rpm          |\n",
    "| 20     | HPT coolant bleed (W31)                  | 10.16 – 39.89 lbm/s        |\n",
    "| 21     | LPT coolant bleed (W32)                  | 6.0105 – 23.9505 lbm/s     |\n",
    "\n",
    "*Die angegebenen Wertebereiche wurden über alle Trainingsdaten der Szenarien FD001 bis FD004 bestimmt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"FD001\": util.load_cmapss_data(\"FD001\"),\n",
    "    \"FD002\": util.load_cmapss_data(\"FD002\"),\n",
    "    \"FD003\": util.load_cmapss_data(\"FD003\"),\n",
    "    \"FD004\": util.load_cmapss_data(\"FD004\"),\n",
    "    \"ALL\":   util.load_cmapss_data()\n",
    "}\n",
    "\n",
    "raw_datasets = {k: (df_train.copy(), df_test.copy()) for k, (df_train, df_test) in datasets.items()}\n",
    "\n",
    "df_train_01, df_test_01 = datasets[\"FD001\"]\n",
    "df_train_02, df_test_02 = datasets[\"FD002\"]\n",
    "df_train_03, df_test_03 = datasets[\"FD003\"]\n",
    "df_train_04, df_test_04 = datasets[\"FD004\"]\n",
    "df_train, df_test = datasets[\"ALL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vorverarbeitung – Skalierung nach Betriebs­bedingungen\n",
    "\n",
    "Um Niveauverschiebungen auszublenden, die allein durch wechselnde Flughöhen, Machzahlen oder Drosselklappen-Stellungen entstehen (op_settings), werden alle 21 Sensoren **z-standardisiert – getrennt pro Betriebs­gruppe (`op_cond`)**.\n",
    "\n",
    "Die Gruppierung erfolgt anhand fester Schwellenwerte (siehe Plot unten) in einer **6 × 5 × 2-Einteilung**:\n",
    "\n",
    "| Einstellgrösse    | Binning-Strategie                            | Zweck                           |\n",
    "|-------------------|----------------------------------------------|----------------------------------|\n",
    "| **op_setting 1**  | manuell: `[0 – 5 – 15 – 22 – 30 – 40 – ∞]`    | trennt Flughöhenbereiche        |\n",
    "| **op_setting 2**  | manuell: `[0 – 0.2 – 0.55 – 0.63 – 0.8 – ∞]`  | trennt Geschwindigkeitsbereiche |\n",
    "| **op_setting 3**  | binär: `< 80` → T0, `≥ 80` → T1               | Zweipunkt-Steuerung (TRA)       |\n",
    "\n",
    "Diese Einteilung ergibt **60 theoretisch mögliche Kombinationen** (6 × 5 × 2).  \n",
    "**Tatsächlich kommen aber in jedem Szenario nur genau 6 Gruppen vor** – ein Grossteil der Kombinationen tritt in den Daten nicht auf. Dadurch bleibt die Normalisierung robust und gut interpretierbar.\n",
    "\n",
    "- Der `StandardScaler` wird **ausschliesslich auf den Trainingsdaten** pro `op_cond`-Gruppe fit-transformiert.\n",
    "- Für die zugehörigen Testdaten wird **dieselbe Skalierung** mittels `transform()` übernommen.\n",
    "- Bei **konstanten Betriebspunkten** (z. B. FD001 & FD003) degeneriert das Verfahren zu einer **globalen Standardisierung**, da nur eine einzige `op_cond`-Gruppe existiert.\n",
    "\n",
    "> **Hinweis:** Alle tatsächlich vorkommenden Gruppen enthalten mindestens **5000 Zeilen**, was eine robuste, gruppenbasierte Skalierung erlaubt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_op_settings_histograms(df_train_02, df_test_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    for k in datasets:\n",
    "        datasets[k] = util.standardize_by_op_cond(*datasets[k])\n",
    "else:\n",
    "    for k in datasets:\n",
    "        datasets[k] = tuple(util.assign_op_cond_bins(df) for df in datasets[k])\n",
    "\n",
    "df_train_01, df_test_01 = datasets[\"FD001\"]\n",
    "df_train_02, df_test_02 = datasets[\"FD002\"]\n",
    "df_train_03, df_test_03 = datasets[\"FD003\"]\n",
    "df_train_04, df_test_04 = datasets[\"FD004\"]\n",
    "df_train, df_test = datasets[\"ALL\"]\n",
    "\n",
    "print(\"df_train_02:\", util.get_op_cond_distribution_summary(df_train_02), \"\\n\")\n",
    "print(\"df_test_02:\", util.get_op_cond_distribution_summary(df_test_02), \"\\n\")\n",
    "\n",
    "print(\"df_train_04:\", util.get_op_cond_distribution_summary(df_train_04), \"\\n\")\n",
    "print(\"df_test_04:\", util.get_op_cond_distribution_summary(df_test_04), \"\\n\")\n",
    "\n",
    "print(\"df_train:\", util.get_op_cond_distribution_summary(df_train), \"\\n\")\n",
    "print(\"df_test:\", util.get_op_cond_distribution_summary(df_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Einzelanalysen der vier Datensätze\n",
    "\n",
    "Ziel dieses Kapitels ist es, die vier Teildatensätze **FD001 bis FD004** separat zu analysieren und zu modellieren. Jeder Datensatz repräsentiert ein eigenes Betriebsszenario mit unterschiedlichen Rahmenbedingungen (konstante vs. variable Settings, ein oder zwei Degradationsmodi).\n",
    "\n",
    "Für jeden Datensatz wird eine identische Analysepipeline angewendet, bestehend aus:\n",
    "- Explorative Datenanalyse (EDA)\n",
    "- Feature Engineering\n",
    "- Modellierung\n",
    "- Hyperparameter-Tuning\n",
    "- Evaluation\n",
    "\n",
    "Diese Einzelschritte ermöglichen ein besseres Verständnis der Stärken und Schwächen verschiedener Modelle je Szenario und legen die Basis für die spätere kombinierte Analyse in Kapitel 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1 Analyse für FD001\n",
    "Der Datensatz FD001 stellt das einfachste Szenario innerhalb von C-MAPSS dar: konstante Betriebsbedingungen und ein einziger Degradationsmodus. Er eignet sich daher besonders gut für eine erste Modellierung und das Testen von Grundkonzepten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Explorative Datenanalyse (EDA)\n",
    "Ziel dieses Abschnitts ist es, ein erstes Verständnis für die Struktur und Eigenschaften des Datensatzes FD001 zu entwickeln. Dabei werden typische Lebensdauerverläufe analysiert, exemplarische Sensorwerte visualisiert und erste Hinweise auf potenziell relevante Merkmale identifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD001:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD001 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_01, \"FD001\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in [2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[39, 69]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=69, dataset_name=\"FD001-69\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD001\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD001 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_01,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD001\",\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_01[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD001\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD001\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD001\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD001\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD001\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD001\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD001\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD001\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD001 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD001 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lebensdauerverteilung:**  \n",
    "Die Lebensdauer der Triebwerke reicht von 128 bis 362 Zyklen (Median: 199). Die Verteilung ist leicht rechtsschief und weist einige Ausreisser mit hoher Zyklenanzahl auf.\n",
    "\n",
    "**Operation Settings:**  \n",
    "Die Betriebsbedingungen sind in diesem Szenario konstant und nur leicht verrauscht. `op_setting_1` und `op_setting_2` zeigen minimale Streuung, während `op_setting_3` konstant bleibt. Die Korrelationen der Settings mit der RUL sind vernachlässigbar (alle < 0.01). Auch innerhalb der Lifetime-Cluster zeigen sich keine signifikanten Unterschiede, weshalb diese Settings nicht zur Modellierung herangezogen werden sollten.\n",
    "\n",
    "**Sensoranalyse:**  \n",
    "Die Sensoren lassen sich in mehrere Gruppen mit stark korrelierten Verläufen einteilen. Konstante Sensoren wurden zuvor entfernt:\n",
    "\n",
    "- **Gruppe A:** `sensor_2`, `3`, `4`, `8`, `11`, `13`, `15`, `17`  \n",
    "- **Gruppe B:** `sensor_7`, `12`, `20`, `21`  \n",
    "- **Gruppe C:** `sensor_9`, `14`  \n",
    "- **Gruppe D:** `sensor_6` – stark verrauscht, nicht informativ\n",
    "\n",
    "Mehrere Sensoren zeigen klare Trends über die Zeit und starke Korrelationen mit der RUL. Sensorverläufe über normierte Zeit zeigen für viele Sensoren monotone, glatte Verläufe. Diese sind potenziell prädiktiv und für Feature Engineering geeignet. Die Verteilungen zeigen teils Unterschiede zwischen Units mit langer und kurzer Lebensdauer, was weitere Segmentierungen rechtfertigt. Die Verteilungen sind meist unimodal im letzen Zyklus und weissen wenig Aussreiser auf. Die Ausreisser wurden dabei nicht entfernt da sie potenziel wichitge Informationen liefern.\n",
    "\n",
    "**Clusteranalyse:**  \n",
    "Ein t-SNE/DBSCAN-Verfahren identifiziert zwei Cluster, wobei der kleinere (Cluster 1) ca. 2 % der Daten umfasst. Er enthält keine finalen Datenpunkte (also keinen Lebensdauer-Endpunkt). Der Eintritt in diesen Cluster erfolgt typischerweise deutlich früher (Ø = 0.255 normierte Zeit) als bei Cluster 0 (Ø = 0.507).\n",
    "\n",
    "Sensorverläufe in Cluster 1 sind stark verrauscht und flach. In Cluster 0 hingegen zeigen sich klar strukturierte Abnahmen bzw. Zunahmen – konsistent mit dem Verschleissverhalten. Daraus ergibt sich:\n",
    "\n",
    "- **Cluster 0**: Hauptcluster mit verwertbaren Mustern und finalen Datenpunkten  \n",
    "- **Cluster 1**: Frühzeitiger Sondercluster ohne verwertbare Zielgrösse (RUL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Feature Engineering\n",
    "\n",
    "Auf Basis der EDA wurden gezielt Sensoren ausgewählt, die für die Prognose der Restlebensdauer (RUL) eine hohe Aussagekraft besitzen. Die Auswahl erfolgte entlang physikalischer Kriterien, des zeitlichen Signalverlaufs, der Korrelation zur Zielgrösse sowie einer Redundanzanalyse innerhalb stark korrelierter Sensorgruppen. Konstant bleibende oder verrauschte Sensoren wurden entfernt.\n",
    "\n",
    "Zur besseren Übersicht wurden die verbleibenden Sensoren in Gruppen eingeteilt und repräsentative Merkmale extrahiert. Zusätzlich wurden kombinierte Features gebildet, um komplexe physikalische Zusammenhänge wie thermodynamische Effizienz oder mechanische Wechselwirkungen modellierbar zu machen.\n",
    "\n",
    "Um den physikalischen Kontext zu verdeutlichen, wurden im ersten Verarbeitungsschritt alle Sensoren und Betriebsbedingungen in Klartext umbenannt. Ein weiterer Verarbeitungsschritt bestand darin, das Trainingsset gezielt zu kürzen: Bei einem zufälligen Anteil von 25 % der Triebwerks-Units wurde das letzte Segment abgeschnitten, sodass diese Einheiten nicht bis zum vollständigen Ausfall beobachtet wurden. Dadurch wird das Modell gezwungen, auch aus unvollständigen Lebenszyklen zu lernen, was der realen Situation im laufenden Betrieb besser entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df_train_01, df_test_01 = raw_datasets[\"FD001\"]\n",
    "df_train_01_fe = fe.rename_opsettings_and_sensors(df_train_01)\n",
    "df_test_01_fe = fe.rename_opsettings_and_sensors(df_test_01)\n",
    "df_train_01_fe = fe.truncate_train_units(df_train_01_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gruppe A: Temperatur, Druck, Drehzahl & Verhältnisse\n",
    "\n",
    "Verwendet wurden `sensor_4_T50_LPT_outlet_temp`, `sensor_11_Ps30_HPC_static_pres`, `sensor_15_BPR_bypass_ratio` und `sensor_17_htBleed_bleed_enthalpy`, da sie zentrale thermodynamische und aerodynamische Zustände des Triebwerks abbilden. `sensor_4` zeigte die höchste Korrelation mit der RUL und ist physikalisch am sinnvollsten, da er die Temperatur ganz am Ende des Systems misst. Die Sensoren `sensor_2_T24` und `sensor_3_T30` wurden aufgrund starker Redundanz mit `sensor_4` ausgeschlossen. Ergänzend wurden mehrere kombinierte Features eingesetzt: `rpm_diff = sensor_13_NRf_corrected_fan_speed - sensor_8_Nf_fan_speed` dient als robustes Mass für mechanische Abweichungen. `temp_to_pressure = sensor_4_T50_LPT_outlet_temp / sensor_11_Ps30_HPC_static_pres` quantifiziert potenzielle Effizienzverluste bei abweichenden Druckverhältnissen. `bleed_minus_temp = sensor_17_htBleed_bleed_enthalpy - sensor_4_T50_LPT_outlet_temp` identifiziert thermische Ungleichgewichte zwischen Zapfluft und Abgastemperatur, z. B. durch Leckagen.\n",
    "\n",
    "##### Gruppe B: Treibstofffluss & Kühlung\n",
    "\n",
    "Es wurde `sensor_12_phi_fuel_flow_per_Ps30` verwendet, da er die Brennstoffeffizienz relativ zum statischen Druck abbildet. Zusätzlich wurde `coolant_mean = (sensor_20_W31_HPT_coolant_bleed + sensor_21_W32_LPT_coolant_bleed)/2` gebildet, um den thermischen Kühlzustand robuster zu erfassen. Das kombinierte Feature `phi_to_bpr = sensor_12_phi_fuel_flow_per_Ps30 / sensor_15_BPR_bypass_ratio` erlaubt Rückschlüsse auf Effizienzverluste bei untypischer Strömungsverteilung.\n",
    "\n",
    "##### Gruppe C: Mechanische Belastung\n",
    "\n",
    "`sensor_14_NRc_corrected_core_speed` wurde als direkter Indikator für mechanische Belastung ausgewählt. Zusätzlich wurde `torque_ratio = sensor_14_NRc_corrected_core_speed / sensor_9_Nc_core_speed` gebildet, um die Lastverteilung normiert über Betriebspunkte hinweg zu erfassen. `sensor_9_Nc_core_speed` wurde aufgrund starker linearer Korrelation (r = 0.96) entfernt. Das gruppenübergreifende Feature `torque_times_bleed = sensor_14_NRc_corrected_core_speed * sensor_17_htBleed_bleed_enthalpy` verstärkt Zustände mit gleichzeitiger mechanischer und thermischer Belastung, wie sie bei ineffizientem Betrieb auftreten.\n",
    "\n",
    "##### Gruppe D: Konstant / verrauscht\n",
    "\n",
    "`sensor_6_P15_bypass_pres` wurde ausgeschlossen, da er über alle Units konstant bzw. stark verrauscht war und keinen Beitrag zur Zustandsdiagnose liefert.\n",
    "\n",
    "##### Skalierung und Zeitnormalisierung\n",
    "\n",
    "Alle Merkmale wurden anschliessend mithilfe von `standardize_by_op_cond()` standardisiert. Obwohl im Szenario **FD001** nur eine einzige Betriebsbedingung (`op_cond`-Gruppe) vorliegt, wurde die Funktion trotzdem verwendet, um ein konsistentes Vorgehen über alle Datensätze hinweg sicherzustellen. In diesem Fall entspricht die Skalierung einer **globalen Standardisierung** über alle Datenpunkte hinweg. Dies stellt sicher, dass alle Sensorwerte **dimensionslos und vergleichbar** sind, und verhindert, dass einzelne Sensoren aufgrund unterschiedlicher Wertebereiche **unverhältnismässig stark** ins Modell eingehen.\n",
    "\n",
    "Zur Verbesserung der zeitlichen Einordnung wurde zudem die **Zykluszeit pro Unit auf den Bereich [0, 1] normiert** (`groupby(\"unit\")[\"time\"] / max`), um **Trends über den Lebensverlauf** unabhängig von der absoluten Lebensdauer sichtbar zu machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01_fe = fe.add_combined_features(df_train_01_fe, dataset_name=\"FD001\")\n",
    "df_test_01_fe = fe.add_combined_features(df_test_01_fe, dataset_name=\"FD001\")\n",
    "\n",
    "df_train_01_fe, df_test_01_fe = util.standardize_by_op_cond(df_train_01_fe, df_test_01_fe)\n",
    "\n",
    "df_train_01_fe[\"time\"] = df_train_01_fe.groupby(\"unit\")[\"time\"].transform(lambda x: x / x.max())\n",
    "df_test_01_fe[\"time\"] = df_test_01_fe.groupby(\"unit\")[\"time\"].transform(lambda x: x / x.max())\n",
    "\n",
    "df_train_01_fe = fe.select_columns(df_train_01_fe, [4, 11, 12, 14, 17], include_opsettings = False, dataset_name=\"FD001\")\n",
    "df_test_01_fe = fe.select_columns(df_test_01_fe, [4, 11, 12, 14, 17], include_opsettings = False, dataset_name=\"FD001\")\n",
    "\n",
    "df_train_01_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduktion nach Analyse\n",
    "drop_cols = [\n",
    "    \"sensor_14_NRc_corrected_core_speed\",\n",
    "    \"rpm_diff\",\n",
    "    \"temp_to_pressure\",\n",
    "    \"bleed_minus_temp\",\n",
    "    \"torque_ratio\",\n",
    "    \"torque_times_bleed\"\n",
    "]\n",
    "df_train_01_fe.drop(columns=drop_cols, inplace=True)\n",
    "df_test_01_fe.drop(columns=drop_cols, inplace=True)\n",
    "# ---\n",
    "\n",
    "toggle = util.make_toggle_shortcut(df_train_01_fe, \"FD001_FE\")\n",
    "\n",
    "feature_cols = [col for col in df_train_01_fe.columns if col not in [\"unit\", \"time\", \"RUL\"]]\n",
    "\n",
    "sensors_plots = [\n",
    "    toggle(\"Korrelation\", lambda df: eda.plot_sensor_correlation_matrix(df, sensor_cols=feature_cols, dataset_name=\"FD001_FE\", annot=True)),\n",
    "    toggle(\"Verteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=feature_cols),\n",
    "    toggle(\"Trend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=feature_cols),\n",
    "    toggle(\"RUL-Korrelation\", eda.plot_sensor_rul_correlation, sensor_cols=feature_cols),\n",
    "]\n",
    "\n",
    "sections = [\n",
    "    util.make_dropdown_section(sensors_plots, \"FD001_FE\", use_cache=False),\n",
    "]\n",
    "tab_titles = [\"Featureanalyse (FE)\"]\n",
    "\n",
    "eda_panel_FD001_FE = util.make_lazy_panel_with_tabs(\n",
    "    sections,\n",
    "    tab_titles=tab_titles,\n",
    "    open_btn_text=\"FD001_FE öffnen\",\n",
    "    close_btn_text=\"Schliessen\"\n",
    ")\n",
    "display(eda_panel_FD001_FE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reduktion nach Feature-Analyse\n",
    "\n",
    "Nach der initialen Auswahl physikalisch sinnvoller und korrelierter Sensoren sowie der Berechnung mehrerer kombinierter Features wurde eine gezielte Reduktion der Featuremenge durchgeführt. Grundlage bildeten die normierten Zeitverläufe, Verteilungen nach Lebensdauer, Korrelationsmatrix sowie die Korrelation mit der Zielgrösse (RUL).\n",
    "\n",
    "Folgende ursprünglich gewählte Merkmale wurden entfernt:\n",
    "\n",
    "- `sensor_14_NRc_corrected_core_speed`, `torque_ratio`, `torque_times_bleed`: Zeigten entweder hohe Varianz im späteren Verlauf oder starke Korrelation untereinander bzw. mit bestehenden thermischen Merkmalen.\n",
    "- `rpm_diff`, `temp_to_pressure`, `bleed_minus_temp`: Keine klaren Trends oder geringe Streuung, ohne nennenswerte Korrelation zur RUL.\n",
    "\n",
    "Die finale Featuremenge enthält somit nur Merkmale mit stabilen zeitlichen Trends, guter Trennschärfe in der Lebensdauerverteilung und möglichst geringer Redundanz.\n",
    "\n",
    "**Verwendete Sensoren:**\n",
    "\n",
    "- **Direkt:** `sensor_4`, `sensor_11`, `sensor_12`, `sensor_17`  \n",
    "- **Indirekt über kombinierte Features:** `sensor_15`, `sensor_20`, `sensor_21`\n",
    "\n",
    "Die Gruppe C Mechanische Belastung wurde ausgeschlossen da die Sensoren `sensor_14` und `sensor_9` teils starke Varianz oder starke Redundanz zu bereits verwendeten thermischen Merkmalen zeigten. Trotz mehrerer getesteter Kombinationen (z. B. Verhältnis-, Differenz- und Log-Features) konnten keine robusten, verlässlich prädiktiven Trends identifiziert werden. Daher wurde Gruppe C in der finalen Featureauswahl nicht berücksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Erweiterung durch temporale Fenstermerkmale\n",
    "\n",
    "Um dynamische Informationen über den Degradationsverlauf zu erfassen, wurde die ursprüngliche Featuremenge mithilfe der Funktion `extract_temporal_features()` um aggregierte Merkmale aus mehreren Zeitfenstern erweitert. Für jeden Triebwerkslauf wurden um normierte Zeitpunkte (25 %, 50 %, 75 %) herum statistische Kennzahlen wie **Mittelwert, Standardabweichung, Min, Max, Range**, **lineare Regressionsslope und R²** sowie die **Mittelwertdifferenz** zwischen dem frühen und dem späten Bereich im Fenster berechnet. Dabei entspricht der frühe Bereich den **ersten 30 %** und der späte Bereich den **letzten 30 %** der Werte im jeweiligen Zeitfenster.\n",
    "\n",
    "Das verwendete Fenster betrug jeweils **± 0.25 um den jeweiligen Zeitpunkt**, sodass **alle Sensorwerte pro Unit** in mindestens ein Fenster einflossen. Damit spiegeln die extrahierten Merkmale nicht nur lokale, sondern auch übergreifende Verläufe der Sensorzeitreihen wider.\n",
    "\n",
    "Beim Testdatensatz kam eine angepasste Version (`extract_temporal_features_test()`) zum Einsatz. Dabei wurde pro Unit ein **einziges Zeitfenster um den letzten bekannten Zeitpunkt** (normierte Zeit = 1.0) betrachtet. Innerhalb dieses Fensters wurden **alle verfügbaren Sensorwerte ausgewertet**, um die aggregierten Merkmale zu berechnen. Die dabei entstehende Zielvariable (`RUL`) wurde anschliessend durch die **originalen Labelwerte** ersetzt, um eine faire Evaluation sicherzustellen und **Data-Leakage** zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_01_fe = fe.extract_temporal_features(df_train_01_fe)\n",
    "df_test_01_fe = fe.extract_temporal_features_test(df_test_01_fe)\n",
    "\n",
    "df_train_01_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection\n",
    "Nach dem vollständigen Feature Engineering erfolgt nun die gezielte Reduktion der Merkmale mittels RandomForest-basierter Feature Selection. Ziel ist es, Merkmale mit sehr geringer Prädiktionsrelevanz zu identifizieren und zu entfernen, um Overfitting zu vermeiden und die Modellkomplexität zu reduzieren.\n",
    "\n",
    "Dazu wird ein RandomForestRegressor auf den Trainingsdaten trainiert und die Feature-Wichtigkeiten (feature_importances_) berechnet. Alle Merkmale mit einer Wichtigkeit unterhalb eines definierten Schwellenwerts (< 0.005) werden verworfen.\n",
    "\n",
    "Die wichtigsten Merkmale stammen überwiegend aus **temporalen Trendanalysen**, insbesondere aus Zeitreihenmerkmalen wie **Steigung (`slope`)**, **Regressionsgüte (`r²`)** und **Mittelwertunterschied (`mean_diff`)**. Dominant sind die Temperatur am LPT-Ausgang (`sensor_4_T50`) sowie kombinierte Effizienzkennzahlen wie `phi_to_bpr` und `coolant_mean`.  \n",
    "\n",
    "Diese Features spiegeln **deutliche zeitliche Veränderungen** im Systemzustand wider und sind daher besonders gut geeignet, den Verschleissverlauf und die verbleibende Lebensdauer vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Vorbereitung der Daten ===\n",
    "X_train = df_train_01_fe.drop(columns=[\"unit\", \"time_point\", \"RUL\"])\n",
    "y_train = df_train_01_fe[\"RUL\"]\n",
    "X_test = df_test_01_fe.drop(columns=[\"unit\", \"time_point\", \"RUL\"])\n",
    "y_test = df_test_01_fe[\"RUL\"]\n",
    "\n",
    "# Feature Selection durchführen\n",
    "X_train, X_test, imp_df, drop_cols = fe.select_features(X_train, y_train, X_test)\n",
    "\n",
    "# Top-10 Features anzeigen\n",
    "imp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Modellierung\n",
    "\n",
    "In diesem Schritt werden verschiedene Regressionsmodelle trainiert, um die verbleibende Nutzungsdauer (RUL) auf Basis der zuvor selektierten Features vorherzusagen. Ziel ist es, die leistungsfähigsten Modelle anhand praxisnaher Fehlerkennzahlen zu bewerten und das beste Modell für die weitere Verwendung auszuwählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Baseline-Modell\n",
    "\n",
    "**Verwendete Bewertungsmetriken:**\n",
    "- **RMSE (Root Mean Squared Error):** Durchschnittlicher quadratischer Fehler – misst die allgemeine Abweichung zwischen Vorhersage und Wahrheit.\n",
    "- **R² (Bestimmtheitsmass):** Erklärt, wie viel Varianz der Zielvariable durch das Modell erklärt wird.\n",
    "- **NASA-Score:** Eine speziell für RUL-Probleme entwickelte Metrik, die Fehler **asymmetrisch und exponentiell** bestraft.\n",
    "  \n",
    "Der NASA-Score wurde speziell für Remaining-Useful-Life-Prognosen entwickelt und berücksichtigt die unterschiedliche Schwere von Vorhersagefehlern:\n",
    "\n",
    "- **Überschätzungen der RUL** (Modell zu optimistisch) werden **stark bestraft**, da sie in der Praxis zu unerwarteten Ausfällen führen können.  \n",
    "- **Unterschätzungen** (Modell zu vorsichtig) sind weniger kritisch und werden entsprechend **milder bestraft**.\n",
    "\n",
    "Die Strafe erfolgt exponentiell – mit unterschiedlicher Basis:\n",
    "\n",
    "$$\n",
    "\\text{NASA-Score} =\n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^{n} e^{- \\frac{\\hat{y}_i - y_i}{13}} - 1, & \\text{falls } \\hat{y}_i - y_i < 0 \\\\\n",
    "\\sum_{i=1}^{n} e^{\\frac{\\hat{y}_i - y_i}{10}} - 1, & \\text{sonst}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dabei ist $(\\hat{y}_i) $ die vorhergesagte RUL und $(y_i)$ der wahre Wert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Modellliste mit Angabe, ob sie sample_weight unterstützen ===\n",
    "ALL_MODELS = {\n",
    "    \"Linear Regression\":      (LinearRegression, True),\n",
    "    \"Ridge Regression\":       (Ridge, True),\n",
    "    \"Lasso Regression\":       (Lasso, True),\n",
    "    \"Elastic Net\":            (ElasticNet, True),\n",
    "    \"Decision Tree\":          (DecisionTreeRegressor, True),\n",
    "    \"Random Forest\":          (RandomForestRegressor, True),\n",
    "    \"Gradient Boosting\":      (GradientBoostingRegressor, True),\n",
    "    \"K-Nearest Neighbors\":    (KNeighborsRegressor, False),\n",
    "    \"Support Vector Regr.\":   (SVR, False),\n",
    "}\n",
    "\n",
    "# Einmalige Instanzierung + Gewichtungsinfo für alle Modelle\n",
    "model_defs = [(name, cls(), supports_weights) for name, (cls, supports_weights) in ALL_MODELS.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation aller Modelle ===\n",
    "results = []\n",
    "for name, model, _ in model_defs:\n",
    "    results.append(models.evaluate_model(model, X_train, y_train, X_test, y_test, model_name=name, weighted=False))\n",
    "\n",
    "models_df = pd.DataFrame(results).sort_values(\"NASA-Score\")\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.plot_model_scores(\n",
    "    models_df,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: (Scores bei 2000 begrenzt)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich:**  \n",
    "Die Abbildung zeigt den NASA-Score verschiedener Regressionsmodelle bei der Vorhersage der verbleibenden Nutzungsdauer (RUL). Je niedriger der Score, desto besser ist das Modell in Bezug auf sichere, realistische Vorhersagen.\n",
    "\n",
    "- **Random Forest** erzielt den besten Score, gefolgt von **Gradient Boosting** und **Ridge**.  \n",
    "- Modelle wie **ElasticNet**, **Lasso**, **Decision Tree** und **KNN** erreichen den maximalen Score (2000) und gelten in dieser Form als ungeeignet für dieses Szenario.  \n",
    "\n",
    "In [2] wird für das Ridge-Modell auf demselben Datensatz ein RMSE von 22.64 berichtet. Das hier verwendete Modell erreicht in der Grundkonfiguration einen RMSE von 20.7. Dies deutet darauf hin, dass das eingesetzte Feature Engineering zu einer verbesserten Vorhersagegüte beiträgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Bestes Modell ungewichtet instanziieren, trainieren, vorhersagen ===\n",
    "best_model_name = models_df.iloc[0][\"Model\"]\n",
    "best_model_cls = ALL_MODELS[best_model_name][0]\n",
    "best_model = best_model_cls()\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Plot\n",
    "models.plot_prediction_and_residuals(y_test, y_pred, model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse des Random Forest:**\n",
    "\n",
    "Der rechte Residuenplot zeigt, dass das Modell bei **niedriger RUL tendenziell zur Überschätzung** neigt – es prognostiziert also eine längere verbleibende Lebensdauer als tatsächlich vorhanden ist. Umgekehrt tritt bei hoher RUL häufig eine leichte Unterschätzung auf. Diese Tendenz ist insbesondere in späten Lebensphasen kritisch, da **Überschätzungen kurz vor dem Ausfall** das Risiko ungeplanter Stillstände deutlich erhöhen.\n",
    "\n",
    "**Definition der Gewichtsfunktion**\n",
    "\n",
    "Der verwendete **NASA-Score berücksichtigt diese Asymmetrie** explizit, indem er Überschätzungen deutlich stärker bestraft als Unterschätzungen. Um diesem Umstand gezielt Rechnung zu tragen, wird im nächsten Schritt eine **gewichtete Modellbewertung** eingeführt:  \n",
    "Beobachtungen mit geringer RUL erhalten ein höheres Gewicht, sodass das Modell stärker auf präzise Vorhersagen in sicherheitskritischen Phasen optimiert wird. Die Gewichtsfunktion nimmt dabei exponentiell mit der RUL ab:\n",
    "\n",
    "$$\n",
    "w(\\text{RUL}) = 1 + 2 \\cdot e^{- \\frac{\\text{RUL}}{25}}\n",
    "$$\n",
    "\n",
    "Die Parameter wurden so gewählt, dass die Gewichtung insbesondere im Bereich bis etwa **125 Zyklen** wirkt – also genau dort, wo im Residuenplot eine systematische Überschätzung auftritt. Damit erhalten Einheiten mit geringer Restlebensdauer ein bis zu dreifach höheres Gewicht. Die folgende Grafik visualisiert den Funktionsverlauf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gewichtsfunktion definieren ===\n",
    "rul_vals = np.linspace(0, 125, 200)\n",
    "weights = 1 + 2 * np.exp(-rul_vals / 25)\n",
    "\n",
    "plt.plot(rul_vals, weights)\n",
    "plt.xlabel(\"RUL\")\n",
    "plt.ylabel(\"Gewicht\")\n",
    "plt.title(\"Gewichtsfunktion in Abhängigkeit vom RUL\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gewichtete Modelle evaluieren ===\n",
    "results_weighted = []\n",
    "for name, model, supports_weight in model_defs:\n",
    "    if not supports_weight:\n",
    "        continue\n",
    "    weighted_name = f\"{name} (weighted)\"\n",
    "    results_weighted.append(models.evaluate_model(model, X_train, y_train, X_test,  y_test, model_name=weighted_name, weighted=True))\n",
    "\n",
    "models_df_weighted = pd.DataFrame(results_weighted).sort_values(\"NASA-Score\")\n",
    "\n",
    "# === Kombinieren mit ungewichteten Ergebnissen ===\n",
    "models_df_combined = (pd.concat([models_df, models_df_weighted]).sort_values(\"NASA-Score\").reset_index(drop=True))\n",
    "models_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellvergleichsplot\n",
    "models.plot_model_scores(\n",
    "    models_df,\n",
    "    models_df_weighted,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach Gewichtung (Scores bis 2000 begrenzt)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich vor und nach Gewichtung:**\n",
    "\n",
    "Die Abbildung zeigt den Vergleich der NASA-Scores für jedes Modell – jeweils **vor (schraffiert)** und **nach (vollflächig)** Anwendung der Gewichtung. Ziel war es, Überschätzungen bei niedriger RUL stärker zu bestrafen und so das Modellverhalten in sicherheitskritischen Phasen gezielter zu verbessern.\n",
    "\n",
    "- Bei fast allen Modellen verbessert sich der Score leicht bis deutlich. Besonders ausgeprägt ist der Effekt bei **Linear Regression**, **Gradient Boosting** und **Ridge**.\n",
    "- Bei **Random Forest** ist die Verbesserung zwar gering, aber vorhanden – das Modell war bereits ungewichtet sehr gut.\n",
    "- Bei **ElasticNet** und **Lasso** bringt die Gewichtung zwar einen Fortschritt, allerdings verbleiben sie weiterhin im nicht praktikablen Bereich.\n",
    "- **Decision Trees** bleiben unabhängig von der Gewichtung ungeeignet.\n",
    "\n",
    "Insgesamt zeigt sich, dass eine gezielte Gewichtung der Trainingsdaten — abgestimmt auf die Schwere der Vorhersagefehler — zu einer robusteren Modellleistung führen kann, insbesondere bei Modellen, die empfindlich auf fehlerverteilte Daten reagieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Bestes Modell bestimmen + Instanz erstellen ===\n",
    "best_name = models_df_combined.iloc[0][\"Model\"]\n",
    "base_name = best_name.removesuffix(\" (weighted)\")\n",
    "is_weighted = (best_name != base_name)\n",
    "\n",
    "model_cls, supports_weights = ALL_MODELS[base_name]\n",
    "best_model = model_cls()\n",
    "\n",
    "# === Training (optional mit sample_weight) ===\n",
    "fit_kwargs = {}\n",
    "if is_weighted and supports_weights:\n",
    "    fit_kwargs[\"sample_weight\"] = 1 + 2 * np.exp(-y_train / 25)\n",
    "\n",
    "best_model.fit(X_train, y_train, **fit_kwargs)\n",
    "\n",
    "# === Vorhersage + Plot ===\n",
    "y_pred = best_model.predict(X_test)\n",
    "models.plot_prediction_and_residuals(y_test, y_pred, model_name=best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyse des gewichteten Random Forest:**\n",
    "\n",
    "Im Vergleich zur ungewichteten Variante zeigt der gewichtete Random Forest eine **verbesserte Modellanpassung in den kritischen RUL-Bereichen**. In der linken Grafik („Vorhersage vs. Wahrheit“) sind weniger starke Überschätzungen bei niedriger RUL sichtbar, was auf eine gezieltere Fehlerkontrolle in späten Lebensphasen hinweist.\n",
    "\n",
    "Auch im Residuenplot (rechts) ist eine **leichte Zentrierung der Residuen im Bereich niedriger RUL** erkennbar. Die systematische Tendenz zur Überschätzung wurde abgemildert. Bei höherer RUL bleibt die Streuung vergleichbar zur ungewichteten Variante – hier hat die Gewichtung kaum Einfluss, was gewünscht ist.\n",
    "\n",
    "Insgesamt bestätigt sich, dass die eingeführte Gewichtung ihre Wirkung entfaltet: **Fehler bei niedriger RUL – die im NASA-Score stark bestraft werden – wurden gezielt reduziert**, ohne das Verhalten in stabilen Bereichen negativ zu beeinflussen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Hyperparameter-Tuning (HPT)\n",
    "\n",
    "Nachdem die Modelle im vorherigen Schritt mit Standardparametern trainiert und bewertet wurden, erfolgt nun eine gezielte Optimierung der Hyperparameter in zwei aufeinander aufbauenden Stufen.\n",
    "\n",
    "**Stufe 1 – Grobe Raster-Suche (GridSearch):**  \n",
    "Zunächst wird für alle Modelle ein sinnvoller Parameterraum definiert und mittels `GridSearchCV` nach einer geeigneten Modellkonfiguration gesucht. Als Bewertungsmetrik kommt erneut der NASA-Score zum Einsatz. Diese erste Phase dient dazu, eine solide Ausgangsbasis zu schaffen und bereits klare Fehlkonfigurationen auszusortieren.\n",
    "\n",
    "**Stufe 2 – Feinjustierung (RandomizedSearch):**  \n",
    "Für eine Auswahl der vielversprechendsten Modelle aus der GridSearch wird im Anschluss eine umfassendere Feinabstimmung mit `RandomizedSearchCV` durchgeführt. Dabei werden grössere, kontinuierliche Hyperraumverteilungen verwendet, um durch stichprobenartige Suche bessere Parameterkombinationen zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Modelle und GridSearch-Suchräume definieren ===\n",
    "param_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Ridge Regression\": {\"alpha\": [0.1, 1.0, 10.0]},\n",
    "    \"Lasso Regression\": {\"alpha\": [0.001, 0.01, 0.1]},\n",
    "    \"Elastic Net\": {\"alpha\": [0.01, 0.1], \"l1_ratio\": [0.2, 0.5, 0.8]},\n",
    "    \"K-Nearest Neighbors\": {\"n_neighbors\": [3, 5, 7]},\n",
    "    \"Support Vector Regr.\": {\"C\": [1, 10], \"epsilon\": [0.1, 0.5]},\n",
    "    \"Decision Tree\": {\"max_depth\": [4, 6, 10], \"min_samples_leaf\": [5, 10]},\n",
    "    \"Random Forest\": {\"n_estimators\": [50, 100], \"max_depth\": [6, 10]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [50, 100], \"learning_rate\": [0.05, 0.1]},\n",
    "}\n",
    "\n",
    "# === GridSearchCV – erste Stufe des HPT ===\n",
    "df_hpt_grid = models.run_grid_search(\n",
    "    X_train, y_train,\n",
    "    X_test,  y_test,\n",
    "    models=model_defs,\n",
    "    param_grids=param_grids,\n",
    "    model_path=\"models/fd001/best_grid_model.pkl\",\n",
    "    force_run=HPT_FD001      # True => immer neu rechnen\n",
    ")\n",
    "\n",
    "df_hpt_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add = models_df[models_df[\"Model\"].isin([\"Support Vector Regr.\", \"K-Nearest Neighbors\"])]\n",
    "models_df_vor = pd.concat([models_df_weighted, rows_to_add], ignore_index=True)\n",
    "models.plot_model_scores(\n",
    "    models_df_vor,\n",
    "    df_hpt_grid,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach HPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modellvergleich vor und nach erstem Hyperparameter-Tuning:**\n",
    "\n",
    "Die Abbildung zeigt die Auswirkungen des HPT auf den NASA-Score der Modelle. Verglichen wird die Modellleistung **vor dem Tuning (schraffiert)** mit der Leistung **nach dem Tuning (vollflächig)**.\n",
    "\n",
    "- Bei den meisten Modellen konnte der Score durch HPT weiter reduziert werden, insbesondere bei **Lasso**, **ElasticNet** und **SVR**, die vorher relativ schlecht abschnitten. Auch der **Decision Tree** verbessert sich deutlich, bleibt jedoch insgesamt schwach.\n",
    "- **Random Forest** und **Gradient Boosting** profitieren hingegen kaum vom HPT, da sie bereits zuvor mit guten Default-Werten arbeiteten.\n",
    "- **KNN** bleibt weiterhin ungeeignet – trotz Tuning werden keine brauchbaren Scores erreicht.\n",
    "\n",
    "In [2] wird für das Lasso-Modell auf FD001 ein RMSE von 23.86 berichtet. Nach der GridSearch erreicht das hier trainierte Lasso-Modell einen RMSE von 20.15 und liegt somit darunter. Dies deutet darauf hin, dass die Kombination aus selektiven Features und gezieltem Hyperparameter-Tuning zu einer verbesserten Modellgüte beiträgt.\n",
    "\n",
    "Für das erweiterte Hyperparameter-Tuning mittels `RandomizedSearchCV` wurden bewusst nicht nur die leistungsstärksten Modelle ausgewählt, sondern gezielt solche, bei denen noch substantielles Optimierungspotenzial vermutet wurde:\n",
    "\n",
    "- **Random Forest** und **Gradient Boosting**: bereits starke Resultate, aber mögliche Feinjustierung.\n",
    "- **Lasso**, **ElasticNet** und **SVR**: deutliche Fortschritte in GridSearch, komplexe Hyperräume mit Potenzial für zusätzliche Verbesserungen.\n",
    "- **Decision Tree**: nicht weiter optimiert – begrenzter Nutzen im Vergleich zu RF/GB.\n",
    "- **Ridge** und **Linear Regression**: ausgeschlossen, da kaum Verbesserungspotenzial und keine (bzw. nur minimale) Hyperparameter vorhanden.\n",
    "\n",
    "Die Modellauswahl zielt darauf ab, **verschiedene Modellfamilien sinnvoll abzudecken**, ohne Rechenressourcen auf wenig vielversprechende Optionen zu verschwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# === Parameterräume ===\n",
    "param_distributions = {\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": randint(100, 500),\n",
    "        \"max_depth\": randint(5, 21),\n",
    "        \"min_samples_leaf\": randint(1, 16),\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"bootstrap\": [True, False],\n",
    "        \"ccp_alpha\": uniform(0.0, 0.01)\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": randint(100, 500),\n",
    "        \"learning_rate\": uniform(0.01, 0.2),\n",
    "        \"max_depth\": randint(3, 10),\n",
    "        \"subsample\": uniform(0.6, 0.4),\n",
    "        \"min_samples_leaf\": randint(1, 11)\n",
    "    },\n",
    "    \"Lasso Regression\": {\n",
    "        \"alpha\": uniform(0.00001, 0.1)\n",
    "    },\n",
    "    \"Elastic Net\": {\n",
    "        \"alpha\": uniform(0.0001, 0.1),\n",
    "        \"l1_ratio\": uniform(0, 1)\n",
    "    },\n",
    "    \"Support Vector Regr.\": {\n",
    "        \"C\": uniform(1, 50),\n",
    "        \"epsilon\": uniform(0.01, 1.0),\n",
    "        \"kernel\": [\"rbf\", \"linear\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Modelle + Parameter + Gewichtbarkeit zusammenführen ===\n",
    "X_train[\"unit\"] = df_train_01_fe[\"unit\"]\n",
    "X_test[\"unit\"] = df_test_01_fe[\"unit\"]\n",
    "\n",
    "# === RandomizedSearch ausführen ===\n",
    "df_hpt_rand = models.run_random_search(\n",
    "    X_train.drop(columns=\"unit\"),\n",
    "    y_train,\n",
    "    X_test.drop(columns=\"unit\"),\n",
    "    y_test,\n",
    "    groups=X_train[\"unit\"],\n",
    "    models=model_defs,\n",
    "    param_distributions=param_distributions,\n",
    "    n_splits=3,\n",
    "    n_iter=500,\n",
    "    model_path=\"models/fd001/best_rand_model.pkl\",\n",
    "    force_run=HPT_FD001      # True ⇒ neu rechnen\n",
    ")\n",
    "\n",
    "df_hpt_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Hyperparameter-Spalten aus \"Best Params\" extrahieren\n",
    "df_best_params = models.expand_best_params(df_hpt_rand)\n",
    "df_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpt_grid_red = df_hpt_grid[~df_hpt_grid[\"Model\"].isin([\"Linear Regression\", \"Ridge Regression\", \"Decision Tree\", \"K-Nearest Neighbors\"])]\n",
    "df_plot = models.select_best_per_model(df_hpt_grid_red, df_hpt_rand)\n",
    "models.plot_model_scores(\n",
    "    df_hpt_grid_red,\n",
    "    df_plot,\n",
    "    score_col=\"NASA-Score\",\n",
    "    title=\"Modellvergleich: vor und nach erweitertem HPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellvergleich: Effekt des erweiterten Hyperparameter-Tunings\n",
    "\n",
    "Die Grafik vergleicht die NASA-Scores ausgewählter Modelle **vor und nach der RandomizedSearchCV**. Eingeschlossen sind nur jene Modelle, bei denen eine erweiterte Feinjustierung nach der GridSearch durchgeführt wurde.\n",
    "\n",
    "- **Random Forest** erzielt weiterhin die besten Resultate. Durch die Feinabstimmung konnte der NASA-Score von etwa 495 auf **455** gesenkt werden.\n",
    "- **Gradient Boosting** verbessert sich ebenfalls merklich und reduziert den Score von rund 550 auf **490**.\n",
    "- **Lasso Regression** erreicht eine spürbare Steigerung der Modellqualität – der Score fällt von ca. 600 auf **534**.\n",
    "- Auch **Elastic Net** profitiert vom erweiterten Suchraum, wenngleich in geringerem Ausmass. Der Score sinkt von rund 700 auf **605**.\n",
    "- **Support Vector Regression** bleibt trotz umfangreichem Hyperparameterraum auf sehr hohem Niveau (**ca. 750**) – der Score ist **vor und nach dem Tuning identisch**, was auf fehlende Optimierbarkeit im gegebenen Setup hindeutet.\n",
    "\n",
    "Die Resultate unterstreichen: **RandomizedSearchCV ist vor allem dann wirkungsvoll**, wenn das Modell stark auf Hyperparameter reagiert. Während **Lasso** und **Elastic Net** klar profitieren, liefern **Random Forest** und **Gradient Boosting** bereits ohne Feintuning sehr gute Resultate. Für **SVR** hingegen bleibt der Ansatz trotz Tuning ungeeignet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Evaluation\n",
    "\n",
    "Nach Abschluss der zweistufigen Hyperparameter-Optimierung folgt die finale Bewertung der besten Modellkonfigurationen. Jedes Modell mit starker Performance aus der Randomized Search wird erneut instanziiert, auf den Trainingsdaten mit gewichteter Verlustfunktion trainiert und auf den Testdaten evaluiert.\n",
    "\n",
    "Das zentrale Auswahlkriterium bleibt der **NASA-Score**, da er im Kontext prädiktiver Wartung kritische Fehler stärker gewichtet als Standardmetriken wie RMSE oder R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "results     = []\n",
    "y_preds     = []\n",
    "models_list = []\n",
    "\n",
    "# Evaluierung aller Modelle aus df_plot mit richtigen Parametern\n",
    "for name, _, supports_weights in model_defs:\n",
    "    if name not in df_plot[\"Model\"].values:\n",
    "        continue  # nur Modelle evaluieren, die im df_plot vorhanden sind\n",
    "\n",
    "    row    = df_plot[df_plot[\"Model\"] == name].iloc[0]\n",
    "    params = row[\"Best Params\"]\n",
    "\n",
    "    model_cls = ALL_MODELS[name][0]\n",
    "    if \"random_state\" in inspect.signature(model_cls).parameters:\n",
    "        model = model_cls(**{**params, \"random_state\": 9})\n",
    "    else:\n",
    "        model = model_cls(**params)\n",
    "\n",
    "    eval_res = models.evaluate_model(\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        X_test,  y_test,\n",
    "        model_name=name,\n",
    "        weighted=supports_weights\n",
    "    )\n",
    "\n",
    "    results.append(eval_res)\n",
    "    y_preds.append(model.predict(X_test))\n",
    "    models_list.append(model)\n",
    "\n",
    "# Bestes Modell bestimmen\n",
    "df_test_eval     = pd.DataFrame(results)\n",
    "best_idx         = df_test_eval[\"NASA-Score\"].idxmin()\n",
    "df_test_eval     = df_test_eval.loc[[best_idx]].reset_index(drop=True)\n",
    "y_pred_best      = y_preds[best_idx]\n",
    "best_model_name  = df_test_eval.loc[0, \"Model\"]\n",
    "df_test_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interpretation_plots = [\n",
    "    toggle(\"Vorhersage + Residuen\", lambda df: models.plot_prediction_and_residuals(y_test, y_pred_best, best_model_name)),\n",
    "    toggle(\"Feature-Wichtigkeiten\", lambda df: models.plot_feature_importance(best_model, X_train)),\n",
    "    toggle(\"SHAP Beeswarm\", lambda df: models.plot_shap_beeswarm(best_model, X_train, X_test)),\n",
    "    toggle(\"SHAP Beispiele (Waterfall)\", lambda df: models.plot_shap_waterfalls(best_model, X_train, X_test, y_test, y_pred_best)),\n",
    "    toggle(\"Partial Dependence Plots\", lambda df: models.plot_pdp(best_model, X_train)),\n",
    "]\n",
    "\n",
    "model_interpretation_section = [\n",
    "    util.make_dropdown_section(model_interpretation_plots, f\"fd001_{best_model_name}_Interpretation\", use_cache=False)\n",
    "]\n",
    "\n",
    "panel_modelinterpretation = util.make_lazy_panel_with_tabs(\n",
    "    model_interpretation_section,\n",
    "    tab_titles=[\"Modellinterpretation\"],\n",
    "    open_btn_text=\"FD001_XAI öffnen\",\n",
    "    close_btn_text=\"Schliessen\"\n",
    ")\n",
    "\n",
    "display(panel_modelinterpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abschliessende Evaluation des besten Modells: Random Forest (weighted)**\n",
    "\n",
    "Das finale Modell ist ein **gewichteter Random Forest** mit folgenden Kennwerten:\n",
    "\n",
    "- **RMSE-Test:** 17.28  \n",
    "- **R²-Test:** 0.83  \n",
    "- **NASA-Score:** 441.85\n",
    "\n",
    "Die **Vorhersagegrafik** zeigt eine konsistente Übereinstimmung mit der Realität über den gesamten RUL-Bereich hinweg.  \n",
    "Nur in sehr hohen RUL-Werten treten leichte systematische Abweichungen auf, die jedoch keine gravierenden Fehlprognosen verursachen.\n",
    "\n",
    "Der **Residuenplot** verdeutlicht, dass die Fehlerverteilung gleichmässig um Null zentriert ist – ein Indikator für robuste Generalisierung und geringe systematische Verzerrung.\n",
    "\n",
    "Insgesamt lässt sich festhalten:  \n",
    "Der gewichtete Random Forest bildet den komplexen Degradationsverlauf zuverlässig ab und vermeidet gleichzeitig kritische Überschätzungen in späten Lebensphasen – was insbesondere durch den niedrigen NASA-Score bestätigt wird.\n",
    "\n",
    "**Modellinterpretation**\n",
    "\n",
    "Zur vertieften Analyse wurden fünf XAI-Methoden angewandt:\n",
    "\n",
    "1. **Gini-Importanz** bestätigt `sensor_4_T50_LPT_outlet_temp_r2` und dessen Steigung als die dominierenden Merkmale.  \n",
    "2. **SHAP Beeswarm** zeigt: neben Temperaturmerkmalen spielen auch Druckfluktuationen (`Ps30`) und Mischungskennzahlen (`phi_to_bpr`) eine starke Rolle.  \n",
    "3. **SHAP-Waterfall-Diagramme** für exemplarische Einheiten zeigen, wie einzelne Features zu über-, unter- oder exakt passenden Vorhersagen führen.  \n",
    "4. **PDP-Diagramme** bestätigen klare nichtlineare Schwellenwerte für zentrale Sensoren, z. B. ein starker Abfall der RUL-Vorhersage bei `sensor_4_T50_LPT_outlet_temp_r2 > 0.35`.  \n",
    "5. Die Interpretationen bestätigen: das Modell ist **sensitiv**, aber **stabil** und **physikalisch plausibel**.\n",
    "\n",
    "**Vergleich mit bestehender Literatur**\n",
    "\n",
    "Zur Bewertung des eigenen Modells wurden vier aktuelle Arbeiten sowie die systematische Vergleichstabelle aus [3] herangezogen. Die folgende Tabelle fasst zentrale Ergebnisse zusammen:\n",
    "\n",
    "| Quelle | Methode                                 | RMSE   | R²     | NASA-Score |\n",
    "|--------|------------------------------------------|--------|--------|-------------|\n",
    "| [1]    | Random Forest (5-fold CV)                | 19.01  | –      | –           |\n",
    "| [2]    | RF-Feature-Selection + MLP (Bayes-Opt.)  | 17.14  | 0.83   | –           |\n",
    "| [4]    | LSTM mit geglätteten Sequenzen           | ~28.20 | –      | –           |\n",
    "| [3]    | Deep LSTM mit Deg.-Erkennung             | **7.78**   | –      | **100**       |\n",
    "| [3]    | Deep-Learning-Übersicht (Range)          | 7.78–18.44 | –    | 100–1290    |\n",
    "| **Eigene Arbeit** | Random Forest (weighted, tuned)     | **17.28** | **0.83** | **441.85**   |\n",
    "\n",
    "Das hier entwickelte Modell reiht sich damit im unteren Drittel der Deep-Learning-Vergleichswerte ein und übertrifft dabei mehrere bestehende ML- und DL-Ansätze. Besonders hervorzuheben ist die Kombination aus guter Vorhersagegüte, niedrigem NASA-Score und vollständiger Interpretierbarkeit – ein klarer Vorteil gegenüber vielen komplexeren Black-Box-Methoden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fazit zu Kapitel 3.1 – Analyse für FD001**\n",
    "\n",
    "Die Analyse des einfachsten C-MAPSS-Szenarios FD001 hat gezeigt, dass auch unter konstanten Betriebsbedingungen eine präzise RUL-Vorhersage anspruchsvoll bleibt. Durch gezielte Feature-Auswahl, temporale Merkmalsextraktion sowie eine schrittweise Modelloptimierung konnte jedoch ein leistungsfähiges Vorhersagemodell entwickelt werden.\n",
    "\n",
    "Besonders hervorgetan hat sich der **gewichtete Random Forest**, der dank robuster Struktur und Fehlergewichtung sowohl in klassischen Metriken (RMSE, R²) als auch im NASA-Score überzeugte. Die Gewichtung erwies sich dabei als entscheidender Faktor zur Reduktion systematischer Überschätzungen bei niedriger RUL.\n",
    "\n",
    "Damit bildet FD001 eine solide Grundlage, auf der sich die Generalisierbarkeit und Belastbarkeit der entwickelten Pipeline in komplexeren Szenarien (Kapitel 3.2–3.4) überprüfen lässt. Erste übergreifende Erkenntnisse zeigen, dass die Kombination aus gezielter Feature-Reduktion, zeitabhängigen Merkmalen und gewichteter Modellierung ein vielversprechender Ansatz zur Verbesserung der Robustheit und Interpretierbarkeit ist.\n",
    "\n",
    "Ein möglicher nächster Schritt wäre die Entwicklung eines Ensemble-Modells, das verschiedene Modelltypen kombiniert und deren Stärken gezielt vereint. Gerade im Szenario FD002, das durch heterogene Betriebsbedingungen geprägt ist, könnte mithilfe von Clustering zunächst eine Segmentierung erfolgen, woraufhin unterschiedlichen Clustern spezifische Modelle zugewiesen werden.\n",
    "\n",
    "Zudem bieten Deep-Learning-Modelle grundsätzlich eine höhere Vorhersagepräzision, insbesondere bei komplexen, sequenziellen Datenstrukturen. Diese Leistungsfähigkeit geht jedoch meist mit einem erheblichen Verlust an Interpretierbarkeit einher. Das kann in sicherheitskritischen Anwendungen wie der Triebwerksüberwachung problematisch sein. In solchen Kontexten kann die fehlende Transparenz der Modelle zu berechtigter Unsicherheit führen und ihre praktische Einsetzbarkeit einschränken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.2 Analyse für FD002\n",
    "\n",
    "FD002 enthält variable Betriebsbedingungen bei einem einzigen Degradationsmodus. Im Vergleich zu FD001 sind die Sensorverläufe komplexer und stärker durch die Operation Settings beeinflusst. Die Analyse fokussiert auf geeignete Normalisierungen, die Rolle der Settings und die Möglichkeit, durch Clustering differenzierte Modelle für verschiedene Betriebszustände einzusetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Explorative Datenanalyse (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD002:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD002 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_02, \"FD002\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in list(range(1, 18)) + [19, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[244, 112]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=112, dataset_name=\"FD002-112\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD002\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD002 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_02,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD002\",\n",
    "            dbscan_eps = 2.5,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_02[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD002\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD002\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD002\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD002\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD002\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD002\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD002\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD002\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD002 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD002 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD002  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.3 Analyse für FD003\n",
    "FD003 weist konstante Betriebsbedingungen, aber mehrere Degradationsmodi auf. Damit eignet sich der Datensatz gut, um rein sensorbasierte Unterschiede im Degradationsverhalten zu untersuchen, ohne dass sich zusätzlich die Betriebszustände verändern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD003:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD003 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_03, \"FD003\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21]]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[99, 55]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=55, dataset_name=\"FD003-55\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD003\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD003 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_03,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD003\",\n",
    "            dbscan_eps = 3,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_03[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD003\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD003\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD003\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD003\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD003\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD003\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD003\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD003\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD003 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD003 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD003  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.4 Analyse für FD004\n",
    "FD004 kombiniert die komplexesten Bedingungen aller C-MAPSS-Datensätze: variable Betriebspunkte und mehrere Degradationsmodi.\n",
    "Dieser Datensatz stellt somit das realistischste, aber auch herausforderndste Szenario dar. Ziel der Analyse ist es, robuste Muster trotz starker Streuung und Rauschen zu identifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.1 Explorative Datenanalyse (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EDA_FD004:\n",
    "    # ─────────────────────────────\n",
    "    # Konfiguration für FD004 EDA\n",
    "    # ─────────────────────────────\n",
    "    # Steuerung des PNG-Cachings pro Plot-Sektion.\n",
    "    # Falls False: PNG wird gelöscht und neu erstellt.\n",
    "    USE_CACHE = {\n",
    "        \"overview\": True,\n",
    "        \"ops\": True,\n",
    "        \"sensors\": True,\n",
    "        \"cluster\": True,\n",
    "    }\n",
    "    FORCE_RECOMPUTE_TSNE_DBSCAN = FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "    # FORCE_RECOMPUTE_TSNE_DBSCAN = True\n",
    "    # ─────────────────────────────\n",
    "\n",
    "    toggle = util.make_toggle_shortcut(df_train_04, \"FD004\")\n",
    "    sensor_cols = [f\"sensor_{i}\" for i in range(1, 22)]\n",
    "\n",
    "    overview_plots = [\n",
    "        toggle(\"1-1. Lebensdauerkennzahlen\", eda.describe_life_stats),\n",
    "        toggle(\"1-2. Lebensdauerverteilung\", eda.plot_life_distribution),\n",
    "    ]\n",
    "    ops_plots = [\n",
    "        toggle(\"2-1. Verläufe Operation Settings\", eda.plot_opsetting_curves, unit_ids=[214, 118]),\n",
    "        toggle(\"2-2. Korrelation Operation Settings\", eda.plot_opsetting_correlation_matrix),\n",
    "        toggle(\"2-3. Verteilung im letzten Zyklus\", eda.plot_opsetting_box_violin_last_cycle),\n",
    "        toggle(\"2-4. Verteilung nach Quantilen\", eda.plot_opsetting_distributions_by_cycle_range, lower_quantile=0.25, upper_quantile=0.75),\n",
    "        toggle(\"2-5. RUL-Korrelation\", eda.plot_opsetting_rul_correlation),\n",
    "        toggle(\"2-6. Trend normierte Zeit\", eda.plot_average_opsetting_trend_normalized_time),\n",
    "    ]\n",
    "    sensors_plots = [\n",
    "        toggle(\"3-1. Sensorverläufe\", eda.plot_single_sensor_curves, unit_ids=range(1, 6), rolling_window=10),\n",
    "        toggle(\"3-2. Sensor-Overlay\", eda.plot_sensor_overlay, unit_id=118, dataset_name=\"FD004-118\"),\n",
    "        toggle(\"3-3. Sensor-Korrelation\", lambda df: (\n",
    "            (fig := plt.figure(figsize=(28, 10))),\n",
    "            (axs := fig.subplots(1, 2)),\n",
    "            eda.plot_sensor_correlation_matrix(df, dataset_name=\"FD004\", ax=axs[0]),\n",
    "            eda.plot_sensor_correlation_matrix(df, sensor_cols=sensor_cols, dataset_name=\"FD004 (ohne konstante)\", annot=True, ax=axs[1]),\n",
    "            plt.tight_layout(),\n",
    "        )),\n",
    "        toggle(\"3-4. Box/Violin letzter Zyklus\", eda.plot_sensor_box_violin_last_cycle, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-5. Sensorverteilung nach Lebensdauer\", eda.plot_sensor_distributions_by_cycle_range, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-6. Sensorverteilungen nach op_cond\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"op_cond\", sensor_cols=sensor_cols),\n",
    "        toggle(\"3-7. RUL-Korrelation Sensoren\", eda.plot_sensor_rul_correlation, sensor_cols=sensor_cols),\n",
    "        toggle(\"3-8. Sensortrend normierte Zeit\", eda.plot_average_sensor_trend_normalized_time, sensor_cols=sensor_cols),\n",
    "    ]\n",
    "\n",
    "    # Einstellungen von plot_tsne_dbscan_clusters\n",
    "    toggle_tsne = widgets.Output()\n",
    "    with toggle_tsne:\n",
    "        fig, labels = eda.plot_tsne_dbscan_clusters(\n",
    "            df_train_04,\n",
    "            feature_cols = sensor_cols,\n",
    "            dataset_name=\"FD004\",\n",
    "            dbscan_eps = 3,\n",
    "            force_recompute=FORCE_RECOMPUTE_TSNE_DBSCAN\n",
    "        )\n",
    "        df_train_04[\"cluster_tsne\"] = labels\n",
    "\n",
    "    cluster_plots = [\n",
    "        toggle(\"4-1. TSNE + DBSCAN Cluster\", eda.plot_tsne_dbscan_clusters), # plot_tsne_dbscan_clusters zeigt nur den Plot an\n",
    "        toggle(\"4-2. op_settings je Cluster (Boxplot)\", eda.plot_op_settings_vs_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-3. Cluster-Transitions (Sankey)\", lambda df: (\n",
    "            fig := eda.plot_cluster_transitions_sankey(df, cluster_col=\"cluster_tsne\", dataset_name=\"FD004\"),\n",
    "            fig.update_layout(width=1800, height=600),\n",
    "            fig\n",
    "        )),\n",
    "        toggle(\"4-4. Durchschnittlicher Zeitpunkt je Cluster\", eda.plot_cluster_average_time, cluster_col=\"cluster_tsne\", dataset_name=\"FD004\"),\n",
    "        toggle(\"4-5. Clusterverteilung letzter Zyklus\", eda.plot_cluster_distribution_last_cycle, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-6. Lebensdauer pro finalem Cluster\", eda.plot_lifetime_boxplot_by_cluster, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-7. Mittlere Sensorwerte pro Cluster\", eda.plot_mean_normalized_sensors_by_cluster, sensor_cols=sensor_cols, cluster_col=\"cluster_tsne\"),\n",
    "        toggle(\"4-8. Sensorverteilungen nach Cluster\", eda.plot_sensor_distributions_by_cycle_range, hue_col=\"cluster_tsne\", sensor_cols=sensor_cols),\n",
    "        toggle(\"4-9. Trend Sensoren je Cluster\",\n",
    "               lambda df: util.make_cluster_navigation_panel(\n",
    "                   df=df,\n",
    "                   cluster_col=\"cluster_tsne\",\n",
    "                   cluster_plot_func=eda.plot_average_sensor_trend_normalized_time,\n",
    "                   sensor_cols=sensor_cols,\n",
    "                   dataset_name=\"FD004\",\n",
    "                   force_recompute=not USE_CACHE[\"cluster\"]\n",
    "               )),\n",
    "        toggle(\"4-10. Cluster-Zusammenfassung (Tabelle)\", eda.summarize_cluster_characteristics, cluster_col=\"cluster_tsne\"),\n",
    "    ]\n",
    "\n",
    "    if PRECOMPUTE_ALL_PLOTS:\n",
    "        util.cache_util.cache_all_plots(\n",
    "            [overview_plots, ops_plots, sensors_plots, cluster_plots],\n",
    "            dataset_name=\"FD004\",\n",
    "            force_recompute=FORCE_RECOMPUTE_PLOTS\n",
    "        )\n",
    "\n",
    "    sections = [\n",
    "        util.make_dropdown_section(overview_plots, \"FD004\", use_cache=USE_CACHE[\"overview\"]),\n",
    "        util.make_dropdown_section(ops_plots, \"FD004\", use_cache=USE_CACHE[\"ops\"]),\n",
    "        util.make_dropdown_section(sensors_plots, \"FD004\", use_cache=USE_CACHE[\"sensors\"]),\n",
    "        util.make_dropdown_section(cluster_plots, \"FD004\", use_cache=USE_CACHE[\"cluster\"]),\n",
    "    ]\n",
    "    tab_titles = [\n",
    "        \"1. Übersicht\",\n",
    "        \"2. Operation Settings\",\n",
    "        \"3. Sensoren\",\n",
    "        \"4. Clusteranalyse\",\n",
    "    ]\n",
    "    eda_panel_FD004 = util.make_lazy_panel_with_tabs(\n",
    "        sections,\n",
    "        tab_titles=tab_titles,\n",
    "        open_btn_text=\"FD004 EDA öffnen\",\n",
    "        close_btn_text=\"Schliessen\"\n",
    "    )\n",
    "    display(eda_panel_FD004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA-Zusammenfassung FD004  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.4 Hyperparameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.4.5 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Kombinierte Analyse (FD001–FD004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Explorative Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.4 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Zusammenfassung und Ausblick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Ergebnisse im Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.3 Weiterführende Ideen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anhang A – Eigenständigkeitserklärung\n",
    "\n",
    "Hiermit bestätige ich, dass ich die vorliegende Arbeit selbständig verfasst und keine anderen als die angegebenen Hilfsmittel benutzt habe.  \n",
    "Die Stellen der Arbeit, die dem Wortlaut oder dem Sinn nach anderen Werken (dazu zählen auch Internetquellen) entnommen sind, wurden unter Angabe der Quelle kenntlich gemacht.\n",
    "\n",
    "<table style=\"width:100%; background-color: white; padding: 10px; border-radius: 6px; box-shadow: 0 0 5px rgba(0,0,0,0.2); margin-top:20px;\">\n",
    "  <tr>\n",
    "    <td align=\"left\">\n",
    "      <img src=\"images/Unterschrift.png\" alt=\"Unterschrift\" style=\"height:80px;\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anhang B – Literaturverzeichnis\n",
    "\n",
    "[1] Gupta, R. K.; Nakum, J.; Gupta, P.: *A Machine Learning Approach for Turbofan Jet Engine Predictive Maintenance*. Procedia Computer Science. 259, 2025, S. 161–171. https://doi.org/10.1016/j.procs.2025.03.317\n",
    "\n",
    "[2] Wang, H.; Li, D.; Li, D.; Liu, C.; Yang, X.; Zhu, G.: *Remaining Useful Life Prediction of Aircraft Turbofan Engine Based on Random Forest Feature Selection and Multi-Layer Perceptron*. Applied Sciences. 13, 2023, Art. 7186. https://doi.org/10.3390/app13127186\n",
    "\n",
    "[3] Asif, O.; Haider, S. A.; Naqvi, S. R.; Zaki, J. F. W.; Kwak, K.-S.; Islam, S. M. R.: *A Deep Learning Model for Remaining Useful Life Prediction of Aircraft Turbofan Engine on C-MAPSS Dataset* in IEEE Access, vol. 10, pp. 95425-95440, 2022, https://doi.org//10.1109/ACCESS.2022.3203406\n",
    "\n",
    "[4] Peringal, A.; Mohiuddin, M. B.; Hassan, A.: *Remaining Useful Life Prediction for Aircraft Engines using LSTM.* Preprint auf arXiv, 2024. [arXiv:2401.07590](https://arxiv.org/abs/2401.07590)\n",
    "\n",
    "---\n",
    "*Für die sprachliche Überarbeitung und die Unterstützung bei Codefragmenten wurde das KI-Tool* **ChatGPT** *von OpenAI (GPT-4o, https://chatgpt.com) verwendet. Die fachliche und inhaltliche Verantwortung liegt vollständig beim Autor.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
